# 
# Translators:
msgid ""
msgstr ""
"Project-Id-Version: OpenStack Manuals\n"
"POT-Creation-Date: 2014-05-16 14:49+0000\n"
"PO-Revision-Date: 2014-05-18 21:11+0000\n"
"Last-Translator: openstackjenkins <jenkins@openstack.org>\n"
"Language-Team: Hungarian (http://www.transifex.com/projects/p/openstack-manuals-i18n/language/hu/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: hu\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_arch_provision.xml108(None)
msgid ""
"@@image: 'figures/os_disk_partition.png'; "
"md5=2cd7b90349b84b8ef2c97727b9601045"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml14(title)
msgid "Provisioning and Deployment"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml15(para)
msgid ""
"A critical part of a cloud's scalability is the amount of effort that it "
"takes to run your cloud. To minimize the operational cost of running your "
"cloud, set up and use an automated deployment and configuration "
"infrastructure with a configuration management system such as Puppet or "
"Chef. Combined, these systems greatly reduce manual effort and the chance "
"for operator error."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml21(para)
msgid ""
"This infrastructure includes systems to automatically install the operating "
"system's initial configuration and later coordinate the configuration of all"
" services automatically and centrally, which reduces both manual effort and "
"the chance for error. Examples include Ansible, Chef, Puppet, and Salt. You "
"can even use OpenStack to deploy OpenStack, fondly named TripleO, for "
"OpenStack On OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml28(title)
msgid "Automated Deployment"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml29(para)
msgid ""
"An automated deployment system installs and configures operating systems on "
"new servers, without intervention, after the absolute minimum amount of "
"manual work, including physical racking, MAC-to-IP assignment, power "
"configuration, and so on. Typically, solutions rely on wrappers around PXE "
"boot and TFTP servers for the basic operating system install, and then hand "
"off to an automated configuration management system."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml37(para)
msgid ""
"Both Ubuntu and Red Hat Linux include mechanisms for configuring the "
"operating system, including preseed and kickstart, that you can use after a "
"network boot. Typically, these are used to bootstrap an automated "
"configuration system. Alternatively, you can use an image-based approach for"
" deploying the operating system, such as systemimager. You can use both "
"approaches with a virtualized infrastructure, such as when you run VMs to "
"separate your control services and physical infrastructure."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml45(para)
msgid ""
"When you create a deployment plan, focus on a few vital areas because they "
"are very hard to modify post deployment. The next two sections talk about "
"configurations for:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml51(para)
msgid "Disk partioning and disk array setup for scalability"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml54(para)
msgid "Networking configuration just for PXE booting"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml60(title)
msgid "Disk Partitioning and RAID"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml61(para)
msgid ""
"At the very base of any operating system are the hard drives on which the "
"operating system (OS) is installed."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml63(para)
msgid ""
"You must complete the following configurations on the server's hard drives:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml66(para)
msgid ""
"Partitioning, which provides greater flexibility for layout of operating "
"system and swap space, as described below."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml70(para)
msgid ""
"Adding to a RAID array (RAID stands for redundant array of independent "
"disks), based on the number of disks you have available, so that you can add"
" capacity as your cloud grows. Some options are described in more detail "
"below."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml76(para)
msgid ""
"The simplest option to get started is to use one hard drive with two "
"partitions:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml80(para)
msgid ""
"File system to store files and directories, where all the data lives, "
"including the root partition that starts and runs the system."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml85(para)
msgid ""
"Swap space to free up memory for processes, as an independent area of the "
"physical disk used only for swapping and nothing else."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml90(para)
msgid ""
"RAID is not used in this simplistic one-drive setup because generally for "
"production clouds you want to ensure that if one disk fails another can take"
" its place. Instead, for production, use more than one disk. The number of "
"disks determine what types of RAID arrays to build."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml97(para)
msgid ""
"We recommend that you choose one of the following multiple disk options:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml100(para)
msgid ""
"<emphasis role=\"bold\">Option 1:</emphasis> Partition all drives in the "
"same way in a horizontal fashion, as shown in <xref "
"linkend=\"disk_partition_figure\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml105(title)
msgid "Partition setup of drives"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml112(para)
msgid ""
"With this option, you can assign different partitions to different RAID "
"arrays. You can allocate partition 1 of disk one and two to the "
"<code>/boot</code> partition mirror. You can make partition 2 of all disks "
"the root partition mirror. You can use partition 3 of all disks for a <code"
">cinder-volumes</code> LVM partition running on a RAID 10 array."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml118(para)
msgid ""
"While you might end up with unused partitions, such as partition 1 in disk "
"three and four of this example, this option allows for maximum utilization "
"of disk space. I/O performance might be an issue as a result of all disks "
"being used for all tasks."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml126(para)
msgid ""
"<emphasis role=\"bold\">Option 2:</emphasis> Add all raw disks to one large "
"RAID array, either hardware or software based. You can partition this large "
"array with the boot, root, swap, and LVM areas. This option is simple to "
"implement and uses all partitions. However, disk I/O might suffer."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml132(para)
msgid ""
"<emphasis role=\"bold\">Option 3:</emphasis> Dedicate entire disks to "
"certain partitions. For example, you could allocate disk one and two "
"entirely to the boot, root, and swap partitions under a RAID 1 mirror. Then,"
" allocate disk three and four entirely to the LVM partition, also under a "
"RAID 1 mirror. Disk I/O should be better because I/O is focused on dedicated"
" tasks. However, the LVM partition is much smaller."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml143(para)
msgid ""
"You may find that you can automate the partitioning itself. For example, MIT"
" uses Fully Automatic Installation (FAI) (<link href=\"http://fai-"
"project.org/\">fai-project.org/</link>) to do the initial PXE-based "
"partition and then install using a combination of min/max and percentage-"
"based partitioning."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml151(para)
msgid ""
"As with most architecture choices, the right answer depends on your "
"environment. If you are using existing hardware, you know the disk density "
"of your servers and can determine some decisions based on the options above."
" If you are going through a procurement process, your user's requirements "
"also help you determine hardware purchases. Here are some examples from a "
"private cloud providing web developers custom environments at AT&amp;T. This"
" example is from a specific deployment, so your existing hardware or "
"procurement opportunity may vary from this. AT&amp;Ts use three types of "
"hardware in its deployment:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml165(para)
msgid ""
"Hardware for controller nodes, used for all stateless OpenStack API "
"services. About 32–64 GB memory, small attached disk, one processor, varied "
"number of cores, such as 6–12."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml172(para)
msgid ""
"Hardware for compute nodes. Typically 256 or 144 GB memory, two processors, "
"24 cores. 4–6 TB direct attached storage, typically in a RAID 5 "
"configuration."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml178(para)
msgid ""
"Hardware for storage nodes. Typically for these the disk space is optimized "
"for the lowest cost per GB of storage while maintaining rack-space "
"efficiency."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml184(para)
msgid ""
"Again, the right answer depends on your environment. You have to make your "
"decision based on the trade-offs between space utilization, simplicity, and "
"I/O performance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml190(title)
msgid "Network Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml191(para)
msgid ""
"Network configuration is a very large topic that spans multiple areas of "
"this book. For now, make sure that your servers can PXE boot and "
"successfully communicate with the deployment server."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml195(para)
msgid ""
"For example, you usually cannot configure NICs for VLANs when PXE booting. "
"Additionally, you usually cannot PXE boot with bonded NICs. If you run into "
"this scenario, consider using a simple 1 GB switch in a private network on "
"which only your cloud communicates."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml203(title)
msgid "Automated Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml204(para)
msgid ""
"The purpose of automatic configuration management is to establish and "
"maintain the consistency of a system without using human intervention. You "
"want to maintain consistency in your deployments so that you can have the "
"same cloud every time, repeatably. Proper use of automatic configuration-"
"management tools ensures that components of the cloud systems are in "
"particular states, in addition to simplifying deployment, and configuration "
"change propagation."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml213(para)
msgid ""
"These tools also make it possible to test and roll back changes, as they are"
" fully repeatable. Conveniently, a large body of work has been done by the "
"OpenStack community in this space. Puppet—a configuration management "
"tool—even provides official modules for OpenStack in an OpenStack "
"infrastructure system known as Stackforge at <link "
"href=\"https://github.com/stackforge/puppet-"
"openstack\">https://github.com/stackforge/puppet-openstack</link>. Chef "
"configuration management is provided within <link "
"href=\"https://github.com/stackforge/openstack-chef-"
"repo\">https://github.com/stackforge/openstack-chef-repo</link>. Additional "
"configuration-management systems include Juju, Ansible, and Salt. Also, "
"PackStack is a command-line utility for Red Hat Enterprise Linux and "
"derivatives that uses Puppet modules to support rapid deployment of "
"OpenStack on existing servers over an SSH connection."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml231(para)
msgid ""
"An integral part of a configuration-management system is the items that it "
"controls. You should carefully consider all of the items that you want, or "
"do not want, to be automatically managed. For example, you may not want to "
"automatically format hard drives with user data."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml239(title)
msgid "Remote Management"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml240(para)
msgid ""
"In our experience, most operators don't sit right next to the servers "
"running the cloud, and many don't necessarily enjoy visiting the data "
"center. OpenStack should be entirely remotely configurable, but sometimes "
"not everything goes according to plan."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml244(para)
msgid ""
"In this instance, having an out-of-band access into nodes running OpenStack "
"components, is a boon. The IPMI protocol is the de-facto standard here, and "
"acquiring hardware that supports it is highly recommended to achieve that "
"lights-out data center aim."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml248(para)
msgid ""
"In addition, consider remote power control as well. While IPMI usually "
"controls the server's power state, having remote access to the PDU that the "
"server is plugged into can really be useful for situations when everything "
"seems wedged."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml254(title)
msgid "Parting Thoughts for Provisioning and Deploying OpenStack"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml255(para)
msgid ""
"You can save time by understanding the use cases for the cloud you want to "
"create. Use cases for OpenStack are varied. Some include object storage "
"only, others require preconfigured compute resources to speed development-"
"environment set up, and others need fast provisioning of compute resources "
"that are already secured per tenant with private networks. Your users may "
"have need for highly redundant servers to make sure their legacy "
"applications continue to run. Perhaps a goal would be to architect these "
"legacy applications so that they run on multiple instances in a cloudy, "
"fault-tolerant way, but not make it a goal to add to those clusters over "
"time. Your users may indicate that they need scaling considerations because "
"of heavy Windows server use."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml269(para)
msgid ""
"You can save resources by looking at the best fit for the hardware you have "
"in place already. You might have some high-density storage hardware "
"available. You could format and repurpose those servers for OpenStack Object"
" Storage. All of these considerations and input from users help you build "
"your use case and your deployment plan."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml275(para)
msgid ""
"For further research about OpenStack deployment, investigate the supported "
"and documented pre-configured, pre packaged installers for OpenStack from "
"companies such as <link "
"href=\"http://www.ubuntu.com/cloud/tools/openstack\">Canonical</link>, <link"
" "
"href=\"http://www.cisco.com/web/solutions/openstack/&#x200E;\">Cisco</link>,"
" <link href=\"http://www.cloudscaling.com/\">Cloudscaling</link>, <link "
"href=\"http://www-03.ibm.com/software/products/en/smartcloud-"
"orchestrator/\">IBM</link>, <link "
"href=\"http://www.metacloud.com/\">Metacloud</link>, <link "
"href=\"http://www.mirantis.com/\">Mirantis</link>, <link "
"href=\"http://www.pistoncloud.com/\">Piston</link>, <link "
"href=\"http://www.rackspace.com/cloud/private/&#x200E;\">Rackspace</link>, "
"<link href=\"http://www.redhat.com/openstack/\">Red Hat</link>, <link "
"href=\"http://www.suse.com/cloud\">SUSE</link>, and <link "
"href=\"http://www.swiftstack.com/\">SwiftStack</link>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml296(title)
#: ./doc/openstack-ops/ch_ops_customize.xml855(title)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml393(title)
#: ./doc/openstack-ops/ch_arch_storage.xml561(title)
#: ./doc/openstack-ops/ch_arch_network_design.xml383(title)
msgid "Conclusion"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml297(para)
msgid ""
"The decisions you make with respect to provisioning and deployment will "
"affect your day-to-day, week-to-week, and month-to-month maintenance of the "
"cloud. Your configuration management will be able to evolve over time. "
"However, more thought and design need to be done for upfront choices about "
"deployment, disk partitioning, and network configuration."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml13(title)
msgid "User-Facing Operations"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml14(para)
msgid ""
"This guide is for OpenStack operators and does not seek to be an exhaustive "
"reference for users, but as an operator you should have a basic "
"understanding of how to use the cloud facilities. This chapter looks at "
"OpenStack from a basic user perspective, which helps you understand your "
"users' needs and determine, when you get a trouble ticket, whether it is a "
"user issue or a service issue. The main concepts covered are images, "
"flavors, security groups, blocks storage, and instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml21(title)
#: ./doc/openstack-ops/ch_ops_user_facing.xml880(para)
#: ./doc/openstack-ops/ch_arch_cloud_controller.xml427(title)
msgid "Images"
msgstr "Képek"

#: ./doc/openstack-ops/ch_ops_user_facing.xml23(para)
msgid ""
"OpenStack images can often be thought of as \"virtual machine templates.\" "
"Images can also be standard installation media such as ISO images. "
"Essentially, they contain bootable file systems that are used to launch "
"instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml27(title)
msgid "Adding Images"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml28(para)
msgid ""
"Several premade images exist and can easily be imported into the Image "
"Service. A common image to add is the CirrOS image, which is very small and "
"used for testing purposes. To add this image, simply do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml34(para)
msgid ""
"The <code>glance image-create</code> command provides a large set of options"
" for working with your image. For example, the <code>min-disk</code> option "
"is useful for images that require root disks of a certain size (for example,"
" large Windows images). To view these options, do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml41(para)
msgid ""
"The <code>location</code> option is important to note. It does not copy the "
"entire image into the Image Service, but references an original location "
"where the image can be found. Upon launching an instance of that image, the "
"Image Service accesses the image from the location specified."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml47(para)
msgid ""
"The <code>copy-from</code> option copies the image from the location "
"specified into the <code>/var/lib/glance/images</code> directory. The same "
"thing is done when using the STDIN redirection with &lt; such as shown in "
"the example."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml52(para)
msgid "Run the following command to view the properties of existing images:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml57(title)
msgid "Sharing Images Between Projects"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml58(para)
msgid ""
"In a multitenant cloud environment, users sometimes want to share their "
"personal images or snapshots with other projects. This can be done on the "
"command line with the <placeholder-1/> tool by the owner of the image."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml62(para)
msgid "To share an image or snapshot with another project, do the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml66(para)
msgid "Obtain the UUID of the image:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml70(para)
msgid ""
"Obtain the UUID of the project with which you want to share your image. "
"Unfortunately, nonadmin users are unable to use the <placeholder-1/> command"
" to do this. The easiest solution is to obtain the UUID either from an "
"administrator of the cloud or from a user located in the project."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml78(para)
msgid "Once you have both pieces of information, run the glance command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml81(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml329(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml351(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml365(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml394(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml539(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml560(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml580(para)
msgid "For example:"
msgstr "Például:"

#: ./doc/openstack-ops/ch_ops_user_facing.xml84(para)
msgid ""
"Project 771ed149ef7e4b2b88665cc1c98f77ca will now have access to image "
"733d1c44-a2ea-414b-aca7-69decf20d810."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml91(title)
msgid "Deleting Images"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml92(para)
msgid "To delete an image, just execute:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml95(para)
msgid ""
"Deleting an image does not affect instances or snapshots that were based on "
"the image."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml100(title)
msgid "Other CLI Options"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml101(para)
msgid "A full set of options can be found using:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml103(para)
msgid ""
"or the <link href=\"http://docs.openstack.org/cli/quick-start/content"
"/glance-cli-reference.html\">OpenStack Image Service</link> CLI Guide. "
"(http://docs.openstack.org/cli/quick-start/content/glance-cli-"
"reference.html)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml109(title)
msgid "The Image Service and the Database"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml110(para)
msgid ""
"The only thing that the Image Service does not store in a database is the "
"image itself. The Image Service database has two main tables:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml115(para)
msgid "images"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml118(para)
msgid "image_properties"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml121(para)
msgid ""
"Working directly with the database and SQL queries can provide you with "
"custom lists and reports of images. Technically, you can update properties "
"about images through the database, although this is not generally "
"recommended."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml128(title)
msgid "Example Image Service Database Queries"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml129(para)
msgid ""
"One interesting example is modifying the table of images and the owner of "
"that image. This can be easily done if you simply display the unique ID of "
"the owner. This example goes one step further and displays the readable name"
" of the owner:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml138(para)
msgid "Another example is displaying all properties for a certain image:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml145(title)
msgid "Flavors"
msgstr "Változatok"

#: ./doc/openstack-ops/ch_ops_user_facing.xml146(para)
msgid ""
"Virtual hardware templates are called \"flavors\" in OpenStack, defining "
"sizes for RAM, disk, number of cores, and so on. The default install "
"provides five flavors. These are configurable by admin users (the rights may"
" also be delegated to other users by redefining the access controls for "
"<code>compute_extension:flavormanage</code> in "
"<code>/etc/nova/policy.json</code> on the <code>nova-api</code> server). To "
"get the list of available flavors on your system, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml162(para)
msgid ""
"The <code>nova flavor-create</code> command allows authorized users to "
"create new flavors. Additional flavor manipulation commands can be shown "
"with the command: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml164(para)
msgid ""
"Flavors define a number of parameters, resulting in the user having a choice"
" of what type of virtual machine to run—just like they would have if they "
"were purchasing a physical server. The table lists the elements that can be "
"set. Note in particular <literal>extra_specs</literal>, which can be used to"
" define free-form characteristics, giving a lot of flexibility beyond just "
"the size of RAM, CPU, and Disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml172(caption)
msgid "Flavor Parameters"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml179(emphasis)
msgid "Column"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml184(emphasis)
#: ./doc/openstack-ops/section_arch_example-neutron.xml157(th)
#: ./doc/openstack-ops/ch_ops_projects_users.xml153(th)
#: ./doc/openstack-ops/ch_ops_projects_users.xml495(td)
msgid "Description"
msgstr "Leírás"

#: ./doc/openstack-ops/ch_ops_user_facing.xml190(para)
msgid "ID"
msgstr "Azonosító"

#: ./doc/openstack-ops/ch_ops_user_facing.xml193(para)
msgid "A unique numeric ID."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml198(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml41(th)
msgid "Name"
msgstr "Név"

#: ./doc/openstack-ops/ch_ops_user_facing.xml201(para)
msgid ""
"A descriptive name, such as xx.size_name, is conventional but not required, "
"though some third-party tools may rely on it."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml207(para)
msgid "Memory_MB"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml210(para)
msgid "Virtual machine memory in megabytes."
msgstr "Virtuális gép memóriája megabájtokban."

#: ./doc/openstack-ops/ch_ops_user_facing.xml215(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml44(th)
msgid "Disk"
msgstr "Lemez"

#: ./doc/openstack-ops/ch_ops_user_facing.xml218(para)
msgid ""
"Virtual root disk size in gigabytes. This is an ephemeral disk the base "
"image is copied into. You don't use it when you boot from a persistent "
"volume. The \"0\" size is a special case that uses the native base image "
"size as the size of the ephemeral root volume."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml226(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml45(th)
msgid "Ephemeral"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml229(para)
msgid ""
"Specifies the size of a secondary ephemeral data disk. This is an empty, "
"unformatted disk and exists only for the life of the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml236(para)
msgid "Swap"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml239(para)
msgid "Optional swap space allocation for the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml244(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml305(para)
msgid "VCPUs"
msgstr "VCPU-k"

#: ./doc/openstack-ops/ch_ops_user_facing.xml247(para)
msgid "Number of virtual CPUs presented to the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml252(para)
msgid "RXTX_Factor"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml255(para)
msgid ""
"Optional property that allows created servers to have a different bandwidth "
"cap from that defined in the network they are attached to. This factor is "
"multiplied by the rxtx_base property of the network. Default value is 1.0 "
"(that is, the same as the attached network)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml263(para)
msgid "Is_Public"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml266(para)
msgid ""
"Boolean value that indicates whether the flavor is available to all users or"
" private. Private flavors do not get the current tenant assigned to them. "
"Defaults to True."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml272(para)
msgid "extra_specs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml275(para)
msgid ""
"Additional optional restrictions on which compute nodes the flavor can run "
"on. This is implemented as key-value pairs that must match against the "
"corresponding key-value pairs on compute nodes. Can be used to implement "
"things like special resources (such as flavors that can run only on compute "
"nodes with GPU hardware)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml285(title)
msgid "Private Flavors"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml286(para)
msgid ""
"A user might need a custom flavor that is uniquely-tuned for a project they "
"are working on. For example, the user might require 128 GB of memory. If you"
" create a new flavor as described above, the user would have access to the "
"custom flavor, but so will all other tenants in your cloud. Sometimes this "
"sharing isn't desirable. In this scenario, allowing all users to have access"
" to a flavor with 128 GB of memory might cause your cloud to reach full "
"capacity very quickly. To prevent this, you can restrict access to the "
"custom flavor using the <placeholder-1/> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml296(para)
msgid "To view a flavor's access list, do the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml299(title)
msgid "Best practices"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml300(para)
msgid ""
"Once access to a flavor has been restricted, no other projects besides the "
"ones granted explicit access will be able to see the flavor. This includes "
"the admin project. Make sure to add the admin project in addition to the "
"original project."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml305(para)
msgid ""
"It's also helpful to allocate a specific numeric range for custom and "
"private flavors. On UNIX-based systems, non-system accounts usually have a "
"UID starting at 500. A similar approach can be taken with custom flavors. "
"This helps you easily identify which flavors are custom, private, and public"
" for the entire cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml314(title)
msgid "How Do I Modify an Existing Flavor?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml315(para)
msgid ""
"The OpenStack dashboard simulates the ability to modify a flavor by deleting"
" an existing flavor and creating a new one with the same name."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml323(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml292(para)
msgid "Security Groups"
msgstr "Biztonsági csoportok"

#: ./doc/openstack-ops/ch_ops_user_facing.xml324(para)
msgid ""
"A common new-user issue with OpenStack is failing to set an appropriate "
"security group when launching an instance. As a result, the user is unable "
"to contact the instance on the network."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml327(para)
msgid ""
"Security groups are sets of IP filter rules that are applied to an "
"instance's networking. They are project specific and project members can "
"edit the default rules for their group and add new rules sets. All projects "
"have a \"default\" security group, which is applied to instances that have "
"no other security group defined. Unless changed, this security group denies "
"all incoming traffic."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml335(title)
msgid "General Security Groups Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml336(para)
msgid ""
"The <code>nova.conf</code> option <code>allow_same_net_traffic</code> (which"
" defaults to true) globally controls whether the rules apply to hosts that "
"share a network. When set to true, hosts on the same subnet are not filtered"
" and are allowed to pass all types of traffic between them. On a flat "
"network, this allows all instances from all projects unfiltered "
"communication. With VLAN networking, this allows access between instances "
"within the same project. If <code>allow_same_net_traffic</code> is set to "
"false, security groups are enforced for all connections. In this case, it is"
" possible for projects to simulate <code>allow_same_net_traffic</code> by "
"configuring their default security group to allow all traffic from their "
"subnet."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml351(para)
msgid ""
"As noted in the previous chapter, the number of rules per security group is "
"controlled by the <code>quota_security_group_rules</code> and the number of "
"allowed security groups per project is controlled by the "
"<code>quota_security_groups</code> quota."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml358(title)
msgid "End User Configuration of Security Groups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml359(para)
msgid ""
"Security groups for the current project can be found on the OpenStack "
"dashboard under <guilabel>Access &amp; Security</guilabel>. To see details "
"of an existing group, select the <guilabel>edit</guilabel> action for that "
"security group. Obviously, modifying existing groups can be done from this "
"<guilabel>edit</guilabel> interface. There is a <guibutton>Create Security "
"Group</guibutton> button on the main <guilabel>Access &amp; "
"Security</guilabel> page for creating new groups. We discuss the terms used "
"in these fields when we explain the command line equivalents."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml368(para)
msgid ""
"From the command line you can get a list of security groups for the project "
"you're acting in using the nova command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml378(para)
msgid "To view the details of the \"open\" security group:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml387(para)
msgid ""
"These rules are all \"allow\" type rules as the default is deny. The first "
"column is the IP protocol (one of icmp, tcp, or udp), and the second and "
"third columns specify the affected port range. The fourth column specifies "
"the IP range in CIDR format. This example shows the full port range for all "
"protocols allowed from all IPs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml393(para)
msgid ""
"When adding a new security group you should pick a descriptive but brief "
"name. This name shows up in brief descriptions of the instances that use it "
"where the longer description field often does not. Seeing that an instance "
"is using security group \"http\" is much easier to understand than "
"\"bobs_group\" or \"secgrp1.\""
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml399(para)
msgid ""
"As an example, let's create a security group that allows web traffic "
"anywhere on the Internet. We'll call this group \"global_http,\" which is "
"clear and reasonably concise, encapsulating what is allowed and from where. "
"From the command line, do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml411(para)
msgid ""
"This creates the empty security group. To make it do what we want we need to"
" add some rules."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml420(para)
msgid ""
"Note that the arguments are positional, and the \"from-port\" and \"to-"
"port\" arguments specify the allowed local port range connections. These "
"arguments are not indicating source and destination ports of the connection."
" More complex rule sets can be built up through multiple invocations of "
"<placeholder-1/>. For example, if you want to pass both http and https "
"traffic, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml433(para)
msgid ""
"Despite only outputting the newly added rule, this operation is additive:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml442(para)
msgid ""
"The inverse operation is called <placeholder-1/>, using the same format. "
"Whole security groups can be removed with <placeholder-2/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml445(para)
msgid ""
"To create security group rules for a cluster of instances, you want to use "
"SourceGroups."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml447(para)
msgid ""
"SourceGroups are a special dynamic way of defining the CIDR of allowed "
"sources. The user specifies a SourceGroup (security group name) and then all"
" the users' other instances using the specified SourceGroup are selected "
"dynamically. This dynamic selection alleviates the need for individual rules"
" to allow each new member of the cluster."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml452(para)
msgid ""
"Example usage: <code>nova secgroup-add-group-rule &lt;secgroup&gt; &lt"
";source-group&gt; &lt;ip-proto&gt; &lt;from-port&gt; &lt;to-port&gt;</code>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml454(para)
msgid ""
"The \"cluster\" rule allows ssh access from any other instance that uses the"
" \"global-http\" group."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml461(title)
#: ./doc/openstack-ops/ch_ops_backup_recovery.xml148(title)
#: ./doc/openstack-ops/ch_arch_storage.xml140(title)
#: ./doc/openstack-ops/glossary-terms.xml621(glossterm)
msgid "Block Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml462(para)
msgid ""
"OpenStack volumes are persistent block-storage devices that may be attached "
"and detached from instances, but they can be attached to only one instance "
"at a time. Similar to an external hard drive, they do not provide shared "
"storage in the way a network file system or object store does. It is left to"
" the operating system in the instance to put a file system on the block "
"device and mount it, or not."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml469(para)
msgid ""
"As with other removable disk technology, it is important that the operating "
"system is not trying to make use of the disk before removing it. On Linux "
"instances this typically involves unmounting any file systems mounted from "
"the volume. The OpenStack volume service cannot tell whether it is safe to "
"remove volumes from an instance, so it does what it is told. If a user tells"
" the volume service to detach a volume from an instance while it is being "
"written to, you can expect some level of file system corruption as well as "
"faults from whatever process within the instance was using the device."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml480(para)
msgid ""
"There is nothing OpenStack-specific in being aware of the steps needed to "
"access block devices from within the instance operating system, potentially "
"formatting them for first use and being cautious when removing them. What is"
" specific is how to create new volumes and attach and detach them from "
"instances. These operations can all be done from the "
"<guilabel>Volumes</guilabel> page of the dashboard or by using the "
"<placeholder-1/> command-line client."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml488(para)
msgid ""
"To add new volumes, you need only a name and a volume size in gigabytes. "
"Either put these into the <guilabel>create volume</guilabel> web form or use"
" the command line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml492(para)
msgid ""
"This creates a 10 GB volume named \"test-volume.\" To list existing volumes "
"and the instances they are connected to if any:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml501(para)
msgid ""
"OpenStack Block Storage also allows for creating snapshots of volumes. "
"Remember that this is a block level snapshot that is crash consistent, so it"
" is best if the volume is not connected to an instance when the snapshot is "
"taken and second best if the volume is not in use on the instance it is "
"attached to. If the volume is under heavy use, the snapshot may have an "
"inconsistent file system. In fact, by default, the volume service does not "
"take a snapshot of a volume that is attached to an image, though it can be "
"forced to. To take a volume snapshot either select <guilabel>Create "
"Snapshot</guilabel> from the actions column next to the volume name on the "
"dashboard volume page, or run this from the command line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml524(title)
msgid "Block Storage Creation Failures"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml525(para)
msgid ""
"If a user tries to create a volume and the volume immediately goes into an "
"error state, the best way to troubleshoot is to grep the cinder log files "
"for the volume's UUID. First try the log files on the cloud controller and "
"then try the storage node where the volume was attempted to be created:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml536(title)
#: ./doc/openstack-ops/ch_ops_maintenance.xml185(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml227(para)
msgid "Instances"
msgstr "Példányok"

#: ./doc/openstack-ops/ch_ops_user_facing.xml537(para)
msgid ""
"Instances are the running virtual machines within an OpenStack cloud. This "
"section deals with how to work with them and their underlying images, their "
"network properties, and how they are represented in the database."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml542(title)
msgid "Starting Instances"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml543(para)
msgid ""
"To launch an instance you need to select an image, a flavor, and a name. The"
" name needn't be unique, but your life is simpler if it is because many "
"tools will use the name in place of UUID so long as the name is unique. You "
"can start an instance from the dashboard from the <guibutton>Launch "
"Instance</guibutton> button on the <guilabel>Instances</guilabel> page or by"
" selecting the <guilabel>Launch</guilabel> action next to an image or "
"snapshot on the <guilabel>Images &amp; Snapshots</guilabel> page."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml552(para)
msgid "On the command line, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml554(para)
msgid ""
"There are a number of optional items that can be specified. You should read "
"the rest of this section before trying to start an instance, but this is the"
" base command that later details are layered upon."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml559(para)
msgid ""
"To delete instances from the dashboard select the <guilabel>Terminate "
"instance</guilabel> action next to the instance on the "
"<guilabel>Instances</guilabel> page. From the command line, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml563(para)
msgid ""
"It is important to note that powering off an instance does not terminate it "
"in the OpenStack sense."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml568(title)
msgid "Instance Boot Failures"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml569(para)
msgid ""
"If an instance fails to start and immediately moves to an error state, there"
" are a few different ways to track down what has gone wrong. Some of these "
"can be done with normal user access, while others require access to your log"
" server or compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml574(para)
msgid ""
"The simplest reasons for nodes to fail to launch are quota violations or the"
" scheduler being unable to find a suitable compute node on which to run the "
"instance. In these cases the error is apparent when you run a <code>nova "
"show</code> on the faulted instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml608(para)
msgid ""
"In this case, looking at the \"fault\" message shows NoValidHost, indicating"
" that the scheduler was unable to match the instance requirements."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml611(para)
msgid ""
"If <code>nova show</code> does not sufficiently explain the failure, "
"searching for the instance UUID in the <code>nova-compute.log</code> on the "
"compute node it was scheduled on or the <code>nova-scheduler.log</code> on "
"your scheduler hosts is a good place to start looking for lower-level "
"problems."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml618(para)
msgid ""
"Using <code>nova show</code> as an admin user will show the compute node the"
" instance was scheduled on as <code>hostId</code>. If the instance failed "
"during scheduling this field is blank."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml624(title)
msgid "Using Instance-specific Data"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml625(para)
msgid ""
"There are two main types of instance-specific data: metadata and user data."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml627(title)
msgid "Instance Metadata"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml628(para)
msgid ""
"For Compute, instance metadata is a collection of key-value pairs associated"
" with an instance. Compute reads and writes to these key-value pairs any "
"time during the instance lifetime, from inside and outside the instance, "
"when the end user uses the Compute API to do so. However, you cannot query "
"the instance-associated key-value pairs with the metadata service that is "
"compatible with the Amazon EC2 metadata service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml637(para)
msgid ""
"For an example of instance metadata, users can generate and register ssh "
"keys using the nova command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml641(para)
msgid ""
"This creates a key named <placeholder-1/>, which you can associate with "
"instances. The file <filename>mykey.pem</filename> is the private key, which"
" should be saved to a secure location because it allows root access to "
"instances the <placeholder-2/> key is associated with."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml646(para)
msgid "Use this command to register an existing key with OpenStack:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml649(para)
msgid ""
"You must have the matching private key to access instances associated with "
"this key."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml651(para)
msgid ""
"To associate a key with an instance on boot, add <code>--key_name "
"mykey</code> to your command line. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml655(para)
msgid ""
"When booting a server, you can also add arbitrary metadata so that you can "
"more easily identify it among other running instances. Use the "
"<code>--meta</code> option with a key=value pair, where you can make up the "
"string for both the key and the value. For example, you could add a "
"description and also the creator of the server:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml665(para)
msgid ""
"When viewing the server information, you can see the metadata included on "
"the metadata line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml696(title)
msgid "Instance User Data"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml697(para)
msgid ""
"The <code>user-data</code> key is a special key in the metadata service that"
" holds a file that cloud-aware applications within the guest instance can "
"access. For example <link title=\"OpenStack Image Service\" "
"href=\"https://help.ubuntu.com/community/CloudInit\">cloudinit</link> "
"(https://help.ubuntu.com/community/CloudInit) is an open source package from"
" Ubuntu, but available in most distributions, that handles early "
"initialization of a cloud instance that makes use of this user data."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml707(para)
msgid ""
"This user data can be put in a file on your local system and then passed in "
"at instance creation with the flag <code>--user-data &lt;user-data-"
"file&gt;</code>. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml712(para)
msgid ""
"To understand the difference between user data and metadata, realize that "
"user data is created before an instance is started. User data is accessible "
"from within the instance when it is running. User data can be used to store "
"configuration, a script, or anything the tenant wants."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml720(title)
msgid "File Injection"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml721(para)
msgid ""
"Arbitrary local files can also be placed into the instance file system at "
"creation time by using the <code>--file &lt;dst-path=src-path&gt;</code> "
"option. You may store up to five files. For example, let's say you have a "
"special <filename>authorized_keys</filename> file named "
"special_authorized_keysfile that for some reason you want to put on the "
"instance instead of using the regular ssh key injection. In this case, you "
"can use the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml734(title)
msgid "Associating Security Groups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml735(para)
msgid ""
"Security groups, as discussed earlier, are typically required to allow "
"network traffic to an instance, unless the default security group for a "
"project has been modified to be more permissive."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml739(para)
msgid ""
"Adding security groups is typically done on instance boot. When launching "
"from the dashboard you do this on the <guilabel>Access &amp; "
"Security</guilabel> tab of the <guilabel>Launch Instance</guilabel> dialog. "
"When launching from the command line, append <code>--security-groups</code> "
"with a comma-separated list of security groups."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml745(para)
msgid ""
"It is also possible to add and remove security groups when an instance is "
"running. Currently this is only available through the command-line tools. "
"Here is an example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml752(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml175(para)
msgid "Floating IPs"
msgstr "Lebegő IP-k"

#: ./doc/openstack-ops/ch_ops_user_facing.xml753(para)
msgid ""
"Where floating IPs are configured in a deployment, each project will have a "
"limited number of floating IPs controlled by a quota. However, these need to"
" be allocated to the project from the central pool prior to their "
"use—usually by the administrator of the project. To allocate a floating IP "
"to a project, use the <guibutton>Allocate IP to Project</guibutton> button "
"on the <guilabel>Access &amp; Security</guilabel> page of the dashboard. The"
" command line can also be used:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml763(para)
msgid ""
"Once allocated, a floating IP can be assigned to running instances from the "
"dashboard either by selecting <guibutton>Associate Floating IP</guibutton> "
"from the actions drop-down next to the IP on the <guilabel>Access &amp; "
"Security</guilabel> page or by making this selection next to the instance "
"you want to associate it with on the <guilabel>Instances</guilabel> page. "
"The inverse action, <guibutton>Dissociate Floating IP</guibutton>, is "
"available only from the <guilabel>Access &amp; Security</guilabel> page and "
"not from the <guilabel>Instances</guilabel> page."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml773(para)
msgid ""
"To associate or disassociate a floating IP with a server from the command "
"line, use the following commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml780(title)
msgid "Attaching Block Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml781(para)
msgid ""
"You can attach block storage to instances from the dashboard on the "
"<guilabel>Volumes</guilabel> page. Click the <guibutton>Edit "
"Attachments</guibutton> action next to the volume you want to attach."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml785(para)
msgid "To perform this action from command line, run the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml788(para)
msgid ""
"You can also specify block device mapping at instance boot time through the "
"nova command-line client with this option set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml791(para)
msgid ""
"The block device mapping format is <code>&lt;dev-"
"name&gt;=&lt;id&gt;:&lt;type&gt;:&lt;size(GB)&gt;:&lt;delete-on-"
"terminate&gt;</code>, where:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml796(term)
msgid "dev-name"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml798(para)
msgid ""
"A device name where the volume is attached in the system at "
"<code>/dev/<replaceable>dev_name</replaceable></code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml804(term)
msgid "id"
msgstr "Azonosító"

#: ./doc/openstack-ops/ch_ops_user_facing.xml806(para)
msgid ""
"The ID of the volume to boot from, as shown in the output of nova volume-"
"list."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml811(term)
msgid "type"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml813(para)
msgid ""
"Either <literal>snap</literal>, which means that the volume was created from"
" a snapshot, or anything other than <literal>snap</literal> (a blank string "
"is valid). In the example above, the volume was not created from a snapshot,"
" so we leave this field blank in our example below."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml823(term)
msgid "size (GB)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml825(para)
msgid ""
"The size of the volume in gigabytes. It is safe to leave this blank and have"
" the Compute Service infer the size."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml831(term)
msgid "delete-on-terminate"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml833(para)
msgid ""
"A boolean to indicate whether the volume should be deleted when the instance"
" is terminated. True can be specified as <literal>True</literal> or "
"<literal>1</literal>. False can be specified as <literal>False</literal> or "
"<literal>0</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml841(para)
msgid ""
"The following command will boot a new instance and attach a volume at the "
"same time. The volume of ID 13 will be attached as <code>/dev/vdc</code>. It"
" is not a snapshot, does not specify a size, and will not be deleted when "
"the instance is terminated:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml848(para)
msgid ""
"If you have previously prepared block storage with a bootable file system "
"image, it is even possible to boot from persistent block storage. The "
"following command boots an image from the specified volume. It is similar to"
" the previous command, but the image is omitted and the volume is now "
"attached as <code>/dev/vda</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml857(para)
msgid ""
"Read more detailed instructions for launching an instance from a bootable "
"volume in the <link href=\"http://docs.openstack.org/user-"
"guide/content/boot_from_volume.html\">OpenStack End User Guide</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml861(para)
msgid ""
"To boot normally from an image and attach block storage, map to a device "
"other than vda. You can find instructions for launching an instance and "
"attaching a volume to the instance and for copying the image to the attached"
" volume in the <link href=\"http://docs.openstack.org/user-"
"guide/content/dashboard_launch_instances_from_volume.html\">OpenStack End "
"User Guide</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml868(title)
msgid "Taking Snapshots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml869(para)
msgid ""
"The OpenStack snapshot mechanism allows you to create new images from "
"running instances. This is very convenient for upgrading base images or for "
"taking a published image and customizing it for local use. To snapshot a "
"running instance to an image using the CLI, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml875(para)
msgid ""
"The dashboard interface for snapshots can be confusing because the "
"<guilabel>Images &amp; Snapshots</guilabel> page splits content up into "
"several areas:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml883(para)
msgid "Instance snapshots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml886(para)
msgid "Volume snapshots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml889(para)
msgid ""
"However, an instance snapshot <emphasis>is</emphasis> an image. The only "
"difference between an image that you upload directly to the Image Service "
"and an image that you create by snapshot is that an image created by "
"snapshot has additional properties in the glance database. These properties "
"are found in the image_properties table and include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml899(th)
msgid "name"
msgstr "név"

#: ./doc/openstack-ops/ch_ops_user_facing.xml900(th)
#: ./doc/openstack-ops/ch_ops_projects_users.xml350(replaceable)
msgid "value"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml905(para)
msgid "image_type"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml906(para)
#: ./doc/openstack-ops/ch_ops_user_facing.xml921(para)
#: ./doc/openstack-ops/glossary-terms.xml4238(glossterm)
msgid "snapshot"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml909(para)
msgid "instance_uuid"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml910(para)
msgid "&lt;uuid of instance that was snapshotted&gt;"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml914(para)
msgid "base_image_ref"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml915(para)
msgid "&lt;uuid of original image of instance that was snapshotted&gt;"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml920(para)
msgid "image_location"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml926(title)
msgid "Live snapshots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml927(para)
msgid ""
"Live snapshots is a feature that allows users to snapshot the running "
"virtual machines without pausing them. These snapshots are simply disk-only "
"snapshots. Snapshotting an instance can now be performed with no downtime "
"(assuming QEMU 1.3+ and libvirt 1.0+ are used)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml932(title)
msgid "Ensuring snapshots are consistent"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml933(para)
msgid ""
"The following section is from Sébastien Han's <link title=\"OpenStack Image "
"Service\" href=\"http://www.sebastien-han.fr/blog/2012/12/10/openstack-"
"perform-consistent-snapshots/\">OpenStack: Perform Consistent Snapshots blog"
" entry</link> (http://www.sebastien-han.fr/blog/2012/12/10/openstack-"
"perform-consistent-snapshots/)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml939(para)
msgid ""
"A snapshot captures the state of the file system, but not the state of the "
"memory. Therefore, to ensure your snapshot contains the data that you want, "
"before your snapshot you need to ensure that:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml945(para)
msgid "Running programs have written their contents to disk"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml949(para)
msgid ""
"The file system does not have any \"dirty\" buffers: where programs have "
"issued the command to write to disk, but the operating system has not yet "
"done the write"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml955(para)
msgid ""
"To ensure that important services have written their contents to disk (such "
"as databases), we recommend that you read the documentation for those "
"applications to determine what commands to issue to have them sync their "
"contents to disk. If you are unsure how to do this, the safest approach is "
"to simply stop these running services normally."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml962(para)
msgid ""
"To deal with the \"dirty\" buffer issue, we recommend using the sync command"
" before snapshotting:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml965(para)
msgid ""
"Running <code>sync</code> writes dirty buffers (buffered blocks that have "
"been modified but not written yet to the disk block) to disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml968(para)
msgid ""
"Just running <code>sync</code> is not enough to ensure that the file system "
"is consistent. We recommend that you use the <code>fsfreeze</code> tool, "
"which halts new access to the file system, and create a stable image on disk"
" that is suitable for snapshotting. The <code>fsfreeze</code> tool supports "
"several file systems, including ext3, ext4, and XFS. If your virtual machine"
" instance is running on Ubuntu, install the util-linux package to get "
"fsfreeze:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml978(para)
msgid ""
"If your operating system doesn't have a version of fsfreeze available, you "
"can use xfs_freeze instead, which is available on Ubuntu in the xfsprogs "
"package. Despite the \"xfs\" in the name, xfs_freeze also works on ext3 and "
"ext4 if you are using a Linux kernel version 2.6.29 or greater, since it "
"works at the virtual file system (VFS) level starting at 2.6.29. The "
"xfs_freeze version supports the same command-line arguments as fsfreeze."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml987(para)
msgid ""
"Consider the example where you want to take a snapshot of a persistent block"
" storage volume, detected by the guest operating system as /dev/vdb and "
"mounted on /mnt. The fsfreeze command accepts 2 arguments:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml994(para)
msgid "-f: freeze the system"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml997(para)
msgid "-u: thaw (unfreeze) the system"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1000(para)
msgid ""
"To freeze the volume in preparation for snapshotting, you would do the "
"following, as root, inside the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1004(para)
msgid ""
"You <emphasis role=\"bold\">must mount the file system</emphasis> before you"
" run the <placeholder-1/> command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1007(para)
msgid ""
"When the \"fsfreeze -f\" command is issued, all ongoing transactions in the "
"file system are allowed to complete, new write system calls are halted, and "
"other calls that modify the file system are halted. Most importantly, all "
"dirty data, metadata, and log information are written to disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1013(para)
msgid ""
"Once the volume has been frozen, do not attempt to read from or write to the"
" volume, as these operations hang. The operating system stops every I/O "
"operation and any I/O attempts are delayed until the file system has been "
"unfrozen."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1018(para)
msgid ""
"Once you have issued the fsfreeze command, it is safe to perform the "
"snapshot. For example, if your instance was named mon-instance and you "
"wanted to snapshot it to an image named mon-snapshot, you could now run the "
"following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1024(para)
msgid ""
"When the snapshot is done, you can thaw the file system with the following "
"command, as root, inside of the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1028(para)
msgid ""
"If you want to backup the root file system, you can't simply run the command"
" above because it will freeze the prompt. Instead, run the following one-"
"liner, as root, inside the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1039(title)
msgid "Instances in the Database"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1040(para)
msgid ""
"While instance information is stored in a number of database tables, the "
"table you most likely need to look at in relation to user instances is the "
"\"instances\" table."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1044(para)
msgid ""
"The instances table carries most of the information related to both running "
"and deleted instances. It has a bewildering array of fields; for an "
"exhaustive list, look at the database. These are the most useful fields for "
"operators looking to form queries:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1051(para)
msgid ""
"The deleted field is set to 1 if the instance has been deleted and NULL if "
"it has not been deleted— this field is important for excluding deleted "
"instances from your queries."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1055(para)
msgid ""
"The uuid field is the UUID of the instance and is used throughout other "
"tables in the database as a foreign key. This ID is also reported in logs, "
"the dashboard, and command-line tools to uniquely identify an instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1060(para)
msgid ""
"A collection of foreign keys are available to find relations to the "
"instance. The most useful of these—user_id and project_id—are the UUIDs of "
"the user who launched the instance and the project it was launched in."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1064(para)
msgid "The host field tells which compute node is hosting the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1066(para)
msgid ""
"The hostname field holds the name of the instance when it is launched. The "
"display-name is initially the same as hostname but can be reset using the "
"nova rename command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1071(para)
msgid ""
"A number of time-related fields are useful for tracking when state changes "
"happened on an instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1075(para)
msgid "created_at"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1078(para)
msgid "updated_at"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1081(para)
msgid "deleted_at"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1084(para)
msgid "scheduled_at"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1087(para)
msgid "launched_at"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1090(para)
msgid "terminated_at"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1095(title)
msgid "Good Luck!"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1096(para)
msgid ""
"This section was intended as a brief introduction to some of the most useful"
" of many OpenStack commands. For an exhaustive list, please refer to the "
"<link href=\"http://docs.openstack.org/user-guide-admin/content/\">Admin "
"User Guide</link>, and for additional hints and tips please see the <link "
"href=\"http://docs.openstack.org/admin-guide-cloud/content/\">Cloud Admin "
"Guide</link>. We hope your users remain happy and recognize your hard work! "
"(For more hard work, turn the page to the next chapter, where we discuss the"
" system-facing operations: maintenance, failures and debugging.)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml14(title)
msgid "Upstream OpenStack"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml15(para)
msgid ""
"OpenStack is founded on a thriving community that is a source of help and "
"welcomes your contributions. This chapter details some of the ways you can "
"interact with the others involved."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml20(title)
msgid "Getting Help"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml21(para)
msgid ""
"There are several avenues available for seeking assistance. The quickest way"
" is to help the community help you. Search the Q&amp;A sites, mailing list "
"archives, and bug lists for issues similar to yours. If you can't find "
"anything, follow the directions for reporting bugs or use one of the "
"channels for support, which are listed below."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml27(para)
msgid ""
"Your first port of call should be the official OpenStack documentation, "
"found on http://docs.openstack.org."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml29(para)
msgid "You can get questions answered on the ask.openstack.org site."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml30(para)
msgid ""
"<link href=\"https://wiki.openstack.org/wiki/Mailing_Lists\">Mailing "
"Lists</link> (https://wiki.openstack.org/wiki/Mailing_Lists) are also a "
"great place to get help. The wiki page has more information about the "
"various lists. As an operator, the main lists you should be aware of are:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml40(para)
msgid ""
"<link href=\"http://lists.openstack.org/cgi-"
"bin/mailman/listinfo/openstack\">General list</link>: "
"<code>openstack@lists.openstack.org</code>. The scope of this list is the "
"current state of OpenStack. This is a very high-traffic mailing list, with "
"many, many emails per day."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml50(para)
msgid ""
"<link href=\"http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-"
"operators\">Operators list</link>: <code>openstack-"
"operators@lists.openstack.org.</code> This list is intended for discussion "
"among existing OpenStack cloud operators, such as yourself. Currently, this "
"list is relatively low traffic, on the order of one email a day."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml61(para)
msgid ""
"<link href=\"http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-"
"dev\">Development list</link>: <code>openstack-"
"dev@lists.openstack.org</code>. The scope of this list is the future state "
"of OpenStack. This is a high-traffic mailing list, with multiple emails per "
"day."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml71(para)
msgid ""
"We recommend that you subscribe to the general list and the operator list, "
"although you must set up filters to manage the volume for the general list. "
"You'll also find links to the mailing list archives on the mailing list wiki"
" page where you can search through the discussions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml76(para)
msgid ""
"<link href=\"https://wiki.openstack.org/wiki/IRC\">Multiple IRC "
"channels</link> (https://wiki.openstack.org/wiki/IRC) are available for "
"general questions and developer discussions. The general discussion channel "
"is <code>#openstack</code> on <code>irc.freenode.net</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml86(title)
msgid "Reporting Bugs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml87(para)
msgid ""
"As an operator, you are in a very good position to report unexpected "
"behavior with your cloud. Since OpenStack is flexible, you may be the only "
"individual to report a particular issue. Every issue is important to fix, so"
" it is essential to learn how to easily submit a bug report."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml92(para)
msgid ""
"All OpenStack projects use <link "
"href=\"http://launchpad.net/\">Launchpad</link> for bug tracking. You'll "
"need to create an account on Launchpad before you can submit a bug report."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml97(para)
msgid ""
"Once you have a Launchpad account, reporting a bug is as simple as "
"identifying the project or projects that are causing the issue. Sometimes "
"this is more difficult than expected, but those working on the bug triage "
"are happy to help relocate issues if they are not in the right place "
"initially."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml104(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/nova/+filebug\">nova</link> "
"(https://bugs.launchpad.net/nova/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml109(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"novaclient/+filebug\">python-novaclient</link> (https://bugs.launchpad.net"
"/python-novaclient/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml114(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/swift/+filebug\">swift</link> "
"(https://bugs.launchpad.net/swift/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml119(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"swiftclient/+filebug\">python-swiftclient</link> (https://bugs.launchpad.net"
"/python-swiftclient/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml125(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/glance/+filebug\">glance</link> "
"(https://bugs.launchpad.net/glance/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml130(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"glanceclient/+filebug\">python-glanceclient</link> "
"(https://bugs.launchpad.net/python-glanceclient/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml136(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/keystone/+filebug\">keystone</link> "
"(https://bugs.launchpad.net/keystone/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml141(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"keystoneclient/+filebug\">python-keystoneclient</link> "
"(https://bugs.launchpad.net/python-keystoneclient/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml147(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/neutron/+filebug\">neutron</link> "
"(https://bugs.launchpad.net/neutron/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml152(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"neutronclient/+filebug\">python-neutronclient</link> "
"(https://bugs.launchpad.net/python-neutronclient/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml158(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/cinder/+filebug\">cinder</link> "
"(https://bugs.launchpad.net/cinder/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml163(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"cinderclient/+filebug\">python-cinderclient</link> "
"(https://bugs.launchpad.net/python-cinderclient/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml169(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/horizon/+filebug\">horizon</link> "
"(https://bugs.launchpad.net/horizon/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml174(para)
msgid ""
"Report a bug with the <link href=\"http://bugs.launchpad.net/openstack-"
"manuals/+filebug\">documentation</link> (http://bugs.launchpad.net"
"/openstack-manuals/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml179(para)
msgid ""
"Report a bug with the <link href=\"http://bugs.launchpad.net/openstack-api-"
"site/+filebug\">API documentation</link> (http://bugs.launchpad.net"
"/openstack-api-site/+filebug)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml185(para)
msgid ""
"To write a good bug report, the following process is essential. First, "
"search for the bug to make sure there is no bug already filed for the same "
"issue. If you find one, be sure to click on \"This bug affects X people. "
"Does this bug affect you?\" If you can't find the issue, then enter the "
"details of your report. It should at least include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml193(para)
msgid ""
"The release, or milestone, or commit ID corresponding to the software that "
"you are running."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml198(para)
msgid "The operating system and version where you've identified the bug."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml202(para)
msgid "Steps to reproduce the bug, including what went wrong."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml206(para)
msgid "Description of the expected results instead of what you saw."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml210(para)
msgid "Portions of your log files so that you include only relevant excerpts."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml214(para)
msgid "When you do this, the bug is created with:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml217(para)
msgid "Status: <emphasis>New</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml221(para)
msgid ""
"In the bug comments, you can contribute instructions on how to fix a given "
"bug, and set it to <emphasis>Triaged</emphasis>. Or you can directly fix it:"
" assign the bug to yourself, set it to <emphasis>In progress</emphasis>, "
"branch the code, implement the fix, and propose your change for merging. But"
" let's not get ahead of ourselves, there are bug triaging tasks as well."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml228(title)
msgid "Confirming and Prioritizing"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml229(para)
msgid ""
"This stage is about checking that a bug is real and assessing its impact. "
"Some of these steps require bug supervisor rights (usually limited to core "
"teams). If the bug lacks information to properly reproduce or assess the "
"importance of the bug, the bug is set to:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml237(para)
msgid "Status: <emphasis>Incomplete</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml241(para)
msgid ""
"Once you have reproduced the issue (or are 100 percent confident that this "
"is indeed a valid bug) and have permissions to do so, set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml246(para)
msgid "Status: <emphasis>Confirmed</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml250(para)
msgid "Core developers also prioritize the bug, based on its impact:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml254(para)
msgid "Importance: &lt;Bug impact&gt;"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml257(para)
msgid "The bug impacts are categorized as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml260(para)
msgid ""
"<emphasis>Critical</emphasis> if the bug prevents a key feature from working"
" properly (regression) for all users (or without a simple workaround) or "
"results in data loss."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml267(para)
msgid ""
"<emphasis>High</emphasis> if the bug prevents a key feature from working "
"properly for some users (or with a workaround)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml273(para)
msgid ""
"<emphasis>Medium</emphasis> if the bug prevents a secondary feature from "
"working properly."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml278(para)
msgid "<emphasis>Low</emphasis> if the bug is mostly cosmetic."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml283(para)
msgid ""
"<emphasis>Wishlist</emphasis> if the bug is not really a bug but rather a "
"welcome change in behavior."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml288(para)
msgid ""
"If the bug contains the solution, or a patch, set the bug status to "
"<emphasis>Triaged</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml292(title)
msgid "Bug Fixing"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml293(para)
msgid ""
"At this stage, a developer works on a fix. During that time, to avoid "
"duplicating the work, the developer should set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml297(para)
msgid "Status: <emphasis>In progress</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml301(para)
msgid "Assignee: &lt;yourself&gt;"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml304(para)
msgid ""
"When the fix is ready, the developer proposes a change and gets the change "
"reviewed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml308(title)
msgid "After the Change Is Accepted"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml309(para)
msgid ""
"After the change is reviewed, accepted, and lands in master, it "
"automatically moves to:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml313(para)
msgid "Status: <emphasis>Fix committed</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml317(para)
msgid ""
"When the fix makes it into a milestone or release branch, it automatically "
"moves to:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml321(para)
msgid "Milestone: Milestone the bug was fixed in"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml325(para)
msgid "Status: <emphasis>Fix released</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml332(title)
msgid "Join the OpenStack Community"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml333(para)
msgid ""
"Since you've made it this far in the book, you should consider becoming an "
"official individual member of the community and <link "
"href=\"https://www.openstack.org/join/\">join the OpenStack "
"Foundation</link> (https://www.openstack.org/join/). The OpenStack "
"Foundation is an independent body providing shared resources to help achieve"
" the OpenStack mission by protecting, empowering, and promoting OpenStack "
"software and the community around it, including users, developers, and the "
"entire ecosystem. We all share the responsibility to make this community the"
" best it can possibly be, and signing up to be a member is the first step to"
" participating. Like the software, individual membership within the "
"OpenStack Foundation is free and accessible to anyone."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml347(title)
msgid "How to Contribute to the Documentation"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml348(para)
msgid ""
"OpenStack documentation efforts encompass operator and administrator docs, "
"API docs, and user docs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml350(para)
msgid ""
"The genesis of this book was an in-person event, but now that the book is in"
" your hands we want you to contribute to it. OpenStack documentation follows"
" the coding principles of iterative work, with bug logging, investigating, "
"and fixing."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml355(para)
msgid ""
"Just like the code, the <link "
"href=\"http://docs.openstack.org\">docs.openstack.org</link> site is updated"
" constantly using the Gerrit review system, with source stored in GitHub in "
"the <link href=\"http://github.com/openstack/openstack-manuals/\">openstack-"
"manuals</link> (http://github.com/openstack/openstack-manuals/) repository "
"and the <link href=\"http://github.com/openstack/api-site/\">api-site</link>"
" (http://github.com/openstack/api-site/) repository, in DocBook format."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml367(para)
msgid ""
"To review the documentation before it's published, go to the OpenStack "
"Gerrit server at <link "
"href=\"http://review.openstack.org\">review.openstack.org</link> and search "
"for <link "
"href=\"https://review.openstack.org/#/q/status:open+project:openstack"
"/openstack-manuals,n,z\">project:openstack/openstack-manuals</link> or <link"
" href=\"https://review.openstack.org/#/q/status:open+project:openstack/api-"
"site,n,z\">project:openstack/api-site</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml378(para)
msgid ""
"See the <link href=\"https://wiki.openstack.org/wiki/How_To_Contribute\">How"
" To Contribute</link> (https://wiki.openstack.org/wiki/How_To_Contribute) "
"page on the wiki for more information on the steps you need to take to "
"submit your first documentation review or change."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml387(title)
msgid "Security Information"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml388(para)
msgid ""
"As a community, we take security very seriously and follow a specific "
"process for reporting potential issues. We vigilantly pursue fixes and "
"regularly eliminate exposures. You can report security issues you discover "
"through this specific process. The OpenStack Vulnerability Management Team "
"is a very small group of experts in vulnerability management drawn from the "
"OpenStack community. The team's job is facilitating the reporting of "
"vulnerabilities, coordinating security fixes and handling progressive "
"disclosure of the vulnerability information. Specifically, the team is "
"responsible for the following functions:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml401(para)
msgid ""
"Vulnerability management: All vulnerabilities discovered by community "
"members (or users) can be reported to the Team."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml406(para)
msgid ""
"Vulnerability tracking: The Team will curate a set of vulnerability related "
"issues in the issue tracker. Some of these issues are private to the Team "
"and the affected product leads, but once remediation is in place, all "
"vulnerabilities are public."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml413(para)
msgid ""
"Responsible disclosure: As part of our commitment to work with the security "
"community, the team ensures that proper credit is given to security "
"researchers who responsibly report issues in OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml419(para)
msgid ""
"We provide two ways to report issues to the OpenStack Vulnerability "
"Management Team, depending on how sensitive the issue is:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml424(para)
msgid ""
"Open a bug in Launchpad and mark it as a \"security bug.\" This makes the "
"bug private and accessible to only the Vulnerability Management Team."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml429(para)
msgid ""
"If the issue is extremely sensitive, send an encrypted email to one of the "
"team's members. Find their GPG keys at <link "
"href=\"http://www.openstack.org/projects/openstack-security/\">OpenStack "
"Security</link> (http://www.openstack.org/projects/openstack-security/)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml437(para)
msgid ""
"You can find the full list of security-oriented teams you can join at <link "
"href=\"https://wiki.openstack.org/wiki/SecurityTeams\">Security Teams</link>"
" (http://wiki.openstack.org/SecurityTeams). The vulnerability management "
"process is fully documented at <link "
"href=\"https://wiki.openstack.org/wiki/VulnerabilityManagement\">Vulnerability"
" Management</link> "
"(https://wiki.openstack.org/wiki/VulnerabilityManagement)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml447(title)
msgid "Finding Additional Information"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml448(para)
msgid ""
"In addition to this book, there are many other sources of information about "
"OpenStack. The <link href=\"http://www.openstack.org\">OpenStack "
"website</link> (http://www.openstack.org) is a good starting point, with "
"<link href=\"http://docs.openstack.org\">OpenStack Docs</link> "
"(http://docs.openstack.org) and <link "
"href=\"http://api.openstack.org\">OpenStack API Docs</link> "
"(http://api.openstack.org) providing technical documentation about "
"OpenStack. The <link href=\"https://wiki.openstack.org\">OpenStack "
"wiki</link> contains a lot of general information that cuts across the "
"OpenStack projects, including a list of <link "
"href=\"https://wiki.openstack.org/wiki/OperationsTools\">recommended "
"tools</link> (https://wiki.openstack.org/wiki/OperationsTools ). Finally, "
"there are a number of blogs aggregated at <link "
"href=\"http://planet.openstack.org\">Planet OpenStack</link> "
"(http://planet.openstack.org)."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml19(title)
msgid "Acknowledgments"
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml20(para)
msgid ""
"The OpenStack Foundation supported the creation of this book with plane "
"tickets to Austin, lodging (including one adventurous evening without power "
"after a windstorm), and delicious food. For about USD $10,000, we could "
"collaborate intensively for a week in the same room at the Rackspace Austin "
"office. The authors are all members of the OpenStack Foundation, which you "
"can join. Go to the <link href=\"https://www.openstack.org/join\">Foundation"
" web site</link> at <uri>http://openstack.org/join</uri>."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml28(para)
msgid ""
"We want to acknowledge our excellent host Rackers at Rackspace in Austin:"
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml32(para)
msgid ""
"Emma Richards of Rackspace Guest Relations took excellent care of our lunch "
"orders and even set aside a pile of sticky notes that had fallen off the "
"walls."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml37(para)
msgid ""
"Betsy Hagemeier, a Fanatical Executive Assistant, took care of a room "
"reshuffle and helped us settle in for the week."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml41(para)
msgid ""
"The Real Estate team at Rackspace in Austin, also known as \"The Victors,\" "
"were super responsive."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml45(para)
msgid ""
"Adam Powell in Racker IT supplied us with bandwidth each day and second "
"monitors for those of us needing more screens."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml49(para)
msgid ""
"On Wednesday night we had a fun happy hour with the Austin OpenStack Meetup "
"group and Racker Katie Schmidt took great care of our group."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml54(para)
msgid "We also had some excellent input from outside of the room:"
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml57(para)
msgid ""
"Tim Bell from CERN gave us feedback on the outline before we started and "
"reviewed it mid-week."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml61(para)
msgid ""
"Sébastien Han has written excellent blogs and generously gave his permission"
" for re-use."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml65(para)
msgid ""
"Oisin Feeley read it, made some edits, and provided emailed feedback right "
"when we asked."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml69(para)
msgid ""
"Inside the book sprint room with us each day was our book sprint facilitator"
" Adam Hyde. Without his tireless support and encouragement, we would have "
"thought a book of this scope was impossible in five days. Adam has proven "
"the book sprint method effectively again and again. He creates both tools "
"and faith in collaborative authoring at <link "
"href=\"http://www.booksprints.net/\">www.booksprints.net</link>."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml77(para)
msgid ""
"We couldn't have pulled it off without so much supportive help and "
"encouragement."
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml12(title)
msgid "Conventions"
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml13(para)
msgid "The OpenStack documentation uses several typesetting conventions:"
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml18(title)
msgid "Admonitions"
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml19(para)
msgid "Admonitions take three forms:"
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml23(para)
msgid ""
"This is a note. The information in a note is usually in the form of a handy "
"tip or reminder."
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml29(para)
msgid ""
"This is important. The information in an important admonition is something "
"you must be aware of before moving on."
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml35(para)
msgid ""
"This is a warning. The information in warnings is critical. Warnings provide"
" additional information about risk of data loss or security issues."
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml44(title)
msgid "Command prompts"
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml45(para)
msgid ""
"Commands prefixed with the <literal>#</literal> prompt are to be executed by"
" the <literal>root</literal> user. These examples can also be executed using"
" the <placeholder-1/> command, if available."
msgstr ""

#: ./doc/openstack-ops/section_conventions.xml51(para)
msgid ""
"Commands prefixed with the <literal>$</literal> prompt can be executed by "
"any user, including <literal>root</literal>."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml337(None)
msgid ""
"@@image: 'figures/ha_network_diagram_basic.png'; "
"md5=0933519461caf3a35e0613e77961de9f"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml352(None)
msgid ""
"@@image: 'figures/ha_network_diagram_performance.png'; "
"md5=a5d89c23d17137a1674ce928aa9160da"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml368(None)
msgid ""
"@@image: 'figures/ha_node_controller.png'; "
"md5=e8fae70e07357ce16e23570d373781bd"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml376(None)
msgid ""
"@@image: 'figures/ha_node_compute.png'; md5=401ed8ee723b1c24310ec3e9905cd7d1"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml384(None)
msgid ""
"@@image: 'figures/ha_node_network.png'; md5=62b33a2068665965d628491c26d355c6"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml392(None)
msgid ""
"@@image: 'figures/ha_node_storage.png'; md5=6a675ff9a03c8951dbc05e7ffa66f7f0"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml14(title)
msgid "Example Architecture - OpenStack Networking"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml15(para)
msgid ""
"This chapter provides an example architecture using OpenStack Networking, "
"also known as the Neutron project, in a highly available environment."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml17(title)
#: ./doc/openstack-ops/section_arch_example-nova.xml25(title)
msgid "Overview"
msgstr "Áttekintés"

#: ./doc/openstack-ops/section_arch_example-neutron.xml18(para)
msgid ""
"A highly-available environment can be put into place if you require an "
"environment that can scale horizontally, or want your cloud to continue to "
"be operational in case of node failure. This example architecture has been "
"written based on the current default feature set of OpenStack Havana, with "
"an emphasis on high availability."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml23(title)
#: ./doc/openstack-ops/section_arch_example-nova.xml35(title)
msgid "Components"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml29(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml41(para)
msgid "OpenStack release"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml30(para)
#: ./doc/openstack-ops/app_roadmaps.xml74(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml42(para)
#: ./doc/openstack-ops/glossary-terms.xml2166(glossterm)
msgid "Havana"
msgstr "Havana"

#: ./doc/openstack-ops/section_arch_example-neutron.xml33(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml45(para)
msgid "Host operating system"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml34(para)
msgid "Red Hat Enterprise Linux 6.5"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml37(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml50(para)
msgid "OpenStack package repository"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml38(para)
msgid ""
"<link href=\"http://repos.fedorapeople.org/repos/openstack/openstack-havana"
"/rdo-release-havana-7.noarch.rpm\">Red Hat Distributed OpenStack "
"(RDO)</link> (http://repos.fedorapeople.org/repos/openstack/openstack-havana"
"/rdo-release-havana-7.noarch.rpm)"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml44(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml60(para)
msgid "Hypervisor"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml45(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml61(para)
msgid "KVM"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml48(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml64(para)
#: ./doc/openstack-ops/ch_arch_cloud_controller.xml285(title)
msgid "Database"
msgstr "Adatbázis"

#: ./doc/openstack-ops/section_arch_example-neutron.xml49(para)
msgid "MySQL"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml52(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml68(para)
msgid "Message queue"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml53(para)
#: ./doc/openstack-ops/glossary-terms.xml3612(glossterm)
msgid "Qpid"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml56(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml73(para)
msgid "Networking service"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml57(para)
msgid "OpenStack Networking"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml60(para)
msgid "Tenant Network Separation"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml61(para)
msgid "VLAN"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml65(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml86(para)
msgid "Image Service (glance) back-end"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml67(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml77(para)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml301(para)
#: ./doc/openstack-ops/glossary-terms.xml2086(glossterm)
msgid "GlusterFS"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml70(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml91(para)
msgid "Identity Service (keystone) driver"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml72(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml93(para)
msgid "SQL"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml75(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml96(para)
msgid "Block Storage Service (cinder) back-end"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml82(title)
#: ./doc/openstack-ops/section_arch_example-nova.xml146(title)
msgid "Rationale"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml83(para)
msgid ""
"This example architecture has been selected based on the current default "
"feature set of OpenStack Havana, with an emphasis on high availability. This"
" architecture is currently being deployed in an internal Red Hat OpenStack "
"cloud, and used to run hosted and shared services which by their nature must"
" be highly available."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml88(para)
msgid ""
"This architecture's components have been selected for the following reasons:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml91(para)
msgid ""
"<emphasis role=\"bold\">Red Hat Enterprise Linux</emphasis> - You must "
"choose an operating system that can run on all of the physical nodes. This "
"example architecture is based on Red Hat Enterprise Linux, which offers "
"reliability, long-term support, certified testing, and is hardened. "
"Enterprise customers, now moving into OpenStack usage, typically require "
"these advantages."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml99(para)
msgid ""
"<emphasis role=\"bold\">RDO</emphasis> - The Red Hat Distributed OpenStack "
"package offer an easy way to download the most current OpenStack release "
"that is built for the Red Hat Enterprise Linux platform."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml105(para)
msgid ""
"<emphasis role=\"bold\">KVM</emphasis> - KVM is the supported hypervisor of "
"choice for Red Hat Enterprise Linux (and included in distribution). It is "
"feature complete, and free from licensing charges and restrictions."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml111(para)
msgid ""
"<emphasis role=\"bold\">MySQL</emphasis> - Mysql is used as the database "
"backend for all databases in the OpenStack environment. MySQL is the "
"supported database of choice for Red Hat Enterprise Linux (and included in "
"distribution); the database is open source, scalable, and handles memory "
"well."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml118(para)
msgid ""
"<emphasis role=\"bold\">Qpid</emphasis> - Apache Qpid offers 100 percent "
"compatibility with the Advanced Message Queuing Protocol Standard, and its "
"broker is available for both C++ and Java."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml123(para)
msgid ""
"<emphasis role=\"bold\">OpenStack Networking</emphasis> - OpenStack "
"Networking offers sophisticated networking functionality, including Layer 2 "
"(L2) network segregation and provider networks."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml128(para)
msgid ""
"<emphasis role=\"bold\">VLAN</emphasis> - Using a virtual local area network"
" offers broadcast control, security, and physical layer transparency. If "
"needed, use VXLAN to extend your address space."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml133(para)
msgid ""
"<emphasis role=\"bold\">GlusterFS</emphasis> - GlusterFS offers scalable "
"storage. As your environment grows, you can continue to add more storage "
"nodes (instead of being restricted, for example, by an expensive storage "
"array)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml142(title)
#: ./doc/openstack-ops/section_arch_example-nova.xml258(title)
msgid "Detailed Description"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml144(title)
#: ./doc/openstack-ops/section_arch_example-neutron.xml150(caption)
msgid "Node Types"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml145(para)
msgid ""
"This section gives you a breakdown of the different nodes that make up the "
"OpenStack environment. A node is a physical machine that is provisioned with"
" an operating system, and running a defined software stack on top of it. The"
" following table provides node descriptions and specifications."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml156(th)
msgid "Type"
msgstr "Típus"

#: ./doc/openstack-ops/section_arch_example-neutron.xml158(th)
msgid "Example Hardware"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml163(td)
msgid "Controller"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml164(para)
msgid ""
"Controller nodes are responsible for running the management software "
"services needed for the OpenStack environment to function. These nodes:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml168(para)
msgid ""
"Provide the front door that people access as well as the API services which "
"all other components in the environment talk to."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml172(para)
msgid ""
"Run a number of services in a highly available fashion, utilising Pacemaker "
"and HAProxy to provide a virtual IP and load-balancing functions so all "
"controller nodes are being used."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml177(para)
msgid ""
"Supply highly available \"infrastructure\" services as MySQL and Qpid which "
"underpin all the services."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml180(para)
msgid ""
"Provide what is known as \"persistent storage\" through services run on the "
"host as well. This persistent storage is backed onto the storage nodes for "
"reliability."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml183(para)
msgid "See <xref linkend=\"node_controller-diagram\"/>."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml185(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml207(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml244(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml261(para)
msgid "Model: Dell R620"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml186(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml223(para)
msgid "CPU: 2 x Intel® Xeon® CPU E5-2620 0 @ 2.00GHz"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml187(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml246(para)
msgid "Memory: 32GB"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml188(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml247(para)
msgid "Disk: 2 x 300GB 10000 RPM SAS Disks"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml189(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml229(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml265(para)
msgid "Network: 2 x 10G network ports"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml193(td)
#: ./doc/openstack-ops/ch_ops_backup_recovery.xml91(title)
#: ./doc/openstack-ops/glossary-terms.xml1029(glossterm)
msgid "Compute"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml194(para)
msgid "Compute nodes run the virtual machine instances in OpenStack. They:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml197(para)
msgid "Run the bare minimum of services needed to facilitate these instances."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml201(para)
msgid ""
"Use local storage on the node for the virtual machines, so that no VM "
"migration or instance recovery at node failure is possible."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml195(para)
msgid "<placeholder-1/>See <xref linkend=\"node_compute-diagram\"/>."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml208(para)
msgid "CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00GHz"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml209(para)
msgid "Memory: 128GB"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml210(para)
msgid "Disk: 2 x 600GB 10000 RPM SAS Disks"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml211(para)
msgid "Network: 4 x 10G network ports (For future proofing expansion)"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml215(td)
msgid "Storage"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml216(para)
msgid ""
"Storage nodes store all the data required for the environment, including "
"disk images in the Image Service library, and the persistent storage volumes"
" created by the Block Storage service. Storage nodes use GlusterFS "
"technology to keep the data highly available and scalable."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml220(para)
msgid "See <xref linkend=\"node_storage-diagram\"/>."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml222(para)
msgid "Model: Dell R720xd"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml224(para)
msgid "Memory: 64GB"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml225(para)
msgid "Disk: 2 x 500GB 7200 RPM SAS Disks + 24 x 600GB 10000 RPM SAS Disks"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml227(para)
msgid "Raid Controller: PERC H710P Integrated RAID Controller, 1GB NV Cache"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml233(td)
msgid "Network"
msgstr "Hálózat"

#: ./doc/openstack-ops/section_arch_example-neutron.xml234(para)
msgid ""
"Network nodes are responsible for doing all the virtual networking needed "
"for people to create public or private networks, and uplink their virtual "
"machines into external networks. Network nodes:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml238(para)
msgid ""
"Form the only ingress and egress point for instances running on top of "
"OpenStack."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml239(para)
msgid ""
"Run all of the environment's networking services with the exception of the "
"networking API service (which runs on the controller node)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml242(para)
msgid "See <xref linkend=\"node_network-diagram\"/>."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml245(para)
msgid "CPU: 1 x Intel® Xeon® CPU E5-2620 0 @ 2.00GHz"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml248(para)
msgid "Network: 5 x 10G network ports"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml252(td)
msgid "Utility"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml253(para)
msgid ""
"Utility nodes are used by internal administration staff only to provide a "
"number of basic system administration functions needed to get the "
"environment up and running, and to maintain the hardware, OS, and software "
"on which it runs."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml257(para)
msgid ""
"These nodes run services such as provisioning, configuration management, "
"monitoring, or GlusterFS management software. They are not required to scale"
" although these machines are usually backed up."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml262(para)
msgid "CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00GHz"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml263(para)
msgid "Memory: 32 GB"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml264(para)
msgid "Disk: 2 x 500GB 7200 RPM SAS Disks"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml272(title)
msgid "Networking Layout"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml273(para)
msgid ""
"The network contains all the management devices for all hardware in the "
"environment (for example, by including Dell iDrac7 devices for the hardware "
"nodes, and management interfaces for network switches). The network is "
"accessed by internal staff only when diagnosing or recovering a hardware "
"issue."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml278(title)
msgid "OpenStack internal network"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml279(para)
msgid ""
"This network is used for OpenStack management functions and traffic, "
"including services needed for the provisioning of physical nodes "
"(<systemitem>pxe</systemitem>, <systemitem>tftp</systemitem>, "
"<systemitem>kickstart</systemitem>), traffic between various OpenStack node "
"types using OpenStack APIs and messages (for example, <systemitem>nova-"
"compute</systemitem> talking to <systemitem>keystone</systemitem> or "
"<systemitem>cinder-volume</systemitem> talking to <systemitem>nova-"
"api</systemitem>), and all traffic for storage data to the storage layer "
"underneath by the Gluster protocol. All physical nodes have at least one "
"network interface (typically <systemitem>eth0</systemitem>) in this network."
" This network is only accessible from other VLANs on port 22 (for "
"<systemitem>ssh</systemitem> access to manage machines)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml293(title)
msgid "Public Network"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml296(para)
msgid ""
"IP addresses for public-facing interfaces on the controller nodes (which end"
" users will access the OpenStack services)"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml298(para)
msgid ""
"A range of publicly routable, IPv4 network addresses to be used by OpenStack"
" Networking for floating IPs. You may be restricted in your access to IPv4 "
"addresses; a large range of IPv4 addresses is not necessary."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml302(para)
msgid "Routers for private networks created within OpenStack."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml294(para)
msgid "This network is a combination of: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml305(para)
msgid ""
"This network is connected to the controller nodes so users can access the "
"OpenStack interfaces, and connected to the network nodes to provide VMs with"
" publicly routable traffic functionality. The network is also connected to "
"the utility machines so that any utility services that need to be made "
"public (such as system monitoring) can be accessed."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml312(title)
msgid "VM traffic network"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml313(para)
msgid ""
"This is a closed network that is not publicly routable and is simply used as"
" a private, internal network for traffic between virtual machines in "
"OpenStack, and between the virtual machines and the network nodes which "
"provide l3 routes out to the public network (and floating IPs for "
"connections back in to the VMs). Because this is a closed network, we are "
"using a different address space to the others to clearly define the "
"separation. Only Compute and OpenStack Networking nodes need to be connected"
" to this network."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml323(title)
msgid "Node connectivity"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml324(para)
msgid ""
"The following section details how the nodes are connected to the different "
"networks (see <xref linkend=\"networking_layout\"/>), and what other "
"considerations need to take place (for example, bonding) when connecting "
"nodes to the networks."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml328(title)
msgid "Initial deployment"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml329(para)
msgid ""
"Initially, the connection setup should revolve around keeping the "
"connectivity simple and straightforward, in order to minimise deployment "
"complexity and time to deploy. The following deployment aims to have 1x10G "
"connectivity available to all Compute nodes, while still leveraging bonding "
"on appropriate nodes for maximum performance."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml334(title)
msgid "Basic node deployment"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml343(title)
msgid "Connectivity for maximum performance"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml344(para)
msgid ""
"If the networking performance of the basic layout is not enough, you can "
"move to the following layout which provides 2x10G network links to all "
"instances in the environment, as well as providing more network bandwidth to"
" the storage layer."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml349(title)
msgid "Performance node deployment"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml359(title)
msgid "Node Diagrams"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml360(para)
msgid ""
"The following diagrams include logical information about the different types"
" of nodes, indicating what services will be running on top of them, and how "
"they interact with each other. The diagrams also illustrate how the "
"availability and scalability of services are achieved."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml365(title)
msgid "Controller node"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml373(title)
msgid "Compute Node"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml381(title)
msgid "Network Node"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml389(title)
msgid "Storage Node"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml399(title)
msgid "Example component configuration"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml478(para)
msgid ""
"Because Pacemaker is cluster software, the software itself handles its own "
"availability, leveraging <systemitem>corosync</systemitem> and "
"<systemitem>cman</systemitem> underneath."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml484(para)
msgid ""
"If you use the GlusterFS native client, no virtual IP is needed since the "
"client knows all about nodes after initial connection, and automatically "
"routes around failures on the client side."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml490(para)
msgid ""
"If you use the NFS or SMB adaptor, you will need a virtual IP on which to "
"mount the GlusterFS volumes."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml475(para)
msgid ""
"Pacemaker is the clustering software used to ensure the availability of "
"services running on the controller and network nodes: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml569(para)
msgid ""
"Configured to use Qpid. <systemitem>qpid_heartbeat = 10</systemitem>, "
"configured to use <systemitem>memcached</systemitem> for caching, configured"
" to use <systemitem>libvirt</systemitem>, configured to use "
"<systemitem>neutron</systemitem>."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml573(para)
msgid ""
"Configured <systemitem>nova-consoleauth</systemitem> to use "
"<systemitem>memcached</systemitem> for session management (so that it can "
"have multiple copies and run in a load balancer)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml576(para)
msgid ""
"The nova API, scheduler, objectstore, cert, consoleauth, conductor, and "
"vncproxy services are run on all controller nodes, ensuring at least one "
"instance will be available in case of node failure. Compute is also behind "
"HAProxy, which detects when the software fails and routes requests around "
"the failing instance."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml581(para)
msgid ""
"Compute's compute and conductor services, which run on the compute nodes, "
"are only needed to run services on that node, so availability of those "
"services is coupled tightly to the nodes that are available. As long as a "
"compute node is up, it will have the needed services running on top of it."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml617(para)
msgid ""
"The OpenStack Networking service is run on all controller nodes, ensuring at"
" least one instance will be available in case of node failure. It also sits "
"behind HAProxy, which detects if the software fails and routes requests "
"around the failing instance."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml621(para)
msgid ""
"OpenStack Networking's <systemitem>ovs-agent</systemitem>, <systemitem>l3"
"-agent-dhcp-agent</systemitem>, and <systemitem>metadata-agent</systemitem> "
"services run on the network nodes, as <systemitem>lsb</systemitem> resources"
" inside of Pacemaker. This means that in the case of network node failure, "
"services are kept running on another node. Finally, the <systemitem>ovs-"
"agent</systemitem> service is also run on all compute nodes, and in case of "
"compute node failure, the other nodes will continue to function using the "
"copy of the service running on them."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-neutron.xml400(para)
msgid ""
"The following tables includes example configuration and considerations for "
"both third-party and OpenStack components: <table rules=\"all\"><caption"
">Third-party component configuration</caption><col width=\"10%\"/><col "
"width=\"20%\"/><col width=\"40%\"/><col "
"width=\"30%\"/><thead><tr><th>Component</th><th>Tuning</th><th>Availability</th><th>Scalability</th></tr></thead><tbody><tr><td>MySQL</td><td><systemitem"
">binlog-format = row</systemitem></td><td>Master-Master replication. "
"However, both nodes are not used at the same time. Replication keeps all "
"nodes as close to being up to date as possible (although the asynchronous "
"nature of the replication means a fully consistent state is not possible). "
"Connections to the database only happen through a Pacemaker virtual IP, "
"ensuring that most problems that occur with master-master replication can be"
" avoided.</td><td>Not heavily considered. Once load on the MySQL server "
"increases enough that scalability needs to be considered, multiple masters "
"or a master/slave setup can be "
"used.</td></tr><tr><td>Qpid</td><td><systemitem>max-connections=1000 worker-"
"threads=20 connection-backlog=10</systemitem>, sasl security enabled with "
"SASL-BASIC authentication</td><td>Qpid is added as a resource to the "
"Pacemaker software that runs on Controller nodes where Qpid is situated. "
"This ensures only one Qpid instance is running at one time, and the node "
"with the Pacemaker virtual IP will always be the node running "
"Qpid.</td><td>Not heavily considered. However, Qpid can be changed to run on"
" all controller nodes for scalability and availability purposes, and removed"
" from Pacemaker.</td></tr><tr><td>Haproxy</td><td><systemitem>maxconn "
"3000</systemitem></td><td>Haproxy is a software layer-7 load balancer used "
"to front door all clustered OpenStack API components and do SSL termination."
" Haproxy can be added as a resource to the Pacemaker software that runs on "
"the Controller nodes where HAProxy is situated. This ensures that only one "
"HAProxy instance is running at one time, and the node with the Pacemaker "
"virtual IP will always be the node running HAProxy.</td><td>Not considered. "
"Haproxy has small enough performance overheads that a single instance should"
" scale enough for this level of workload. If extra scalability is needed, "
"<systemitem>keepalived</systemitem> or other Layer-4 load balancing can be "
"introduced to be placed in front of multiple copies of "
"Haproxy.</td></tr><tr><td>Memcached</td><td><systemitem>MAXCONN=\"8192\" "
"CACHESIZE=\"30457\"</systemitem></td><td>Memcached is a fast in-memory "
"key/value cache software that is used by OpenStack components for caching "
"data and increasing performance. Memcached runs on all controller nodes, "
"ensuring that should one go down, another instance of memcached is "
"available.</td><td>Not considered. A single instance of memcached should be "
"able to scale to the desired workloads. If scalability is desired, Haproxy "
"can be placed in front of Memcached (in raw <systemitem>tcp</systemitem> "
"mode) to utilise multiple <systemitem>memcached</systemitem> instances for "
"scalability. However, this might cause cache consistency "
"issues.</td></tr><tr><td>Pacemaker</td><td>Configured to use "
"<systemitem>corosync</systemitem> and <systemitem>cman</systemitem> as a "
"cluster communication stack/quorum manager, and as a two-node "
"cluster.</td><placeholder-1/><td>If more nodes need to be made cluster "
"aware, Pacemaker can scale to 64 "
"nodes.</td></tr><tr><td>GlusterFS</td><td><systemitem>glusterfs</systemitem>"
" performance profile \"virt\" enabled on all volumes. Volumes are setup in "
"2-node replication.</td><td>Glusterfs is a clustered file system that is run"
" on the storage nodes to provide persistent scalable data storage in the "
"environment. Because all connections to gluster use the "
"<systemitem>gluster</systemitem> native mount points, the "
"<systemitem>gluster</systemitem> instances themselves provide availability "
"and failover functionality.</td><td>The scalability of GlusterFS storage can"
" be achieved by adding in more storage "
"volumes.</td></tr></tbody></table><table rules=\"all\"><caption>OpenStack "
"component configuration</caption><col width=\"8%\"/><col width=\"8%\"/><col "
"width=\"19%\"/><col width=\"35%\"/><col "
"width=\"30%\"/><thead><tr><th>Component</th><th>Node "
"type</th><th>Tuning</th><th>Availability</th><th>Scalability</th></tr></thead><tbody><tr><td>Dashboard"
" (horizon)</td><td>Controller</td><td>Configured to use "
"<systemitem>memcached</systemitem> as a session store, "
"<systemitem>neutron</systemitem> support is enabled, "
"<systemitem>can_set_mount_point = False</systemitem></td><td>The Dashboard "
"is run on all controller nodes, ensuring at least one instance will be "
"available in case of node failure. It also sits behind HAProxy, which "
"detects when the software fails and routes requests around the failing "
"instance.</td><td>The Dashboard is run on all controller nodes, so "
"scalability can be achieved with additional controller nodes. Haproxy allows"
" scalability for the Dashboard as more nodes are "
"added.</td></tr><tr><td>Identity "
"(keystone)</td><td>Controller</td><td>Configured to use memcached for "
"caching, and use PKI for tokens.</td><td>Identity is run on all controller "
"nodes, ensuring at least one instance will be available in case of node "
"failure. Identity also sits behind HAProxy, which detects when the software "
"fails and routes requests around the failing instance.</td><td>Identity is "
"run on all controller nodes, so scalability can be achieved with additional "
"controller nodes. Haproxy allows scalability for Identity as more nodes are "
"added.</td></tr><tr><td>Image Service "
"(glance)</td><td>Controller</td><td><systemitem>/var/lib/glance/images</systemitem>"
" is a GlusterFS native mount to a Gluster volume off the storage "
"layer.</td><td>The Image Service is run on all controller nodes, ensuring at"
" least one instance will be available in case of node failure. It also sits "
"behind HAProxy, which detects when the software fails and routes requests "
"around the failing instance.</td><td>The Image Service is run on all "
"controller nodes, so scalability can be achieved with additional controller "
"nodes. HAProxy allows scalability for the Image Service as more nodes are "
"added.</td></tr><tr><td>Compute (nova)</td><td>Controller, "
"Compute</td><placeholder-2/><placeholder-3/><td>The nova API, scheduler, "
"objectstore, cert, consoleauth, conductor, and vncproxy services are run on "
"all controller nodes, so scalability can be achieved with additional "
"controller nodes. HAProxy allows scalability for Compute as more nodes are "
"added. The scalability of services running on the compute nodes (compute, "
"conductor) is achieved linearly by adding in more compute "
"nodes.</td></tr><tr><td>Block Storage "
"(cinder)</td><td>Controller</td><td>Configured to use Qpid, "
"<systemitem>qpid_heartbeat = 10</systemitem>, configured to use a Gluster "
"volume from the storage layer as the backend for Block Storage, using the "
"Gluster native client.</td><td>Block Storage API, scheduler, and volume "
"services are run on all controller nodes, ensuring at least one instance "
"will be available in case of node failure. Block Storage also sits behind "
"HAProxy, which detects if the software fails and routes requests around the "
"failing instance.</td><td>Block Storage API, scheduler and volume services "
"are run on all controller nodes, so scalability can be achieved with "
"additional controller nodes. HAProxy allows scalability for Block Storage as"
" more nodes are added.</td></tr><tr><td>OpenStack Networking "
"(neutron)</td><td>Controller, Compute, Network</td><td>Configured to use "
"QPID. <systemitem>qpid_heartbeat = 10</systemitem>, kernel namespace support"
" enabled, <systemitem>tenant_network_type = vlan</systemitem>, "
"<systemitem>allow_overlapping_ips = true</systemitem>, "
"<systemitem>tenant_network_type = vlan</systemitem>, "
"<systemitem>bridge_uplinks = br-ex:em2</systemitem>, "
"<systemitem>bridge_mappings = physnet1:br-"
"ex</systemitem></td><placeholder-4/><td>The OpenStack Networking server "
"service is run on all controller nodes, so scalability can be achieved with "
"additional controller nodes. HAProxy allows scalability for OpenStack "
"Networking as more nodes are added. Scalability of services running on the "
"network nodes is not currently supported by OpenStack Networking, so they "
"are not be considered. One copy of the services should be sufficient to "
"handle the workload. Scalability of the <systemitem>ovs-agent</systemitem> "
"running on compute nodes is achieved by adding in more compute nodes as "
"necessary.</td></tr></tbody></table>"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/app_roadmaps.xml39(None)
msgid ""
"@@image: 'figures/releasecyclegrizzlydiagram.png'; "
"md5=f4cf95f80608d5069f55cb6c27c215a3"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml14(title)
msgid "Working with Roadmaps"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml15(para)
msgid ""
"The good news: OpenStack has unprecedented transparency when it comes to "
"providing information about what's coming up. The bad news: each release "
"moves very quickly. The purpose of this appendix is to highlight some of the"
" useful pages to track, and take an educated guess at what is coming up in "
"the Icehouse release and perhaps further afield."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml20(para)
msgid ""
"OpenStack follows a six month release cycle, typically releasing in "
"April/May and October/November each year. At the start of each cycle, the "
"community gathers in a single location for a design summit. At the summit, "
"the features for the coming releases are discussed, prioritized, and "
"planned. The <xref linkend=\"release-cycle-diagram\"/> shows an example "
"release cycle with dates showing milestone releases, code freeze, and string"
" freeze dates along with an example of when the summit occurs. Milestones "
"are interim releases within the cycle that are available as packages for "
"download and testing. Code freeze is putting a stop to adding new features "
"to the release. String freeze is putting a stop to changing any strings "
"within the source code."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml34(title)
msgid "Release Cycle Diagram"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml45(title)
msgid "Information Available to You"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml46(para)
msgid ""
"There are several good sources of information available that you can use to "
"track your OpenStack development desires."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml48(para)
msgid "Release notes are maintained on the OpenStack wiki:"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml53(th)
msgid "Series"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml54(th)
msgid "Status"
msgstr "Állapot"

#: ./doc/openstack-ops/app_roadmaps.xml55(th)
msgid "Releases"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml56(th)
msgid "Date"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml61(para)
#: ./doc/openstack-ops/glossary-terms.xml2310(glossterm)
msgid "Icehouse"
msgstr "Icehouse"

#: ./doc/openstack-ops/app_roadmaps.xml65(link)
msgid "Under development, Release schedule"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml70(link)
msgid "2014.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml71(para)
msgid "Apr 17, 2014"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml75(para)
msgid "Current stable release, security-supported"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml81(link)
msgid "2013.2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml83(para)
#: ./doc/openstack-ops/app_roadmaps.xml101(para)
msgid "Apr 4, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml89(link)
msgid "2013.2.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml91(para)
msgid "Dec 16, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml94(para)
#: ./doc/openstack-ops/glossary-terms.xml2124(glossterm)
msgid "Grizzly"
msgstr "Grizzly"

#: ./doc/openstack-ops/app_roadmaps.xml95(para)
msgid "Security-supported"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml99(link)
msgid "2013.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml107(link)
msgid "2013.1.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml109(para)
msgid "May 9, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml116(link)
msgid "2013.1.2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml118(para)
msgid "Jun 6, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml125(link)
msgid "2013.1.3"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml127(para)
msgid "Aug 8, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml134(link)
msgid "2013.1.4"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml136(para)
msgid "Oct 17, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml139(para)
#: ./doc/openstack-ops/glossary-terms.xml2017(glossterm)
msgid "Folsom"
msgstr "Folsom"

#: ./doc/openstack-ops/app_roadmaps.xml140(para)
#: ./doc/openstack-ops/app_roadmaps.xml185(para)
msgid "Community-supported"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml144(link)
msgid "2012.2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml146(para)
msgid "Sep 27, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml152(link)
msgid "2012.2.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml154(para)
msgid "Nov 29, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml161(link)
msgid "2012.2.2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml163(para)
msgid "Dec 13, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml170(link)
msgid "2012.2.3"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml172(para)
msgid "Jan 31, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml179(link)
msgid "2012.2.4"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml181(para)
msgid "Apr 11, 2013"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml184(para)
#: ./doc/openstack-ops/glossary-terms.xml1741(glossterm)
msgid "Essex"
msgstr "Essex"

#: ./doc/openstack-ops/app_roadmaps.xml189(link)
msgid "2012.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml191(para)
msgid "Apr 5, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml198(link)
msgid "2012.1.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml200(para)
msgid "Jun 22, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml207(link)
msgid "2012.1.2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml209(para)
msgid "Aug 10, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml216(link)
msgid "2012.1.3"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml218(para)
msgid "Oct 12, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml221(para)
#: ./doc/openstack-ops/glossary-terms.xml1437(glossterm)
msgid "Diablo"
msgstr "Diablo"

#: ./doc/openstack-ops/app_roadmaps.xml223(para)
#: ./doc/openstack-ops/app_roadmaps.xml242(para)
#: ./doc/openstack-ops/app_roadmaps.xml252(para)
#: ./doc/openstack-ops/app_roadmaps.xml262(para)
msgid "Deprecated"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml227(link)
msgid "2011.3"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml229(para)
msgid "Sep 22, 2011"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml236(link)
msgid "2011.3.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml238(para)
msgid "Jan 19, 2012"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml241(para)
#: ./doc/openstack-ops/glossary-terms.xml720(glossterm)
msgid "Cactus"
msgstr "Cactus"

#: ./doc/openstack-ops/app_roadmaps.xml246(link)
msgid "2011.2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml248(para)
msgid "Apr 15, 2011"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml251(para)
#: ./doc/openstack-ops/glossary-terms.xml571(glossterm)
msgid "Bexar"
msgstr "Bexar"

#: ./doc/openstack-ops/app_roadmaps.xml256(link)
msgid "2011.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml258(para)
msgid "Feb 3, 2011"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml261(para)
#: ./doc/openstack-ops/glossary-terms.xml422(glossterm)
msgid "Austin"
msgstr "Austi"

#: ./doc/openstack-ops/app_roadmaps.xml266(link)
msgid "2010.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml268(para)
msgid "Oct 21, 2010"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml273(link)
msgid ""
"A breakdown of current features under development, with their target "
"milestone."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml275(link)
msgid "A list of all features, including those not yet under development"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml277(link)
msgid ""
"Rough-draft design discussions (\"etherpads\"), from the last design summit"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml279(link)
msgid "List of individual code changes under review"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml284(title)
msgid "Influencing the Roadmap"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml285(para)
msgid ""
"OpenStack truly welcomes your ideas (and contributions), and highly values "
"feedback from real-world users of the software. By learning a little about "
"the process that drives feature development, you can participate and perhaps"
" get the additions you desire."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml290(para)
msgid ""
"Feature requests typically start their life in Etherpad, a collaborative "
"editing tool, which is used to take coordinating notes at a design summit "
"session specific to the feature. This then leads to the creation of a "
"blueprint on the Launchpad site for the particular project, which is used to"
" describe the feature more formally. Blueprints are then approved by project"
" team members, and development can begin."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml298(para)
msgid ""
"Therefore, the fastest way to get your feature request up for consideration "
"is to create an Etherpad with your ideas and propose a session to the design"
" summit. If the design summit has already passed, you may also create a "
"blueprint directly. Read this <link href=\"http://vmartinezdelacruz.com/how-"
"to-work-with-blueprints-without-losing-your-mind/\">blog post about how to "
"work with blueprints</link> (http://vmartinezdelacruz.com/how-to-work-with-"
"blueprints-without-losing-your-mind/) the perspective of Victoria Martínez, "
"a developer intern."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml307(para)
msgid ""
"The roadmap for the next release as it is developed can be seen at <link "
"href=\"http://status.openstack.org/release/\">Releases</link> "
"(http://status.openstack.org/release/)."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml312(para)
msgid ""
"To determine the potential features going in to future releases, or to look "
"at features implemented previously, take a look at the existing blueprints "
"such as <link href=\"https://blueprints.launchpad.net/nova\">OpenStack "
"Compute (nova) Blueprints</link> (https://blueprints.launchpad.net/nova), "
"<link href=\"https://blueprints.launchpad.net/keystone\">OpenStack Identity "
"(keystone) Blueprints</link> (https://blueprints.launchpad.net/keystone), "
"and release notes."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml323(para)
msgid ""
"Aside from the direct-to-blueprint pathway, there is another very well-"
"regarded mechanism to influence the development roadmap: the user survey. "
"Found at <link href=\"http://openstack.org/user-survey\"> "
"http://openstack.org/user-survey</link>, it allows you to provide details of"
" your deployments and needs, anonymously by default. Each cycle, the user "
"committee analyzes the results and produces a report, including providing "
"specific information to the technical committee and technical leads of the "
"projects."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml333(title)
msgid "Aspects to Watch"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml334(para)
msgid ""
"You want to keep an eye on the areas improving within OpenStack. The best "
"way to \"watch\" roadmaps for each project is to look at the blueprints that"
" are being approved for work on milestone releases. You can also learn from "
"PTL webinars that follow the OpenStack summits twice a year."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml341(title)
msgid "Driver Quality Improvements"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml342(para)
msgid ""
"A major quality push has occurred across drivers and plug-ins in Block "
"Storage, Compute, and Networking. Particularly, developers of Compute and "
"Networking drivers that require proprietary or hardware products are now "
"required to provide an automated external testing system for use during the "
"development process."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml351(title)
msgid "Easier Upgrades"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml352(para)
msgid ""
"One of the most requested features since OpenStack began (for components "
"other than Object Storage, which tends to \"just work\"): easier upgrades. "
"From Grizzly onward (and significantly improved in Havana), internal "
"messaging communication is versioned, meaning services can theoretically "
"drop back to backward-compatible behavior. This allows you to run later "
"versions of some components, while keeping older versions of others."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml358(para)
msgid ""
"In addition, a lot of focus has been placed on database migrations. These "
"are now better managed, including the use of the Turbo Hipster tool, which "
"tests database migration performance on copies of real-world user databases."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml362(para)
msgid ""
"These changes have facilitated the first proper OpenStack upgrade guide, "
"found in <xref linkend=\"ch_ops_upgrades\"/>, and will continue to improve "
"in Icehouse."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml367(title)
msgid "Deprecation of Nova Network"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml368(para)
msgid ""
"With the introduction of the full software-defined networking stack provided"
" by OpenStack Networking (neutron) in the Folsom release, development effort"
" on the initial networking code that remains part of the Compute component "
"has gradually lessened. While many still use nova-network in production, "
"there has been a long-term plan to remove the code in favour of the more "
"flexible and full-featured OpenStack Networking."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml378(para)
msgid ""
"An attempt was made to deprecate nova-network during the Havana release, "
"which was aborted due to the lack of equivalent functionality (such as the "
"FlatDHCP multi-host high availability mode mentioned in this guide), lack of"
" a migration path between versions, insufficient testing, and simplicity "
"when used for the more straightforward use cases nova-network traditionally "
"supported. Though significant effort has been made to address these "
"concerns, nova-network will not be deprecated in the Icehouse release. In "
"addition, the Program Technical Lead of the Compute project has indicated "
"that, to a limited degree, patches to nova-network will now again begin to "
"be accepted."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml394(para)
msgid ""
"This leaves you with an important point of decision when designing your "
"cloud. OpenStack Networking is robust enough to use with a small number of "
"limitations (IPv6 support, performance issues in some scenarios) and "
"provides many more features than nova-network. However, if you do not have "
"the more complex use cases that can benefit from fuller software-defined "
"networking capabilities, or are uncomfortable with the new concepts "
"introduced, nova-network may continue to be a viable option for the next 12 "
"to 18 months."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml406(para)
msgid ""
"Similarly, if you have an existing cloud and are looking to upgrade from "
"nova-network to OpenStack Networking, you should have the option to delay "
"the upgrade for this period of time. However, each release of OpenStack "
"brings significant new innovation, and regardless of your use of networking "
"methodology, it is likely best to begin planning for an upgrade within a "
"reasonable timeframe of each release."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml415(para)
msgid ""
"As mentioned, there's currently no way to cleanly migrate from nova-network "
"to neutron. We recommend that you keep a migration in mind and what that "
"process might involve for when a proper migration path is released. If you "
"must upgrade, please be aware that both service and instance downtime is "
"likely unavoidable."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml423(title)
msgid "Replacement of Open vSwitch Plug-in with Modular Layer 2"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml425(para)
msgid ""
"The Modular Layer 2 plug-in is a framework allowing OpenStack Networking to "
"simultaneously utilize the variety of layer-2 networking technologies found "
"in complex real-world data centers. It currently works with the existing "
"Open vSwitch, Linux Bridge, and Hyper-V L2 agents and is intended to replace"
" and deprecate the monolithic plug-ins associated with those L2 agents."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml435(title)
msgid "Compute V3 API"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml436(para)
msgid ""
"The third version of the Compute API was broadly discussed and worked on "
"during the Havana and Icehouse release cycles. Current discussions indicate "
"that the V2 API will remain for many releases, but this is a great time to "
"evaluate the Compute API and provide comments while it is being defined. Of "
"particular note is the decision that the V3 API will not support XML "
"messages—being JSON only. This was based on the poor testing of existing XML"
" responses in the V2 API and the lack of effort to continue to develop and "
"maintain an entire second response type. Feedback on this and any such "
"change is welcome by responding to the <link "
"href=\"https://www.openstack.org/user-survey/\">user survey</link>."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml449(title)
msgid "OpenStack on OpenStack (TripleO)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml450(para)
msgid ""
"This project continues to improve and you may consider using it for "
"greenfield deployments."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml454(title)
msgid "Data Processing (Sahara)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml455(para)
msgid ""
"A much-requested answer to big data problems, a dedicated team has been "
"making solid progress on a Hadoop-as-a-Service project."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml460(title)
msgid "Bare-Metal Deployment (Ironic)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml461(para)
msgid ""
"Though bare-metal deployment has been widely lauded, and development "
"continues, the project to replace the Compute bare-metal driver will not "
"graduate in Icehouse. A particular blueprint to follow is <link "
"href=\"https://blueprints.launchpad.net/ironic/+spec/migration-from-nova\"> "
"Migration Path from Nova's BM Driver</link>, which tracks the ability to "
"move to the new project from an existing bare-metal deployment."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml469(title)
msgid "Database as a Service (Trove)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml470(para)
msgid ""
"The OpenStack community has had a database-as-a-service tool in development "
"for some time, and we will finally see the first integrated release of it in"
" Icehouse. Initially, it will only support MySQL, with further options "
"available in Juno onward, but it should be able to deploy database servers "
"out of the box in a highly available way from this release."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml479(title)
msgid "Messaging as a Service (Marconi)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml480(para)
msgid ""
"A service to provide queues of messages and notifications has entered "
"'incubation,' meaning if the upcoming development cycles are successful, it "
"will be released in Juno."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml486(title)
msgid "Scheduler Improvements"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml487(para)
msgid ""
"Both Compute and Block Storage rely on schedulers to determine where to "
"place virtual machines or volumes. In Havana, the Compute scheduler "
"underwent significant improvement, while in Icehouse the scheduler in Block "
"Storage is slated for a boost. Further down the track, an effort started "
"this cycle that aims to create a holistic scheduler covering both will come "
"to fruition."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml496(title)
msgid "Block Storage Improvements"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml497(para)
msgid ""
"The team discussed many areas of work at the Icehouse summit, including "
"volume migration support, Ceph integration, and access control for volumes."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml502(title)
msgid "Toward a Python SDK"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml503(para)
msgid ""
"Though many successfully use the various python-*client code as an effective"
" SDK for interacting with OpenStack, consistency between the projects and "
"documentation availability waxes and wanes. To combat this, an <link "
"href=\"https://wiki.openstack.org/wiki/PythonOpenStackSDK\">effort to "
"improve the experience</link> has started. Cross-project development efforts"
" in OpenStack have a checkered history, such as the <link "
"href=\"https://wiki.openstack.org/wiki/OpenStackClient\"> unified client "
"project</link> having several false starts. However, the early signs for the"
" SDK project are promising, and we expect to see results during the Juno "
"cycle."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml14(title)
msgid "Customization"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml15(para)
msgid ""
"OpenStack might not do everything you need it to do out of the box. To add a"
" new feature, you can follow different paths."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml18(para)
msgid ""
"To take the first path, you can modify the OpenStack code directly. Learn "
"<link href=\"https://wiki.openstack.org/wiki/How_To_Contribute\">how to "
"contribute</link> (https://wiki.openstack.org/wiki/How_To_Contribute), "
"follow the <link "
"href=\"https://wiki.openstack.org/wiki/GerritWorkflow\">code review "
"workflow</link> (https://wiki.openstack.org/wiki/GerritWorkflow), make your "
"changes, and contribute them back to the upstream OpenStack project. This "
"path is recommended if the feature you need requires deep integration with "
"an existing project. The community is always open to contributions and "
"welcomes new functionality that follows the feature-development guidelines. "
"This path still requires you to use DevStack for testing your feature "
"additions, so this chapter walks you through the DevStack environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml35(para)
msgid ""
"For the second path, you can write new features and plug them in using "
"changes to a configuration file. If the project where your feature would "
"need to reside uses the Python Paste framework, you can create middleware "
"for it and plug it in through configuration. There may also be specific ways"
" of customizing a project such as creating a new scheduler driver for "
"Compute or a custom tab for the dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml41(para)
msgid ""
"This chapter focuses on the second path for customizing OpenStack by "
"providing two examples for writing new features. The first example shows how"
" to modify Object Storage (swift) middleware to add a new feature, and the "
"second example provides a new scheduler feature for OpenStack Compute "
"(nova). To customize OpenStack this way you need a development environment. "
"The best way to get an environment up and running quickly is to run DevStack"
" within your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml49(title)
msgid "Create an OpenStack Development Environment"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml50(para)
msgid ""
"To create a development environment, you can use DevStack. DevStack is "
"essentially a collection of shell scripts and configuration files that "
"builds an OpenStack development environment for you. You use it to create "
"such an environment for developing a new feature."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml55(para)
msgid ""
"You can find all of the documentation at the <link "
"href=\"http://devstack.org/\">DevStack</link> (http://devstack.org/) "
"website."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml59(title)
msgid ""
"To run DevStack for the stable Havana branch on an instance in your "
"OpenStack cloud:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml62(para)
msgid ""
"Boot an instance from the dashboard or the nova command-line interface (CLI)"
" with the following parameters."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml67(para)
msgid "Name: devstack-havana"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml70(para)
msgid "Image: Ubuntu 12.04 LTS"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml73(para)
msgid "Memory Size: 4 GB RAM"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml76(para)
msgid "Disk Size: minimum 5 GB"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml79(para)
msgid ""
"If you are using the <code>nova</code> client, specify <code>--flavor "
"3</code> for the <code>nova boot</code> command to get adequate memory and "
"disk sizes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml85(para)
msgid ""
"Log in and set up DevStack. Here's an example of the commands you can use to"
" set up DevStack on a virtual machine."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml88(para)
msgid "Log in to the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml89(replaceable)
msgid "username"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml89(replaceable)
msgid "my.instance.ip.address"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml91(para)
msgid "Update the virtual machine's operating system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml93(para)
msgid "Install git."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml95(para)
msgid "Clone the stable/havana branch of the devstack repository."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml97(para)
msgid "Change to the devstack repository."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml101(para)
msgid ""
"(Optional) If you've logged in to your instance as the root user, you must "
"create a \"stack\" user, otherwise you'll run into permission issues. If "
"you've logged in as a user other than root, you can skip these steps."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml107(para)
msgid "Run the DevStack script to create the stack user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml109(para)
msgid "Give ownership of the devstack directory to the stack user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml111(para)
msgid "Set some permissions you can use to view the DevStack screen later."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml113(para)
msgid "Switch to the stack user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml118(para)
msgid ""
"Edit the <filename>localrc</filename> configuration file that controls what "
"DevStack will deploy. Copy the example <filename>localrc</filename> file at "
"the end of this section. (See <xref linkend=\"localrc\"/>.)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml123(para)
msgid "Run the stack script that will install OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml125(para)
msgid ""
"When the stack script is done, you can open the screen session it started to"
" view all of the running OpenStack services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml128(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by 0 to go to the first <placeholder-1/> window."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml139(para)
msgid ""
"The <code>stack.sh</code> script takes a while to run. Perhaps take this "
"opportunity to <link href=\"http://www.openstack.org/join/\">join the "
"OpenStack Foundation</link> (http://www.openstack.org/join/)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml148(para)
msgid ""
"<placeholder-1/> is a useful program for viewing many related services at "
"once. For more information, see the <link "
"href=\"http://aperiodic.net/screen/quick_reference\">GNU screen quick "
"reference</link>. (http://aperiodic.net/screen/quick_reference)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml158(para)
msgid ""
"Now that you have an OpenStack development environment, you're free to hack "
"around without worrying about damaging your production deployment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml163(title)
msgid "localrc"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml206(title)
msgid "Customizing Object Storage (Swift) Middleware"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml207(para)
msgid ""
"OpenStack Object Storage, known as swift when reading the code, is based on "
"the Python <link href=\"http://pythonpaste.org/\">Paste</link> "
"(http://pythonpaste.org/) framework. The best introduction to its "
"architecture is <link href=\"http://pythonpaste.org/do-it-yourself-"
"framework.html\">A Do-It-Yourself Framework</link> (http://pythonpaste.org"
"/do-it-yourself-framework.html). Because of the swift project's use of this "
"framework, you are able to add features to a project by placing some custom "
"code in a project's pipeline without having to change any of the core code."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml217(para)
msgid ""
"Imagine a scenario where you have public access to one of your containers, "
"but what you really want is to restrict access to that to a set of IPs based"
" on a whitelist. In this example, we'll create a piece of middleware for "
"swift that allows access to a container from only a set of IP addresses, as "
"determined by the container's metadata items. Only those IP addresses that "
"you explicitly whitelist using the container's metadata will be able to "
"access the container."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml226(para)
msgid ""
"This example is for illustrative purposes only. It should not be used as a "
"container IP whitelist solution without further development and extensive "
"security testing."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml231(para)
msgid ""
"When you join the screen session that <code>stack.sh</code> starts with "
"<code>screen -r stack</code>, you see a screen for each service running, "
"which can be a few or several depending on how many services you configured "
"DevStack to run."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml235(para)
msgid ""
"The asterisk * indicates which screen window you are viewing. This example "
"shows we are viewing the key (for keystone) screen window."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml239(para)
msgid "The purpose of the screen windows are as follows."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml242(para)
#: ./doc/openstack-ops/ch_ops_customize.xml584(para)
msgid ""
"<emphasis role=\"bold\"><code>shell</code></emphasis> A shell where you can "
"get some work done."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml247(para)
msgid "<emphasis role=\"bold\"><code>key*</code></emphasis> The keystone service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml252(para)
#: ./doc/openstack-ops/ch_ops_customize.xml594(para)
msgid ""
"<emphasis role=\"bold\"><code>horizon</code></emphasis> The horizon "
"dashboard web application."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml257(para)
msgid ""
"<emphasis role=\"bold\"><code>s-{name}</code></emphasis> The swift services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml263(title)
msgid "To create the middleware and plug it in through Paste configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml265(para)
msgid ""
"All of the code for OpenStack lives in <code>/opt/stack</code>. Go to the "
"swift directory in the <code>shell</code> screen and edit your middleware "
"module."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml269(para)
msgid "Change to the directory where Object Storage is installed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml271(para)
msgid "Create the ip_whitelist.py Python source code file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml275(para)
msgid ""
"Copy the code in <xref linkend=\"ip_whitelist\"/> into "
"<filename>ip_whitelist.py</filename>. The following code is a middleware "
"example that restricts access to a container based on IP address as "
"explained at the beginning of the section. Middleware passes the request on "
"to another application. This example uses the swift \"swob\" library to wrap"
" Web Server Gateway Interface (WSGI) requests and responses into objects for"
" swift to interact with. When you're done, save and close the file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml285(title)
msgid "ip_whitelist.py"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml380(para)
msgid ""
"There is a lot of useful information in <code>env</code> and "
"<code>conf</code> that you can use to decide what to do with the request. To"
" find out more about what properties are available, you can insert the "
"following log statement into the <code>__init__</code> method"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml388(para)
msgid "and the following log statement into the <code>__call__</code> method"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml393(para)
msgid ""
"To plug this middleware into the swift Paste pipeline, you edit one "
"configuration file, <filename>/etc/swift/proxy-server.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml397(para)
msgid ""
"Find the <code>[filter:ratelimit]</code> section in <filename>/etc/swift"
"/proxy-server.conf</filename>, and copy in the following configuration "
"section after it."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml412(para)
msgid ""
"Find the <code>[pipeline:main]</code> section in <filename>/etc/swift/proxy-"
"server.conf</filename>, and add <code>ip_whitelist</code> after ratelimit to"
" the list like so. When you're done, save and close the file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml421(para)
msgid ""
"Restart the Swift Proxy service to make swift use your middleware. Start by "
"switching to the swift-proxy screen."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml425(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>3</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml426(para)
#: ./doc/openstack-ops/ch_ops_customize.xml790(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>C</keycap></keycombo> to kill "
"the service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml427(para)
#: ./doc/openstack-ops/ch_ops_customize.xml791(para)
msgid "Press Up Arrow to bring up the last command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml428(para)
#: ./doc/openstack-ops/ch_ops_customize.xml792(para)
msgid "Press Enter to run it."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml432(para)
msgid ""
"Test your middleware with the <code>swift</code> CLI. Start by switching to "
"the shell screen and finish by switching back to the <code>swift-"
"proxy</code> screen to check the log output."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml437(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by 0."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml438(para)
msgid "Make sure you're in the devstack directory."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml441(para)
msgid "Source openrc to set up your environment variables for the CLI."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml444(para)
msgid "Create a container called middleware-test."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml446(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>3</keycap> to check the log output."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml449(para)
msgid "Among the log statements you'll see the lines."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml452(para)
msgid ""
"These two statements are produced by our middleware and show that the "
"request was sent from our DevStack instance and was allowed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml456(para)
msgid ""
"Test the middleware from outside DevStack on a remote machine that has "
"access to your DevStack instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml461(para)
msgid ""
"Install the <code>keystone</code> and <code>swift</code> clients on your "
"local machine."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml463(para)
msgid "Attempt to list the objects in the middleware-test container."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml468(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>3</keycap> to check the log output. Look at the swift log "
"statements again, and among the log statements you'll see the lines:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml477(para)
msgid ""
"Here we can see that the request was denied because the remote IP address "
"wasn't in the set of allowed IPs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml482(para)
msgid ""
"Back in your DevStack instance on the shell screen, add some metadata to "
"your container to allow the request from the remote machine."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml486(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>0</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml491(para)
msgid "Add metadata to the container to allow the IP."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml495(para)
msgid ""
"Now try the command from <xref linkend=\"test_middleware_step\"/> again and "
"it succeeds. There are no objects in the container, so there is nothing to "
"list, however there is also no error to report."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml503(para)
msgid ""
"Functional testing like this is not a replacement for proper unit and "
"integration testing, but it serves to get you started."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml505(para)
msgid ""
"You can follow a similar pattern in other projects that use the Python Paste"
" framework. Simply create a middleware module and plug it in through "
"configuration. The middleware runs in sequence as part of that project's "
"pipeline and can call out to other services as necessary. No project core "
"code is touched. Look for a <code>pipeline</code> value in the project's "
"<code>conf</code> or <code>ini</code> configuration files in "
"<code>/etc/&lt;project&gt;</code> to identify projects that use Paste."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml515(para)
msgid ""
"When your middleware is done, we encourage you to open source it and let the"
" community know on the OpenStack mailing list. Perhaps others need the same "
"functionality. They can use your code, provide feedback, and possibly "
"contribute. If enough support exists for it, perhaps you can propose that it"
" be added to the official swift <link "
"href=\"https://github.com/openstack/swift/tree/master/swift/common/middleware\">middleware</link>"
" (https://github.com/openstack/swift/tree/master/swift/common/middleware)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml525(title)
msgid "Customizing the OpenStack Compute (nova) Scheduler"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml526(para)
msgid ""
"Many OpenStack projects allow for customization of specific features using a"
" driver architecture. You can write a driver that conforms to a particular "
"interface and plug it in through configuration. For example, you can easily "
"plug in a new scheduler for Compute. The existing schedulers for Compute are"
" feature full and well documented at <link "
"href=\"http://docs.openstack.org/trunk/config-reference/content"
"/section_compute-scheduler.html\">Scheduling</link> "
"(http://docs.openstack.org/trunk/config-reference/content/section_compute-"
"scheduler.html). However, depending on your user's use cases, the existing "
"schedulers might not meet your requirements. You might need to create a new "
"scheduler."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml539(para)
msgid ""
"To create a scheduler, you must inherit from the class "
"<code>nova.scheduler.driver.Scheduler</code>. Of the five methods that you "
"can override, you <emphasis>must</emphasis> override the two methods marked "
"with an asterisk (*) below."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml546(code)
msgid "update_service_capabilities"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml551(code)
msgid "hosts_up"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml556(code)
msgid "group_hosts"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml560(para)
msgid "* <code>schedule_run_instance</code>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml564(para)
msgid "* <code>select_destinations</code>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml568(para)
msgid ""
"To demonstrate customizing OpenStack, we'll create an example of a Compute "
"scheduler that randomly places an instance on a subset of hosts depending on"
" the originating IP address of the request and the prefix of the hostname. "
"Such an example could be useful when you have a group of users on a subnet "
"and you want all of their instances to start within some subset of your "
"hosts."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml575(para)
msgid ""
"This example is for illustrative purposes only. It should not be used as a "
"scheduler for Compute without further development and testing."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml578(para)
msgid ""
"When you join the screen session that <code>stack.sh</code> starts with "
"<code>screen -r stack</code>, you are greeted with many screen windows."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml589(para)
msgid "<emphasis role=\"bold\"><code>key</code></emphasis> The keystone service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml599(para)
msgid ""
"<emphasis role=\"bold\"><code>n-{name}</code></emphasis> The nova services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml604(para)
msgid ""
"<emphasis role=\"bold\"><code>n-sch</code></emphasis> The nova scheduler "
"service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml610(title)
msgid "To create the scheduler and plug it in through configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml613(para)
msgid ""
"The code for OpenStack lives in <code>/opt/stack</code>, so go to the nova "
"directory and edit your scheduler module. Change to the directory where nova"
" is installed:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml617(para)
msgid ""
"Create the <filename>ip_scheduler.py</filename> Python source code file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml621(para)
msgid ""
"The code in <xref linkend=\"ip_scheduler\"/> is a driver that will schedule "
"servers to hosts based on IP address as explained at the beginning of the "
"section. Copy the code into <filename>ip_scheduler.py</filename>. When "
"you're done, save and close the file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml628(title)
msgid "ip_scheduler.py"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml754(para)
msgid ""
"There is a lot of useful information in <code>context</code>, "
"<code>request_spec</code>, and <code>filter_properties</code> that you can "
"use to decide where to schedule the instance. To find out more about what "
"properties are available, you can insert the following log statements into "
"the <code>schedule_run_instance</code> method of the scheduler above."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml767(para)
msgid ""
"To plug this scheduler into nova, edit one configuration file, "
"<filename>/etc/nova/nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml772(para)
msgid "Find the <code>scheduler_driver</code> config and change it like so."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml777(para)
msgid ""
"Restart the nova scheduler service to make nova use your scheduler. Start by"
" switching to the <code>n-sch</code> screen."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml781(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>9</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml785(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>N</keycap> until you reach the n-sch screen."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml796(para)
msgid ""
"Test your scheduler with the nova CLI. Start by switching to the "
"<code>shell</code> screen and finish by switching back to the "
"<code>n-sch</code> screen to check the log output."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml802(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>0</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml806(para)
msgid "Make sure you're in the <filename>devstack</filename> directory."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml809(para)
msgid ""
"Source <filename>openrc</filename> to set up your environment variables for "
"the CLI."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml812(para)
msgid ""
"Put the image ID for the only installed image into an environment variable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml814(para)
msgid "Boot a test server."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml818(para)
msgid ""
"Switch back to the <code>n-sch</code> screen. Among the log statements, "
"you'll see the line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml823(para)
msgid ""
"Functional testing like this is not a replacement for proper unit and "
"integration testing but it serves to get you started."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml826(para)
msgid ""
"A similar pattern can be followed in other projects that use the driver "
"architecture. Simply create a module and class that conform to the driver "
"interface and plug it in through configuration. Your code runs when that "
"feature is used and can call out to other services as necessary. No project "
"core code is touched. Look for a \"driver\" value in the project's "
"<filename>.conf</filename> configuration files in "
"<code>/etc/&lt;project&gt;</code> to identify projects that use a driver "
"architecture."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml834(para)
msgid ""
"When your scheduler is done, we encourage you to open source it and let the "
"community know on the OpenStack mailing list. Perhaps others need the same "
"functionality. They can use your code, provide feedback, and possibly "
"contribute. If enough support exists for it, perhaps you can propose that it"
" be added to the official Compute <link "
"href=\"https://github.com/openstack/nova/tree/master/nova/scheduler\">schedulers</link>"
" (https://github.com/openstack/nova/tree/master/nova/scheduler)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml844(title)
msgid "Customizing the Dashboard (Horizon)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml845(para)
msgid ""
"The dashboard is based on the Python <link "
"href=\"https://www.djangoproject.com/\">Django</link> "
"(https://www.djangoproject.com/) web application framework. The best guide "
"to customizing it has already been written and can be found at <link "
"href=\"http://docs.openstack.org/developer/horizon/topics/tutorial.html\">Building"
" on Horizon</link> "
"(http://docs.openstack.org/developer/horizon/topics/tutorial.html)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml856(para)
msgid ""
"When operating an OpenStack cloud, you may discover that your users can be "
"quite demanding. If OpenStack doesn't do what your users need, it may be up "
"to you to fulfill those requirements. This chapter provided you with some "
"options for customization and gave you the tools you need to get started."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml14(title)
msgid "Backup and Recovery"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml15(para)
msgid ""
"Standard backup best practices apply when creating your OpenStack back up "
"policy. For example, how often to backup your data is closely related to how"
" quickly you need to recover from data loss."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml20(para)
msgid ""
"If you cannot have any data loss at all, you should also focus on a highly "
"available deployment. The <citetitle><link href=\"http://docs.openstack.org"
"/high-availability-guide/content/\">OpenStack High Availability "
"Guide</link></citetitle> offers suggestions for elimination of a single "
"point of failure that could cause system downtime. While it is not a "
"completely prescriptive document, it offers methods and techniques for "
"avoiding downtime and data loss."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml31(para)
msgid "Other backup considerations include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml34(para)
msgid "How many backups to keep?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml37(para)
msgid "Should backups be kept off-site?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml40(para)
msgid "How often should backups be tested?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml43(para)
msgid ""
"Just as important as a backup policy is a recovery policy (or at least "
"recovery testing)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml48(title)
msgid "What to Backup"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml49(para)
msgid ""
"While OpenStack is composed of many components and moving parts, backing up "
"the critical data is quite simple."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml52(para)
msgid ""
"This chapter describes only how to back up configuration files and databases"
" that the various OpenStack components need to run. This chapter does not "
"describe how to back up objects inside Object Storage or data contained "
"inside Block Storage. Generally these areas are left for users to back up on"
" their own."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml60(title)
msgid "Database Backups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml61(para)
msgid ""
"The example OpenStack architecture designates the cloud controller as the "
"MySQL server. This MySQL server hosts the databases for nova, glance, "
"cinder, and keystone. With all of these databases in one place, it's very "
"easy to create a database backup:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml70(para)
msgid "If you only want to backup a single database, you can instead run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml73(para)
msgid "where <code>nova</code> is the database you want to back up."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml75(para)
msgid ""
"You can easily automate this process by creating a cron job that runs the "
"following script once per day:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml84(para)
msgid ""
"This script dumps the entire MySQL database and deletes any backups older "
"than seven days."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml88(title)
msgid "File System Backups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml89(para)
msgid ""
"This section discusses which files and directories should be backed up "
"regularly, organized by service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml92(para)
msgid ""
"The <filename>/etc/nova</filename> directory on both the cloud controller "
"and compute nodes should be regularly backed up."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml95(para)
msgid ""
"<code>/var/log/nova</code> does not need to be backed up if you have all "
"logs going to a central area. It is highly recommended to use a central "
"logging server or back up the log directory."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml100(para)
msgid ""
"<code>/var/lib/nova</code> is another important directory to back up. The "
"exception to this is the <code>/var/lib/nova/instances</code> subdirectory "
"on compute nodes. This subdirectory contains the KVM images of running "
"instances. You would want to back up this directory only if you need to "
"maintain backup copies of all instances. Under most circumstances, you do "
"not need to do this, but this can vary from cloud to cloud and your service "
"levels. Also be aware that making a backup of a live KVM instance can cause "
"that instance to not boot properly if it is ever restored from a backup."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml115(title)
msgid "Image Catalog and Delivery"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml116(para)
msgid ""
"<code>/etc/glance</code> and <code>/var/log/glance</code> follow the same "
"rules as their nova counterparts."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml120(para)
msgid ""
"<code>/var/lib/glance</code> should also be backed up. Take special notice "
"of <code>/var/lib/glance/images</code>. If you are using a file-based "
"backend of glance, <code>/var/lib/glance/images</code> is where the images "
"are stored and care should be taken."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml127(para)
msgid ""
"There are two ways to ensure stability with this directory. The first is to "
"make sure this directory is run on a RAID array. If a disk fails, the "
"directory is available. The second way is to use a tool such as rsync to "
"replicate the images to another server:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml133(para)
msgid ""
"# rsync -az --progress /var/lib/glance/images backup-"
"server:/var/lib/glance/images/"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml137(title)
msgid "Identity"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml138(para)
msgid ""
"<code>/etc/keystone</code> and <code>/var/log/keystone</code> follow the "
"same rules as other components."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml142(para)
msgid ""
"<code>/var/lib/keystone</code>, although it should not contain any data "
"being used, can also be backed up just in case."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml149(para)
msgid ""
"<code>/etc/cinder</code> and <code>/var/log/cinder</code> follow the same "
"rules as other components."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml153(para)
msgid "<code>/var/lib/cinder</code> should also be backed up."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml158(title)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml323(para)
#: ./doc/openstack-ops/ch_arch_storage.xml46(title)
#: ./doc/openstack-ops/glossary-terms.xml3235(glossterm)
msgid "Object Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml159(para)
msgid ""
"<code>/etc/swift</code> is very important to have backed up. This directory "
"contains the swift configuration files as well as the ring files and ring "
"<glossterm>builder file</glossterm>s, which if lost render the data on your "
"cluster inaccessible. A best practice is to copy the builder files to all "
"storage nodes along with the ring files. Multiple backup copies are spread "
"throughout your storage cluster."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml172(title)
msgid "Recovering Backups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml173(para)
msgid ""
"Recovering backups is a fairly simple process. To begin, first ensure that "
"the service you are recovering is not running. For example, to do a full "
"recovery of nova on the cloud controller, first stop all <code>nova</code> "
"services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml184(para)
msgid "Now you can import a previously backed-up database:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml187(para)
msgid "You can also restore backed-up nova directories:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml190(para)
msgid "Once the files are restored, start everything back up:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml198(para)
msgid ""
"Other services follow the same process, with their respective directories "
"and databases."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml202(title)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml763(title)
#: ./doc/openstack-ops/ch_ops_lay_of_land.xml626(title)
#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml966(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml833(title)
msgid "Summary"
msgstr "Összegzés"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml203(para)
msgid ""
"Backup and subsequent recovery is one of the first tasks system "
"administrators learn. However, each system has different items that need "
"attention. By taking care of your database, image service, and appropriate "
"file system locations, you can be assured you can handle any event requiring"
" recovery."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml14(title)
msgid "Maintenance, Failures, and Debugging"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml15(para)
msgid ""
"Downtime, whether planned or unscheduled, is a certainty when running a "
"cloud. This chapter aims to provide useful information for dealing "
"proactively, or reactively, with these occurrences."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml21(title)
msgid "Cloud Controller and Storage Proxy Failures and Maintenance"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml23(para)
msgid ""
"The cloud controller and storage proxy are very similar to each other when "
"it comes to expected and unexpected downtime. One of each server type "
"typically runs in the cloud, which makes them very noticeable when they are "
"not running."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml28(para)
msgid ""
"For the cloud controller, the good news is if your cloud is using the "
"FlatDHCP multi-host HA network mode, existing instances and volumes continue"
" to operate while the cloud controller is offline. For the storage proxy, "
"however, no storage traffic is possible until it is back up and running."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml36(title)
#: ./doc/openstack-ops/ch_ops_maintenance.xml126(title)
msgid "Planned Maintenance"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml37(para)
msgid ""
"One way to plan for cloud controller or storage proxy maintenance is to "
"simply do it off-hours, such as at 1 or 2 A.M. This strategy affects fewer "
"users. If your cloud controller or storage proxy is too important to have "
"unavailable at any point in time, you must look into high-availability "
"options."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml46(title)
msgid "Rebooting a Cloud Controller or Storage Proxy"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml48(para)
msgid ""
"All in all, just issue the \"reboot\" command. The operating system cleanly "
"shuts down services and then automatically reboots. If you want to be very "
"thorough, run your backup jobs just before you reboot."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml56(title)
msgid "After a Cloud Controller or Storage Proxy Reboots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml58(para)
msgid ""
"After a cloud controller reboots, ensure that all required services were "
"successfully started. The following commands use <code>ps</code> and "
"<code>grep</code> to determine if nova, glance, and keystone are currently "
"running:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml67(para)
msgid ""
"Also check that all services are functioning. The following set of commands "
"sources the <code>openrc</code> file, then runs some basic glance, nova, and"
" keystone commands. If the commands work as expected, you can be confident "
"that those services are in working condition:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml77(para)
msgid ""
"For the storage proxy, ensure that the Object Storage service has resumed:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml80(para)
msgid "Also check that it is functioning:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml85(title)
msgid "Total Cloud Controller Failure"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml86(para)
msgid ""
"The cloud controller could completely fail if, for example, its motherboard "
"goes bad. Users will immediately notice the loss of a cloud controller since"
" it provides core functionality to your cloud environment. If your "
"infrastructure monitoring does not alert you that your cloud controller has "
"failed, your users definitely will. Unfortunately, this is a rough "
"situation. The cloud controller is an integral part of your cloud. If you "
"have only one controller, you will have many missing services if it goes "
"down."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml97(para)
msgid ""
"To avoid this situation, create a highly available cloud controller cluster."
" This is outside the scope of this document, but you can read more in the "
"draft <link title=\"OpenStack High Availability Guide\" "
"href=\"http://docs.openstack.org/trunk/openstack-ha/content/ch-"
"intro.html\">OpenStack High Availability Guide</link> "
"(http://docs.openstack.org/trunk/openstack-ha/content/ch-intro.html)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml105(para)
msgid ""
"The next best approach is to use a configuration- management tool such as "
"Puppet to automatically build a cloud controller. This should not take more "
"than 15 minutes if you have a spare server available. After the controller "
"rebuilds, restore any backups taken (see the <link "
"linkend=\"backup_and_recovery\">Backup and Recovery</link> chapter)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml112(para)
msgid ""
"Also, in practice, the nova-compute services on the compute nodes sometimes "
"do not reconnect cleanly to rabbitmq hosted on the controller when it comes "
"back up after a long reboot and a restart on the nova services on the "
"compute nodes is required."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml121(title)
msgid "Compute Node Failures and Maintenance"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml122(para)
msgid ""
"Sometimes a compute node either crashes unexpectedly or requires a reboot "
"for maintenance reasons."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml127(para)
msgid ""
"If you need to reboot a compute node due to planned maintenance (such as a "
"software or hardware upgrade), first ensure that all hosted instances have "
"been moved off the node. If your cloud is utilizing shared storage, use the "
"<code>nova live-migration</code> command. First, get a list of instances "
"that need to be moved:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml135(para)
msgid "Next, migrate them one by one:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml137(para)
msgid ""
"If you are not using shared storage, you can use the <code>--block-"
"migrate</code> option:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml140(para)
msgid ""
"After you have migrated all instances, ensure that the <code>nova-"
"compute</code> service has stopped:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml144(para)
msgid ""
"If you use a configuration-management system, such as Puppet, that ensures "
"the <code>nova-compute</code> service is always running, you can temporarily"
" move the init files:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml151(para)
msgid ""
"Next, shut down your compute node, perform your maintenance, and turn the "
"node back on. You can reenable the <code>nova-compute</code> service by "
"undoing the previous commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml157(para)
msgid "Then start the <code>nova-compute</code> service:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml160(para)
msgid ""
"You can now optionally migrate the instances back to their original compute "
"node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml165(title)
msgid "After a Compute Node Reboots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml166(para)
msgid ""
"When you reboot a compute node, first verify that it booted successfully. "
"This includes ensuring that the <code>nova-compute</code> service is "
"running:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml172(para)
msgid "Also ensure that it has successfully connected to the AMQP server:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml176(para)
msgid ""
"After the compute node is successfully running, you must deal with the "
"instances that are hosted on that compute node because none of them are "
"running. Depending on your SLA with your users or customers, you might have "
"to start each instance and ensure that they start correctly."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml186(para)
msgid ""
"You can create a list of instances that are hosted on the compute node by "
"performing the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml190(para)
msgid ""
"After you have the list, you can use the nova command to start each "
"instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml194(para)
msgid ""
"Any time an instance shuts down unexpectedly, it might have problems on "
"boot. For example, the instance might require an <code>fsck</code> on the "
"root partition. If this happens, the user can use the dashboard VNC console "
"to fix this."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml200(para)
msgid ""
"If an instance does not boot, meaning <code>virsh list</code> never shows "
"the instance as even attempting to boot, do the following on the compute "
"node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml205(para)
msgid ""
"Try executing the <code>nova reboot</code> command again. You should see an "
"error message about why the instance was not able to boot"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml208(para)
msgid ""
"In most cases, the error is the result of something in libvirt's XML file "
"(<code>/etc/libvirt/qemu/instance-xxxxxxxx.xml</code>) that no longer "
"exists. You can enforce re-creation of the XML file as well as rebooting the"
" instance by running the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml218(title)
msgid "Inspecting and Recovering Data from Failed Instances"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml219(para)
msgid ""
"In some scenarios, instances are running but are inaccessible through SSH "
"and do not respond to any command. The VNC console could be displaying a "
"boot failure or kernel panic error messages. This could be an indication of "
"file system corruption on the VM itself. If you need to recover files or "
"inspect the content of the instance, qemu-nbd can be used to mount the disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml226(para)
msgid ""
"If you access or view the user's content and data, get their approval first!"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml229(para)
msgid ""
"To access the instance's disk (/var/lib/nova/instances/instance-"
"xxxxxx/disk), use the following steps:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml234(para)
msgid "Suspend the instance using the virsh command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml237(para)
msgid "Connect the qemu-nbd device to the disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml240(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml289(para)
msgid "Mount the qemu-nbd device."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml243(para)
msgid "Unmount the device after inspecting."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml246(para)
msgid "Disconnect the qemu-nbd device."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml249(para)
msgid "Resume the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml252(para)
msgid ""
"If you do not follow the steps 4 through 6, OpenStack Compute cannot manage "
"the instance any longer. It fails to respond to any command issued by "
"OpenStack Compute and it is marked as shutdown."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml256(para)
msgid ""
"Once you mount the disk file, you should be to able access it and treat it "
"as normal directories with files and a directory structure. However, we do "
"not recommend that you edit or touch any files because this could change the"
" access control lists (ACLs) that are used to determine which accounts can "
"perform what operations on files and directories. Changing ACLs can make the"
" instance unbootable if it is not already."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml265(para)
msgid ""
"Suspend the instance using the virsh command, taking note of the internal "
"ID:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml278(para)
msgid "Connect the qemu-nbd device to the disk:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml290(para)
msgid ""
"The qemu-nbd device tries to export the instance disk's different partitions"
" as separate devices. For example, if vda is the disk and vda1 is the root "
"partition, qemu-nbd exports the device as /dev/nbd0 and /dev/nbd0p1 "
"respectively:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml296(para)
msgid ""
"You can now access the contents of <code>/mnt</code>, which correspond to "
"the first partition of the instance's disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml299(para)
msgid ""
"To examine the secondary or ephemeral disk, use an alternate mount point if "
"you want both primary and secondary drives mounted at the same time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml329(para)
msgid ""
"Once you have completed the inspection, unmount the mount point and release "
"the qemu-nbd device:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml336(para)
msgid "Resume the instance using virsh:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml351(title)
msgid "Volumes"
msgstr "Kötetek"

#: ./doc/openstack-ops/ch_ops_maintenance.xml352(para)
msgid ""
"If the affected instances also had attached volumes, first generate a list "
"of instance and volume UUIDs:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml359(para)
msgid "You should see a result similar to the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml367(para)
msgid ""
"Next, manually detach and reattach the volumes, where X is the proper mount "
"point:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml371(para)
msgid ""
"Be sure that the instance has successfully booted and is at a login screen "
"before doing the above."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml377(title)
msgid "Total Compute Node Failure"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml378(para)
msgid ""
"Compute nodes can fail the same way a cloud controller can fail. A "
"motherboard failure or some other type of hardware failure can cause an "
"entire compute node to go offline. When this happens, all instances running "
"on that compute node will not be available. Just like with a cloud "
"controller failure, if your infrastructure monitoring does not detect a "
"failed compute node, your users will notify you because of their lost "
"instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml387(para)
msgid ""
"If a compute node fails and won't be fixed for a few hours (or ever at all),"
" you can relaunch all instances that are hosted on the failed node if you "
"use shared storage for <code>/var/lib/nova/instances</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml392(para)
msgid ""
"To do this, generate a list of instance UUIDs that are hosted on the failed "
"node by running the following query on the nova database:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml396(para)
msgid ""
"Next, update the nova database to indicate that all instances that used to "
"be hosted on c01.example.com are now hosted on c02.example.com:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml400(para)
msgid ""
"After that, use the nova command to reboot all instances that were on "
"c01.example.com while regenerating their XML files at the same time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml404(para)
msgid ""
"Finally, reattach volumes using the same method described in the section "
"<link linkend=\"volumes\">Volumes</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml409(title)
msgid "/var/lib/nova/instances"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml410(para)
msgid ""
"It's worth mentioning this directory in the context of failed compute nodes."
" This directory contains the libvirt KVM file-based disk images for the "
"instances that are hosted on that compute node. If you are not running your "
"cloud in a shared storage environment, this directory is unique across all "
"compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml417(para)
msgid ""
"<code>/var/lib/nova/instances</code> contains two types of directories."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml420(para)
msgid ""
"The first is the <code>_base</code> directory. This contains all the cached "
"base images from glance for each unique image that has been launched on that"
" compute node. Files ending in <code>_20</code> (or a different number) are "
"the ephemeral base images."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml426(para)
msgid ""
"The other directories are titled <code>instance-xxxxxxxx</code>. These "
"directories correspond to instances running on that compute node. The files "
"inside are related to one of the files in the <code>_base</code> directory. "
"They're essentially differential-based files containing only the changes "
"made from the original <code>_base</code> directory."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml434(para)
msgid ""
"All files and directories in <code>/var/lib/nova/instances</code> are "
"uniquely named. The files in _base are uniquely titled for the glance image "
"that they are based on, and the directory names <code>instance-"
"xxxxxxxx</code> are uniquely titled for that particular instance. For "
"example, if you copy all data from <code>/var/lib/nova/instances</code> on "
"one compute node to another, you do not overwrite any files or cause any "
"damage to images that have the same unique name, because they are "
"essentially the same file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml446(para)
msgid ""
"Although this method is not documented or supported, you can use it when "
"your compute node is permanently offline but you have instances locally "
"stored on it."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml454(title)
msgid "Storage Node Failures and Maintenance"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml455(para)
msgid ""
"Because of the high redundancy of Object Storage, dealing with object "
"storage node issues is a lot easier than dealing with compute node issues."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml460(title)
msgid "Rebooting a Storage Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml461(para)
msgid ""
"If a storage node requires a reboot, simply reboot it. Requests for data "
"hosted on that node are redirected to other copies while the server is "
"rebooting."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml468(title)
msgid "Shutting Down a Storage Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml469(para)
msgid ""
"If you need to shut down a storage node for an extended period of time (one "
"or more days), consider removing the node from the storage ring. For "
"example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml478(para)
msgid "Next, redistribute the ring files to the other nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml484(para)
msgid ""
"These actions effectively take the storage node out of the storage cluster."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml486(para)
msgid ""
"When the node is able to rejoin the cluster, just add it back to the ring. "
"The exact syntax you use to add a node to your swift cluster with <code"
">swift-ring-builder</code> heavily depends on the original options used when"
" you originally created your cluster. Please refer back to those commands."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml496(title)
msgid "Replacing a Swift Disk"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml497(para)
msgid ""
"If a hard drive fails in an Object Storage node, replacing it is relatively "
"easy. This assumes that your Object Storage environment is configured "
"correctly, where the data that is stored on the failed drive is also "
"replicated to other drives in the Object Storage environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml503(para)
msgid "This example assumes that <code>/dev/sdb</code> has failed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml505(para)
msgid "First, unmount the disk:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml507(para)
msgid ""
"Next, physically remove the disk from the server and replace it with a "
"working disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml509(para)
msgid "Ensure that the operating system has recognized the new disk:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml512(para)
msgid "You should see a message about <code>/dev/sdb</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml513(para)
msgid ""
"Because it is recommended to not use partitions on a swift disk, simply "
"format the disk as a whole:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml516(para)
msgid "Finally, mount the disk:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml518(para)
msgid ""
"Swift should notice the new disk and that no data exists. It then begins "
"replicating the data to the disk from the other existing replicas."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml525(title)
msgid "Handling a Complete Failure"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml526(para)
msgid ""
"A common way of dealing with the recovery from a full system failure, such "
"as a power outage of a data center, is to assign each service a priority, "
"and restore in order. Here is an example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml531(caption)
msgid "Example Service Restoration Priority List"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml536(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml51(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml58(para)
msgid "1"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml538(para)
msgid "Internal network connectivity"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml543(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml65(para)
msgid "2"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml545(para)
msgid "Backing storage services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml550(para)
msgid "3"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml552(para)
msgid "Public network connectivity for user virtual machines"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml557(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml72(para)
msgid "4"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml559(para)
msgid "Nova-compute, nova-network, cinder hosts"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml564(para)
msgid "5"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml566(para)
msgid "User virtual machines"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml570(para)
msgid "10"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml572(para)
msgid "Message queue and database services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml577(para)
msgid "15"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml579(para)
msgid "Keystone services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml583(para)
msgid "20"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml585(para)
msgid "Cinder-scheduler"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml589(para)
msgid "21"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml591(para)
msgid "Image Catalog and Delivery services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml596(para)
msgid "22"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml598(para)
msgid "nova-scheduler services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml602(para)
msgid "98"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml604(para)
msgid "Cinder-api"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml608(para)
msgid "99"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml610(para)
msgid "Nova-api services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml614(para)
msgid "100"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml616(para)
msgid "Dashboard node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml620(para)
msgid ""
"Use this example priority list to ensure that user- affected services are "
"restored as soon as possible, but not before a stable environment is in "
"place. Of course, despite being listed as a single line item, each step "
"requires significant work. For example, just after starting the database, "
"you should check its integrity, or, after starting the nova services, you "
"should verify that the hypervisor matches the database and fix any "
"mismatches."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml632(title)
#: ./doc/openstack-ops/ch_ops_resources.xml104(emphasis)
msgid "Configuration Management"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml633(para)
msgid ""
"Maintaining an OpenStack cloud requires that you manage multiple physical "
"servers, and this number might grow over time. Because managing nodes "
"manually is error prone, we strongly recommend that you use a configuration-"
"management tool. These tools automate the process of ensuring that all your "
"nodes are configured properly and encourage you to maintain your "
"configuration information (such as packages and configuration options) in a "
"version- controlled repository."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml642(para)
msgid ""
"Several configuration-management tools are available, and this guide does "
"not recommend a specific one. The two most popular ones in the OpenStack "
"community are <link href=\"https://puppetlabs.com/\">Puppet</link> "
"(https://puppetlabs.com/), with available <link title=\"Optimization "
"Overview\" href=\"http://github.com/puppetlabs/puppetlabs-"
"openstack\">OpenStack Puppet modules</link> (http://github.com/puppetlabs"
"/puppetlabs-openstack), and <link "
"href=\"http://www.opscode.com/chef/\">Chef</link> (http://opscode.com/chef),"
" with available <link href=\"https://github.com/opscode/openstack-chef-"
"repo\">OpenStack Chef recipes</link> (https://github.com/opscode/openstack-"
"chef-repo). Other newer configuration tools include <link "
"href=\"https://juju.ubuntu.com/\">Juju</link> (https://juju.ubuntu.com/), "
"<link href=\"http://ansible.cc\">Ansible</link> (http://ansible.cc), and "
"<link href=\"http://saltstack.com/\">Salt</link> (http://saltstack.com), and"
" more mature configuration management tools include <link "
"href=\"http://cfengine.com/\">CFEngine</link> (http://cfengine.com), and "
"<link href=\"http://bcfg2.org/\">Bcfg2</link> (http://bcfg2.org)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml672(title)
msgid "Working with Hardware"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml673(para)
msgid ""
"As for your initial deployment, you should ensure that all hardware is "
"appropriately burned in before adding it to production. Run software that "
"uses the hardware to its limits—maxing out RAM, CPU, disk, and network. Many"
" options are available, and normally double as benchmark software, so you "
"also get a good idea of the performance of your system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml682(title)
msgid "Adding a Compute Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml683(para)
msgid ""
"If you find that you have reached or are reaching the capacity limit of your"
" computing resources, you should plan to add additional compute nodes. "
"Adding more nodes is quite easy. The process for adding compute nodes is the"
" same as when the initial compute nodes were deployed to your cloud: use an "
"automated deployment system to bootstrap the bare-metal server with the "
"operating system and then have a configuration- management system install "
"and configure OpenStack Compute. Once the Compute service has been installed"
" and configured in the same way as the other compute nodes, it automatically"
" attaches itself to the cloud. The cloud controller notices the new node(s) "
"and begins scheduling instances to launch there."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml697(para)
msgid ""
"If your OpenStack Block Storage nodes are separate from your compute nodes, "
"the same procedure still applies because the same queuing and polling system"
" is used in both services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml701(para)
msgid ""
"We recommend that you use the same hardware for new compute and block "
"storage nodes. At the very least, ensure that the CPUs are similar in the "
"compute nodes to not break live migration."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml708(title)
msgid "Adding an Object Storage Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml709(para)
msgid ""
"Adding a new object storage node is different from adding compute or block "
"storage nodes. You still want to initially configure the server by using "
"your automated deployment and configuration-management systems. After that "
"is done, you need to add the local disks of the object storage node into the"
" object storage ring. The exact command to do this is the same command that "
"was used to add the initial disks to the ring. Simply rerun this command on "
"the object storage proxy server for all disks on the new object storage "
"node. Once this has been done, rebalance the ring and copy the resulting "
"ring files to the other storage nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml723(para)
msgid ""
"If your new object storage node has a different number of disks than the "
"original nodes have, the command to add the new node is different from the "
"original commands. These parameters vary from environment to environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml732(title)
msgid "Replacing Components"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml733(para)
msgid ""
"Failures of hardware are common in large-scale deployments such as an "
"infrastructure cloud. Consider your processes and balance time saving "
"against availability. For example, an Object Storage cluster can easily live"
" with dead disks in it for some period of time if it has sufficient "
"capacity. Or, if your compute installation is not full, you could consider "
"live migrating instances off a host with a RAM failure until you have time "
"to deal with the problem."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml746(title)
msgid "Databases"
msgstr "Adatbázisok"

#: ./doc/openstack-ops/ch_ops_maintenance.xml747(para)
msgid ""
"Almost all OpenStack components have an underlying database to store "
"persistent information. Usually this database is MySQL. Normal MySQL "
"administration is applicable to these databases. OpenStack does not "
"configure the databases out of the ordinary. Basic administration includes "
"performance tweaking, high availability, backup, recovery, and repairing. "
"For more information, see a standard MySQL administration guide."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml756(para)
msgid ""
"You can perform a couple of tricks with the database to either more quickly "
"retrieve information or fix a data inconsistency error—for example, an "
"instance was terminated, but the status was not updated in the database. "
"These tricks are discussed throughout this book."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml763(title)
msgid "Database Connectivity"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml764(para)
msgid ""
"Review the component's configuration file to see how each OpenStack "
"component accesses its corresponding database. Look for either "
"<code>sql_connection</code> or simply <code>connection</code>. The following"
" command uses <code>grep</code> to display the SQL connection string for "
"nova, glance, cinder, and keystone:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml778(para)
msgid "The connection strings take this format:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml783(title)
msgid "Performance and Optimizing"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml784(para)
msgid ""
"As your cloud grows, MySQL is utilized more and more. If you suspect that "
"MySQL might be becoming a bottleneck, you should start researching MySQL "
"optimization. The MySQL manual has an entire section dedicated to this "
"topic: <link href=\"http://dev.mysql.com/doc/refman/5.5/en/optimize-"
"overview.html\">Optimization Overview</link> "
"(http://dev.mysql.com/doc/refman/5.5/en/optimize-overview.html)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml796(title)
msgid "HDWMY"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml797(para)
msgid ""
"Here's a quick list of various to-do items for each hour, day, week, month, "
"and year. Please note that these tasks are neither required nor definitive "
"but helpful ideas:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml802(title)
msgid "Hourly"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml805(para)
msgid "Check your monitoring system for alerts and act on them."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml809(para)
msgid "Check your ticket queue for new tickets."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml816(title)
msgid "Daily"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml819(para)
msgid "Check for instances in a failed or weird state and investigate why."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml823(para)
msgid "Check for security patches and apply them as needed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml830(title)
msgid "Weekly"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml835(para)
msgid "User quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml838(para)
msgid "Disk space"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml841(para)
msgid "Image usage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml844(para)
msgid "Large instances"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml847(para)
msgid "Network usage (bandwidth and IP usage)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml833(para)
msgid "Check cloud usage: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml853(para)
msgid "Verify your alert mechanisms are still working."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml860(title)
msgid "Monthly"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml863(para)
msgid "Check usage and trends over the past month."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml867(para)
msgid "Check for user accounts that should be removed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml871(para)
msgid "Check for operator accounts that should be removed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml878(title)
msgid "Quarterly"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml881(para)
msgid "Review usage and trends over the past quarter."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml885(para)
msgid "Prepare any quarterly reports on usage and statistics."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml889(para)
msgid "Review and plan any necessary cloud additions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml893(para)
msgid "Review and plan any major OpenStack upgrades."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml900(title)
msgid "Semiannually"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml903(para)
msgid "Upgrade OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml906(para)
msgid ""
"Clean up after an OpenStack upgrade (any unused or new services to be aware "
"of?)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml914(title)
msgid "Determining Which Component Is Broken"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml915(para)
msgid ""
"OpenStack's collection of different components interact with each other "
"strongly. For example, uploading an image requires interaction from <code"
">nova-api</code>, <code>glance-api</code>, <code>glance-registry</code>, "
"keystone, and potentially <code>swift-proxy</code>. As a result, it is "
"sometimes difficult to determine exactly where problems lie. Assisting in "
"this is the purpose of this section."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml925(title)
msgid "Tailing Logs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml926(para)
msgid ""
"The first place to look is the log file related to the command you are "
"trying to run. For example, if <code>nova list</code> is failing, try "
"tailing a nova log file and running the command again:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml930(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml942(para)
msgid "Terminal 1:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml932(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml944(para)
msgid "Terminal 2:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml934(para)
msgid ""
"Look for any errors or traces in the log file. For more information, see the"
" chapter on <link linkend=\"logging_monitoring\">Logging and "
"Monitoring</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml938(para)
msgid ""
"If the error indicates that the problem is with another component, switch to"
" tailing that component's log file. For example, if nova cannot access "
"glance, look at the glance-api log:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml946(para)
msgid "Wash, rinse, and repeat until you find the core cause of the problem."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml952(title)
msgid "Running Daemons on the CLI"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml953(para)
msgid ""
"Unfortunately, sometimes the error is not apparent from the log files. In "
"this case, switch tactics and use a different command, maybe run the service"
" directly on the command line. For example, if the <code>glance-api</code> "
"service refuses to start and stay running, try launching the daemon from the"
" command line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml962(para)
msgid ""
"The <literal>-H</literal> flag is required when running the daemons with "
"sudo because some daemons will write files relative to the user's home "
"directory, and this write may fail if <literal>-H</literal> is left off."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml961(para)
msgid "This might print the error and cause of the problem.<placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml969(title)
msgid "Example of Complexity"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml970(para)
msgid ""
"One morning, a compute node failed to run any instances. The log files were "
"a bit vague, claiming that a certain instance was unable to be started. This"
" ended up being a red herring because the instance was simply the first "
"instance in alphabetical order, so it was the first instance that nova-"
"compute would touch."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml976(para)
msgid ""
"Further troubleshooting showed that libvirt was not running at all. This "
"made more sense. If libvirt wasn't running, then no instance could be "
"virtualized through KVM. Upon trying to start libvirt, it would silently die"
" immediately. The libvirt logs did not explain why."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml982(para)
msgid ""
"Next, the <code>libvirtd</code> daemon was run on the command line. Finally "
"a helpful error message: it could not connect to d-bus. As ridiculous as it "
"sounds, libvirt, and thus <code>nova-compute</code>, relies on d-bus and "
"somehow d-bus crashed. Simply starting d-bus set the entire chain back on "
"track and soon everything was back up and running."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml994(title)
msgid "Uninstalling"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml995(para)
msgid ""
"While we'd always recommend using your automated deployment system to "
"reinstall systems from scratch, sometimes you do need to remove OpenStack "
"from a system the hard way. Here's how:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1000(para)
msgid "Remove all packages"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1001(para)
msgid "Remove remaining files"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1002(para)
msgid "Remove databases"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1004(para)
msgid ""
"These steps depend on your underlying distribution, but in general you "
"should be looking for \"purge\" commands in your package manager, like "
"<literal>aptitude purge ~c $package</literal>. Following this, you can look "
"for orphaned files in the directories referenced throughout this guide. For "
"uninstalling the database properly, refer to the manual appropriate for the "
"product in use."
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml16(title)
#: ./doc/openstack-ops/app_usecases.xml56(title)
#: ./doc/openstack-ops/app_usecases.xml147(title)
#: ./doc/openstack-ops/app_usecases.xml197(title)
#: ./doc/openstack-ops/app_usecases.xml235(title)
msgid "Resources"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml18(emphasis)
#: ./doc/openstack-ops/bk_ops_guide.xml34(productname)
#: ./doc/openstack-ops/glossary-terms.xml3305(glossterm)
msgid "OpenStack"
msgstr "OpenStack"

#: ./doc/openstack-ops/ch_ops_resources.xml20(para)
msgid ""
"<link href=\"http://docs.openstack.org/trunk/config-"
"reference/content/\">OpenStack Configuration Reference</link> "
"(http://docs.openstack.org/trunk/config-reference/content/section_compute-"
"hypervisors.html)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml25(para)
msgid ""
"<link href=\"http://docs.openstack.org/havana/install-guide/install/apt-"
"debian/content/\">OpenStack Install Guide for Debian 7.0</link> "
"(http://docs.openstack.org/havana/install-guide/install/apt-debian/content/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml30(para)
msgid ""
"<link href=\"http://docs.openstack.org/havana/install-"
"guide/install/yum/content/\">OpenStack Install Guide for Red Hat Enterprise "
"Linux, CentOS, and Fedora</link> (http://docs.openstack.org/havana/install-"
"guide/install/yum/content/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml36(para)
msgid ""
"<link href=\"http://docs.openstack.org/havana/install-"
"guide/install/zypper/content/\">OpenStack Install Guide for openSUSE, SUSE "
"Linux Enterprise Server</link> (http://docs.openstack.org/havana/install-"
"guide/install/zypper/content/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml41(para)
msgid ""
"<link href=\"http://docs.openstack.org/havana/install-"
"guide/install/apt/content/\">OpenStack Install Guide for Ubuntu 12.04 (LTS) "
"Server</link> (http://docs.openstack.org/havana/install-"
"guide/install/apt/content/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml46(para)
msgid ""
"<link href=\"http://docs.openstack.org/admin-guide-"
"cloud/content/\">OpenStack Cloud Administrator Guide</link> "
"(http://docs.openstack.org/admin-guide-cloud/content/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml51(para)
msgid ""
"<link href=\"http://docs.openstack.org/security-guide/content/\">OpenStack "
"Security Guide</link> (http://docs.openstack.org/security-guide/content/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml56(para)
msgid ""
"<link href=\"http://www.packtpub.com/openstack-cloud-computing-cookbook-"
"second-edition/book\">OpenStack Cloud Computing Cookbook</link> "
"(http://www.packtpub.com/openstack-cloud-computing-cookbook-second-"
"edition/book)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml62(emphasis)
msgid "Cloud (General)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml64(para)
msgid ""
"<link "
"href=\"http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf\">NIST"
" Cloud Computing Definition</link> "
"(http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml70(emphasis)
#: ./doc/openstack-ops/glossary-terms.xml3594(glossterm)
msgid "Python"
msgstr "Python"

#: ./doc/openstack-ops/ch_ops_resources.xml72(para)
msgid ""
"<link href=\"http://www.diveintopython.net\">Dive Into Python</link> "
"(http://www.diveintopython.net)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml76(emphasis)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml388(title)
#: ./doc/openstack-ops/glossary-terms.xml3064(glossterm)
msgid "Networking"
msgstr "Hálózatkezelés"

#: ./doc/openstack-ops/ch_ops_resources.xml78(para)
msgid ""
"<link href=\"http://www.pearsonhighered.com/educator/product/TCPIP-"
"Illustrated-Volume-1-The-Protocols/9780321336316.page\">TCP/IP "
"Illustrated</link> (http://www.pearsonhighered.com/educator/product/TCPIP-"
"Illustrated-Volume-1-The-Protocols/9780321336316.page)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml83(para)
msgid ""
"<link href=\"http://nostarch.com/tcpip.htm\">The TCP/IP Guide</link> "
"(http://nostarch.com/tcpip.htm)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml86(para)
msgid ""
"<link href=\"http://danielmiessler.com/study/tcpdump/\">A tcpdump Tutorial "
"and Primer</link> (http://danielmiessler.com/study/tcpdump/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml91(emphasis)
msgid "Systems Administration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml93(para)
msgid ""
"<link href=\"http://www.admin.com/\">UNIX and Linux Systems Administration "
"Handbook</link> (http://www.admin.com/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml98(emphasis)
msgid "Virtualization"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml100(para)
msgid ""
"<link href=\"http://nostarch.com/xen.htm\">The Book of Xen</link> "
"(http://nostarch.com/xen.htm)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml106(para)
msgid ""
"<link href=\"http://docs.puppetlabs.com/\">Puppet Labs Documentation</link> "
"(http://docs.puppetlabs.com/)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml109(para)
msgid ""
"<link href=\"http://www.apress.com/9781430230571\">Pro Puppet</link> "
"(http://www.apress.com/9781430230571)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml14(title)
msgid "Compute Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml15(para)
msgid ""
"In this chapter, we discuss some of the choices you need to consider when "
"building out your compute nodes. Compute nodes form the resource core of the"
" OpenStack Compute cloud, providing the processing, memory, network and "
"storage resources to run instances."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml21(title)
msgid "Choosing a CPU"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml22(para)
msgid ""
"The type of CPU in your compute node is a very important choice. First, "
"ensure that the CPU supports virtualization by way of "
"<emphasis>VT-x</emphasis> for Intel chips and <emphasis>AMD-v</emphasis> for"
" AMD chips."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml26(para)
msgid ""
"Consult the vendor documentation to check for virtualization support. For "
"Intel, read <link title=\"Intel VT-x\" "
"href=\"http://www.intel.com/support/processors/sb/cs-030729.htm\"> Does my "
"processor support Intel® Virtualization Technology?</link> "
"(http://www.intel.com/support/processors/sb/cs-030729.htm). For AMD, read "
"<link title=\"AMD-v\" href=\"http://sites.amd.com/us/business/it-"
"solutions/virtualization/Pages/client-side-virtualization.aspx\"> AMD "
"Virtualization</link> (http://sites.amd.com/us/business/it-"
"solutions/virtualization/Pages/client-side-virtualization.aspx). Note that "
"your CPU may support virtualization but it may be disabled. Consult your "
"BIOS documentation for how to enable CPU features."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml37(para)
msgid ""
"The number of cores that the CPU has also affects the decision. It's common "
"for current CPUs to have up to 12 cores. Additionally, if an Intel CPU "
"supports hyper-threading, those 12 cores are doubled to 24 cores. If you "
"purchase a server that supports multiple CPUs, the number of cores is "
"further multiplied."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml43(title)
msgid "Multithread Considerations"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml44(para)
msgid ""
"Hyper-threading is Intel's proprietary simultaneous multithreading "
"implementation used to improve parallelization on their CPUs. You might "
"consider enabling hyper-threading to improve the performance of multi-"
"threaded applications."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml48(para)
msgid ""
"Whether you should enable hyper-threading on your CPUs depends upon your use"
" case. For example, disabling hyper-threading can be beneficial in intense "
"computing environments. We recommend that you do performance testing with "
"your local workload with both hyper-threading on and off to determine what "
"is more appropriate in your case."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml57(title)
msgid "Choosing a Hypervisor"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml63(para)
msgid ""
"<link title=\"reference manual\" href=\"http://www.linux-"
"kvm.org/\">KVM</link> (http://www.linux-kvm.org/)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml64(para)
msgid ""
"<link title=\"reference manual\" "
"href=\"http://lxc.sourceforge.net/\">LXC</link> "
"(http://lxc.sourceforge.net/)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml65(para)
msgid ""
"<link title=\"reference manual\" href=\"http://wiki.qemu.org/\">QEMU</link> "
"(http://wiki.qemu.org/)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml66(para)
msgid ""
"<link title=\"reference manual\" href=\"https://www.vmware.com/support"
"/vsphere-hypervisor\">VMWare ESX/ESXi</link> (https://www.vmware.com/support"
"/vsphere-hypervisor)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml67(para)
msgid ""
"<link title=\"reference manual\" href=\"http://www.xen.org/\">Xen</link> "
"(http://www.xen.org/)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml68(para)
msgid ""
"<link title=\"reference manual\" href=\"http://technet.microsoft.com/en-"
"us/library/hh831531.aspx\">Hyper-V</link> (http://technet.microsoft.com/en-"
"us/library/hh831531.aspx)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml69(para)
msgid ""
"<link title=\"reference manual\" "
"href=\"http://www.docker.io/\">Docker</link> (http://www.docker.io/)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml58(para)
msgid ""
"A hypervisor provides software to manage virtual machine access to the "
"underlying hardware. The hypervisor creates, manages, and monitors virtual "
"machines. OpenStack Compute supports many hypervisors to various degrees, "
"including: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml72(para)
msgid ""
"Probably the most important factor in your choice of hypervisor is your "
"current usage or experience. Aside from that, there are practical concerns "
"to do with feature parity, documentation, and the level of community "
"experience."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml77(para)
msgid ""
"For example, KVM is the most widely adopted hypervisor in the OpenStack "
"community. Besides KVM, more deployments run Xen, LXC, VMWare, and Hyper-V "
"than the others listed. However, each of these are lacking some feature "
"support or the documentation on how to use them with OpenStack is out of "
"date."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml83(para)
msgid ""
"The best information available to support your choice is found on the <link "
"title=\"reference manual\" "
"href=\"https://wiki.openstack.org/wiki/HypervisorSupportMatrix\">Hypervisor "
"Support Matrix</link> "
"(https://wiki.openstack.org/wiki/HypervisorSupportMatrix) and in the <link "
"title=\"configuration reference\" href=\"http://docs.openstack.org/trunk"
"/config-reference/content/section_compute-hypervisors.html\">configuration "
"reference</link> (http://docs.openstack.org/trunk/config-reference/content"
"/section_compute-hypervisors.html)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml93(para)
msgid ""
"It is also possible to run multiple hypervisors in a single deployment using"
" host aggregates or cells. However, an individual compute node can run only "
"a single hypervisor at a time."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml100(title)
msgid "Instance Storage Solutions"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml101(para)
msgid ""
"As part of the procurement for a compute cluster, you must specify some "
"storage for the disk on which the instantiated instance runs. There are "
"three main approaches to providing this temporary-style storage, and it is "
"important to understand the implications of the choice."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml107(para)
msgid "They are:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml110(para)
msgid "Off compute node storage—shared file system"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml113(para)
msgid "On compute node storage—shared file system"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml116(para)
msgid "On compute node storage—nonshared file system"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml119(para)
msgid ""
"In general, the questions you should ask when selecting storage are as "
"follows:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml123(para)
msgid "What is the platter count you can achieve?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml126(para)
msgid "Do more spindles result in better I/O despite network access?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml130(para)
msgid ""
"Which one results in the best cost-performance scenario you're aiming for?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml134(para)
msgid "How do you manage the storage operationally?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml137(para)
msgid ""
"Many operators use separate compute and storage hosts. Compute services and "
"storage services have different requirements, and compute hosts typically "
"require more CPU and RAM than storage hosts. Therefore, for a fixed budget, "
"it makes sense to have different configurations for your compute nodes and "
"your storage nodes. Compute nodes will be invested in CPU and RAM, and "
"storage nodes will be invested in block storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml146(para)
msgid ""
"However, if you are more restricted in the number of physical hosts you have"
" available for creating your cloud and you want to be able to dedicate as "
"many of your hosts as possible to running instances, it makes sense to run "
"compute and storage on the same machines."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml152(para)
msgid ""
"We'll discuss the three main approaches to instance storage in the next few "
"sections."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml155(title)
msgid "Off Compute Node Storage—Shared File System"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml156(para)
msgid ""
"In this option, the disks storing the running instances are hosted in "
"servers outside of the compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml159(para)
msgid ""
"If you use separate compute and storage hosts, you can treat your compute "
"hosts as \"stateless.\" As long as you don't have any instances currently "
"running on a compute host, you can take it offline or wipe it completely "
"without having any effect on the rest of your cloud. This simplifies "
"maintenance for the compute hosts."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml165(para)
msgid "There are several advantages to this approach:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml168(para)
msgid "If a compute node fails, instances are usually easily recoverable."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml172(para)
msgid "Running a dedicated storage system can be operationally simpler."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml176(para)
msgid "You can scale to any number of spindles."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml179(para)
msgid "It may be possible to share the external storage for other purposes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml184(para)
msgid "The main downsides to this approach are:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml187(para)
msgid ""
"Depending on design, heavy I/O usage from some instances can affect "
"unrelated instances."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml192(para)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml221(para)
msgid "Use of the network can decrease performance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml197(title)
msgid "On Compute Node Storage–Shared File System"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml198(para)
msgid ""
"In this option, each compute node is specified with a significant amount of "
"disk space, but a distributed file system ties the disks from each compute "
"node into a single mount."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml202(para)
msgid ""
"The main advantage of this option is that it scales to external storage when"
" you require additional storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml204(para)
msgid "However, this option has several downsides:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml207(para)
msgid ""
"Running a distributed file system can make you lose your data locality "
"compared with non-shared storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml212(para)
msgid "Recovery of instances is complicated by depending on multiple hosts."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml216(para)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml247(para)
msgid ""
"The chassis size of the compute node can limit the number of spindles able "
"to be used in a compute node."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml226(title)
msgid "On Compute Node Storage–Nonshared File System"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml227(para)
msgid ""
"In this option, each compute node is specified with enough disks to store "
"the instances it hosts."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml229(para)
msgid "There are two main reasons why this is a good idea:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml232(para)
msgid ""
"Heavy I/O usage on one compute node does not affect instances on other "
"compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml236(para)
msgid "Direct I/O access can increase performance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml240(para)
msgid "This has several downsides:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml243(para)
msgid "If a compute node fails, the instances running on that node are lost."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml252(para)
msgid ""
"Migrations of instances from one node to another are more complicated, and "
"rely on features that may not continue to be developed."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml258(para)
msgid "If additional storage is required, this option does not scale."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml262(para)
msgid ""
"Running a shared file system on a storage system apart from the computes "
"nodes is ideal for clouds where reliability and scalability are the most "
"important factors. Running a shared file system on the compute nodes "
"themselves may be best in a scenario where you have to deploy to pre-"
"existing servers for which you have little to no control over their "
"specifications. Running a nonshared file system on the compute nodes "
"themselves is a good option for clouds with high I/O requirements and low "
"concern for reliability."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml273(title)
msgid "Issues with Live Migration"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml274(para)
msgid ""
"We consider live migration an integral part of the operations of the cloud. "
"This feature provides the ability to seamlessly move instances from one "
"physical host to another, a necessity for performing upgrades that require "
"reboots of the compute hosts, but only works well with shared storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml280(para)
msgid ""
"Live migration can also be done with nonshared storage, using a feature "
"known as <emphasis>KVM live block migration</emphasis>. While an earlier "
"implementation of block-based migration in KVM and QEMU was considered "
"unreliable, there is a newer, more reliable implementation of block-based "
"live migration as of QEMU 1.4 and libvirt 1.0.2 that is also compatible with"
" OpenStack. However, none of the authors of this guide have first-hand "
"experience using live block migration."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml291(title)
msgid "Choice of File System"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml292(para)
msgid ""
"If you want to support shared-storage live migration, you need to configure "
"a distributed file system."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml295(para)
msgid "Possible options include:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml298(para)
msgid "NFS (default for Linux)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml304(para)
msgid "MooseFS"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml307(para)
msgid "Lustre"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml310(para)
msgid ""
"We've seen deployments with all, and recommend that you choose the one you "
"are most familiar with operating. If you are not familiar with any of these,"
" choose NFS as it is the easiest to set up and there is extensive community "
"knowledge about it."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml318(title)
msgid "Overcommitting"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml319(para)
msgid ""
"OpenStack allows you to overcommit CPU and RAM on compute nodes. This allows"
" you to increase the number of instances you can have running on your cloud,"
" at the cost of reducing the performance of the instances. OpenStack Compute"
" uses the following ratios by default:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml326(para)
msgid "CPU allocation ratio: 16:1"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml329(para)
msgid "RAM allocation ratio: 1.5:1"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml332(para)
msgid ""
"The default CPU allocation ratio of 16:1 means that the scheduler allocates "
"up to 16 virtual cores per physical core. For example, if a physical node "
"has 12 cores, the scheduler sees 192 available virtual cores. With typical "
"flavor definitions of 4 virtual cores per instance, this ratio would provide"
" 48 instances on a physical node."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml338(para)
msgid ""
"The formula for the number of virtual instances on a compute node is "
"<emphasis>(OR*PC)/VC</emphasis>, where:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml343(emphasis)
msgid "OR"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml345(para)
msgid "CPU overcommit ratio (virtual cores per physical core)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml350(emphasis)
msgid "PC"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml352(para)
msgid "Number of physical cores."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml356(emphasis)
msgid "VC"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml358(para)
msgid "Number of virtual cores per instance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml362(para)
msgid ""
"Similarly, the default RAM allocation ratio of 1.5:1 means that the "
"scheduler allocates instances to a physical node as long as the total amount"
" of RAM associated with the instances is less than 1.5 times the amount of "
"RAM available on the physical node."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml367(para)
msgid ""
"For example, if a physical node has 48 GB of RAM, the scheduler allocates "
"instances to that node until the sum of the RAM associated with the "
"instances reaches 72 GB (such as nine instances, in the case where each "
"instance has 8 GB of RAM)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml372(para)
msgid ""
"You must select the appropriate CPU and RAM allocation ratio for your "
"particular use case."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml376(title)
msgid "Logging"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml377(para)
msgid ""
"Logging is detailed more fully in <xref linkend=\"logging_monitoring\"/>. "
"However, it is an important design consideration to take into account before"
" commencing operations of your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml381(para)
msgid ""
"OpenStack produces a great deal of useful logging information, however, but "
"for the information to be useful for operations purposes, you should "
"consider having a central logging server to send logs to, and a log "
"parsing/analysis system (such as logstash)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml389(para)
msgid ""
"Networking in OpenStack is a complex, multi-faceted challenge. See <xref "
"linkend=\"network_design\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml394(para)
msgid ""
"Compute nodes are the workhorse of your cloud and the place where your "
"users' applications will run. They are likely to be affected by your "
"decisions on what to deploy and how you deploy it. Their requirements should"
" be reflected in the choices you make."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml13(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml96(title)
msgid "Upgrades"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml14(para)
msgid ""
"With the exception of Object Storage, upgrading from one version of "
"OpenStack to another can take a great deal of effort. Until the situation "
"improves, this chapter provides some guidance on the operational aspects "
"that you should consider for performing an upgrade based on detailed steps "
"for a basic architecture."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml20(title)
msgid "Pre-upgrade Testing Environment"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml21(para)
msgid ""
"Probably the most important step of all is the pre-upgrade testing. "
"Especially if you are upgrading immediately after release of a new version, "
"undiscovered bugs might hinder your progress. Some deployers prefer to wait "
"until the first point release is announced. However, if you have a "
"significant deployment, you might follow the development and testing of the "
"release, thereby ensuring that bugs for your use cases are fixed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml30(para)
msgid ""
"Each OpenStack cloud is different, and as a result, even with what may seem "
"a near-identical architecture to this guide, you must still test upgrades "
"between versions in your environment. For this, you need an approximate "
"clone of your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml35(para)
msgid ""
"However, that is not to say that it needs to be the same size or use "
"identical hardware as the production environment—few of us have that luxury."
" It is important to consider the hardware and scale of the cloud you are "
"upgrading, but here are some tips to avoid that incredible cost:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml41(para)
msgid ""
"Use your own cloud. The simplest place to start testing the next version of "
"OpenStack is by setting up a new environment inside your own cloud. This may"
" seem odd—especially the double virtualisation used in running compute "
"nodes—but it's a sure way to very quickly test your configuration."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml46(para)
msgid ""
"Use a public cloud. Especially because your own cloud is unlikely to have "
"sufficient space to scale test to the level of the entire cloud, consider "
"using a public cloud to test the scalability limits of your cloud controller"
" configuration. Most public clouds bill by the hour, which means it can be "
"inexpensive to perform even a test with many nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml52(para)
msgid ""
"Make another storage endpoint on the same system. If you use an external "
"storage plug-in or shared file system with your cloud, in many cases it's "
"possible to test that it works by creating a second share or endpoint. This "
"will enable you to test the system before entrusting the new version onto "
"your storage."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml57(para)
msgid ""
"Watch the network. Even at smaller-scale testing, it should be possible to "
"determine whether something is going horribly wrong in intercomponent "
"communication if you look at the network packets and see too many."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml62(para)
msgid ""
"To actually set up the test environment, there are several methods. Some "
"prefer to do a full manual install using the <link "
"href=\"http://docs.openstack.org\"><citetitle>OpenStack Installation "
"Guides</citetitle></link>, and then see what the final configuration files "
"look like and which packages were installed. Others prefer to create a clone"
" of their automated configuration infrastructure with changed package "
"repository URLs and then alter the configuration until it starts working. "
"Either approach is valid, and which you use depends on experience."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml74(para)
msgid ""
"An upgrade pre-testing system is excellent for getting the configuration to "
"work, however, it is important to note that the historical use of the system"
" and differences in user interaction can affect the success of upgrades, "
"too. We've seen experiences where database migrations encountered a bug "
"(later fixed!) because of slight table differences between fresh Grizzly "
"installs and those that migrated from Folsom to Grizzly."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml81(para)
msgid ""
"Artificial scale testing can go only so far. Once your cloud is upgraded, "
"you'll also need to pay careful attention to the performance aspects of your"
" cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml87(title)
msgid "Preparing for a Roll Back"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml88(para)
msgid ""
"Like all major system upgrades, your upgrade could fail for one or more "
"difficult-to-determine reasons. You should prepare for this situation by "
"leaving the ability to roll back your environment to the previous release, "
"including databases, configuration files, and packages. We provide an "
"example process for rolling back your environment in <xref linkend"
"=\"ops_upgrades-roll-back\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml97(para)
msgid "The upgrade process generally follows these steps:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml100(para)
msgid ""
"Perform some \"cleaning\" of the environment prior to starting the upgrade "
"process to ensure a consistent state. For example, instances not fully "
"purged from the system after deletion may cause indeterminate behavior."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml107(para)
msgid "Read the release notes and documentation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml111(para)
msgid "Find incompatibilities between your versions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml114(para)
msgid ""
"Develop an upgrade procedure and assess it thoroughly using a test "
"environment similar to your production environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml119(para)
msgid "Run the upgrade procedure on the production environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml123(para)
msgid ""
"You can perform an upgrade with operational instances, but this strategy can"
" be dangerous. You might consider using live migration to temporarily "
"relocate instances to other compute nodes while performing upgrades. "
"However, you must ensure database consistency throughout the process, "
"otherwise your environment may become unstable. Also, don't forget to "
"provide sufficient notice to your users, including giving them plenty of "
"time to perform their own backups."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml131(para)
msgid "The following order for service upgrades seems the most successful:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml135(para)
msgid "Upgrade the OpenStack Identity Service (keystone)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml139(para)
msgid "Upgrade the OpenStack Image Service (glance)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml142(para)
msgid "Upgrade OpenStack Compute (nova), including networking components."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml146(para)
msgid "Upgrade OpenStack Block Storage (cinder)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml149(para)
msgid "Upgrade the OpenStack dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml152(para)
msgid "The general upgrade process includes the following steps:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml156(para)
msgid "Create a backup of configuration files and databases."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml160(para)
msgid "Update the configuration files according to the release notes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml164(para)
msgid "Upgrade the packages using your distribution's package manager."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml168(para)
msgid "Stop services, update database schemas, and restart services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml172(para)
msgid "Verify proper operation of your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml177(title)
msgid "How to Perform an Upgrade from Grizzly to Havana - Ubuntu"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml179(para)
msgid ""
"For this section, we assume that you are starting with the architecture "
"provided in the OpenStack <link href=\"http://docs.openstack.org/havana"
"/install-guide/install/apt/content/\">Installation Guide</link> and "
"upgrading to the same architecture for Havana. All nodes should run Ubuntu "
"12.04 LTS. This section primarily addresses upgrading core OpenStack "
"services such as the Identity Service (keystone); Image Service (glance); "
"Compute (nova), including networking; Block Storage (cinder); and the "
"dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml189(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml458(title)
msgid "Impact on Users"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml190(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml459(para)
msgid ""
"The upgrade process will interrupt management of your environment, including"
" the dashboard. If you properly prepare for this upgrade, tenant instances "
"will continue to operate normally."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml196(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml465(title)
msgid "Upgrade Considerations"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml197(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml466(para)
msgid ""
"Always review the <link "
"href=\"https://wiki.openstack.org/wiki/ReleaseNotes/Havana\">release "
"notes</link> before performing an upgrade to learn about newly available "
"features that you may want to enable and deprecated features that you should"
" disable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml204(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml472(title)
msgid "Perform a Backup"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml205(para)
msgid "Save the configuration files on all nodes, as shown here:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml213(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml481(para)
msgid ""
"You can modify this example script on each node to handle different "
"services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml216(para)
msgid "Back up all databases on the controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml220(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml488(title)
msgid "Manage Repositories"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml221(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml489(para)
msgid ""
"On all nodes, remove the repository for Grizzly packages and add the "
"repository for Havana packages:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml226(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml494(para)
msgid "Make sure any automatic updates are disabled."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml230(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml502(title)
msgid "Update Configuration Files"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml231(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml503(para)
msgid ""
"Update the glance configuration on the controller node for compatibility "
"with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml233(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml505(para)
msgid ""
"If not currently present and configured as follows, add or modify the "
"following keys in <filename>/etc/glance/glance-api.conf</filename> and "
"<filename>/etc/glance/glance-registry.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml246(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml533(para)
msgid ""
"If currently present, remove the following key from the [filter:authtoken] "
"section in <filename>/etc/glance/glance-api-paste.ini</filename> and "
"<filename>/etc/glance/glance-registry-paste.ini</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml253(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml540(para)
msgid ""
"Update the nova configuration on all nodes for compatibility with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml255(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml542(para)
msgid ""
"Add the new [database] section and associated key to "
"<filename>/etc/nova/nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml259(para)
msgid ""
"Remove defunct configuration from the [DEFAULT] section in "
"<filename>/etc/nova/nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml263(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml549(para)
msgid ""
"If not already present and configured as follows, add or modify the "
"following keys in <filename>/etc/nova/nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml274(para)
msgid ""
"On all compute nodes, increase the DHCP lease time (measured in seconds) in "
"<filename>/etc/nova/nova.conf</filename> to enable currently active "
"instances to continue leasing their IP addresses during the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml279(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml569(para)
msgid ""
"Setting this value too high may cause more dynamic environments to run out "
"of available IP addresses. Use an appropriate value for your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml286(para)
msgid ""
"You must restart dnsmasq and the networking component of Compute to enable "
"the new DHCP lease time."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml290(para)
msgid ""
"Update the Cinder configuration on the controller and storage nodes for "
"compatibility with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml292(para)
msgid ""
"Add the new [database] section and associated key to "
"<filename>/etc/cinder/cinder.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml296(para)
msgid ""
"Remove defunct configuration from the [DEFAULT] section in "
"<filename>/etc/cinder/cinder.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml300(para)
msgid ""
"If not currently present and configured as follows, add or modify the "
"following key in <filename>/etc/cinder/cinder.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml305(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml591(para)
msgid ""
"Update the dashboard configuration on the controller node for compatibility "
"with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml307(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml593(para)
msgid ""
"The dashboard installation procedure and configuration file changed "
"substantially between Grizzly and Havana. Particularly, if you are running "
"Django 1.5 or later, you must ensure that <filename>/etc/openstack-"
"dashboard/local_settings</filename> contains a correctly configured "
"ALLOWED_HOSTS key that contains a list of hostnames recognized by the "
"dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml314(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml600(para)
msgid ""
"If users will access your dashboard using http://dashboard.example.com, you "
"would set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml317(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml603(para)
msgid ""
"If users will access your dashboard on the local system, you would set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml320(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml606(para)
msgid ""
"If users will access your dashboard using an IP address in addition to a "
"hostname, you would set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml325(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml611(title)
msgid "Upgrade Packages on the Controller Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml326(para)
msgid "Upgrade packages on the controller node to Havana, as shown below:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml331(para)
msgid ""
"Depending on your specific configuration, performing a <code>dist-"
"upgrade</code> may restart services supplemental to your OpenStack "
"environment. For example, if you use Open-iSCSI for Block Storage volumes "
"and the upgrade includes a new <code>open-scsi</code> package, the package "
"manager will restart Open-iSCSI services, which may cause the volumes for "
"your users to be disconnected."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml339(para)
msgid ""
"The package manager will ask you about updating various configuration files."
" We recommend denying these changes. The package manager will append <code"
">.dpkg-dist</code> to the end of newer versions of existing configuration "
"files. You should consider adopting conventions associated with the newer "
"configuration files and merging them with your existing configuration files "
"after completing the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml348(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml633(title)
msgid ""
"Stop Services, Update Database Schemas, and Restart Services on the "
"Controller Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml349(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml634(para)
msgid ""
"Stop each service, run the database synchronization command if necessary to "
"update the associated database schema, and restart each service to apply the"
" new configuration. Some services require additional commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml355(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml640(para)
msgid "OpenStack Identity:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml362(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml647(para)
msgid "OpenStack Image Service:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml370(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml655(para)
msgid "OpenStack Compute:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml386(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml671(para)
msgid "OpenStack Block Storage:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml394(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml679(para)
msgid ""
"The controller node update is complete. Now you can upgrade the compute "
"nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml398(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml683(title)
msgid "Upgrade Packages and Restart Services on the Compute Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml399(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml684(para)
msgid "Upgrade packages on the compute nodes to Havana:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml401(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml432(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml687(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml703(para)
msgid ""
"Make sure you have removed the repository for Grizzly packages and added the"
" repository for Havana packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml406(para)
msgid ""
"Due to a packaging issue, this command may fail with the following error:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml412(para)
msgid "You can fix this issue by using the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml416(para)
msgid ""
"The packaging system will ask about updating the <filename>/etc/nova/api-"
"paste.ini</filename> file. As with the controller upgrade, we recommend "
"denying these changes and reviewing the <code>.dpkg-dist</code> file after "
"completing the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml421(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml693(para)
msgid "Restart Compute services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml427(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml699(title)
msgid "Upgrade Packages and Restart Services on the Block Storage Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml428(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml700(para)
msgid "Upgrade packages on the storage nodes to Havana:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml435(para)
msgid ""
"The packaging system will ask about updating the <filename>/etc/cinder/api-"
"paste.ini</filename> file. Like the controller upgrade, we recommend denying"
" these changes and reviewing the <code>.dpkg-dist</code> file after "
"completing the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml440(para)
msgid "Restart Block Storage services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml445(title)
msgid ""
"How to Perform an Upgrade from Grizzly to Havana—Red Hat Enterprise Linux "
"and Derivatives"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml447(para)
msgid ""
"For this section, we assume that you are starting with the architecture "
"provided in the OpenStack <link href=\"http://docs.openstack.org/havana"
"/install-guide/install/yum/content/\">Installation Guide</link> and "
"upgrading to the same architecture for Havana. All nodes should run Red Hat "
"Enterprise Linux 6.4 or compatible derivatives. Newer minor releases should "
"also work. This section primarily addresses upgrading core OpenStack "
"services such as the Identity Service (keystone); Image Service (glance); "
"Compute (nova), including networking; Block Storage (cinder); and the "
"dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml473(para)
msgid "First, save the configuration files on all nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml484(para)
msgid "Next, back up all databases on the controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml497(para)
msgid ""
"Consider checking for newer versions of the <link "
"href=\"http://repos.fedorapeople.org/repos/openstack/openstack-"
"havana\">Havana repository</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml546(para)
msgid ""
"Remove defunct database configuration from "
"<filename>/etc/nova/nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml562(para)
msgid ""
"On all compute nodes, increase the DHCP lease time (measured in seconds) in "
"<filename>/etc/nova/nova.conf</filename> to enable currently active "
"instances to continue leasing their IP addresses during the upgrade process,"
" as shown here:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml573(para)
msgid ""
"You must restart dnsmasq and the nova networking service to enable the new "
"DHCP lease time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml577(para)
msgid ""
"Update the cinder configuration on the controller and storage nodes for "
"compatibility with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml579(para)
msgid ""
"Add the new [database] section and associated key to "
"<filename>/etc/cinder/cinder.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml583(para)
msgid ""
"Remove defunct database configuration from "
"<filename>/etc/cinder/cinder.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml586(para)
msgid ""
"If not currently present and configured as follows, add or modify the "
"following key in <filename>/etc/cinder/cinder.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml612(para)
msgid "Upgrade packages on the controller node to Havana:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml615(para)
msgid ""
"Some services may terminate with an error during the package upgrade "
"process. If this may cause a problem with your environment, consider "
"stopping all services before upgrading them to Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml621(para)
msgid ""
"The package manager will append <code>.rpmnew</code> to the end of newer "
"versions of existing configuration files. You should consider adopting "
"conventions associated with the newer configuration files and merging them "
"with your existing configuration files after completing the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml628(para)
msgid "Install the OpenStack SELinux package on the controller node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml690(para)
msgid "Install the OpenStack SELinux package on the compute nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml706(para)
msgid "Install the OpenStack SELinux package on the storage nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml709(para)
msgid "Restart Block Storage services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml714(title)
msgid "Cleaning Up and Final Configuration File Updates"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml715(para)
msgid ""
"On all distributions, you need to perform some final tasks to complete the "
"upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml717(para)
msgid ""
"Decrease DHCP timeouts by modifying <filename>/etc/nova/nova.conf</filename>"
" on the compute nodes back to the original value for your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml720(para)
msgid ""
"Update all of the <filename>.ini</filename> files to match passwords and "
"pipelines as required for Havana in your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml723(para)
msgid ""
"After a migration, your users will see different results from <systemitem "
"class=\"service\">nova image-list</systemitem> and <systemitem "
"class=\"service\">glance image-list</systemitem> unless you match up "
"policies for access to private images. To do so, edit "
"<filename>/etc/glance/policy.json</filename> and "
"<filename>/etc/nova/policy.json</filename> to contain "
"<code>\"context_is_admin\": \"role:admin\",</code> which limits access to "
"private images for projects."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml731(para)
msgid ""
"Thoroughly test the environment, and then let your users know that their "
"cloud is running normally again."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml735(title)
msgid "Rolling Back a Failed Upgrade"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml736(para)
msgid ""
"While we do not wish this fate upon anyone, upgrades involve complex "
"operations and can fail. This section provides guidance for rolling back to "
"a previous release of OpenStack. Although only tested on Ubuntu, other "
"distributions follow a similar procedure."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml741(para)
msgid ""
"In this section, we consider only the most immediate case: you have taken "
"down production management services in preparation for an upgrade, completed"
" part of the upgrade process, discovered one or more problems not "
"encountered during testing, and need to roll back your environment to the "
"original \"known good\" state. We specifically assume that you did not make "
"any state changes after attempting the upgrade process: no new instances, "
"networks, storage volumes, etc."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml749(para)
msgid ""
"Within this scope, you need to accomplish three main steps to successfully "
"roll back your environment:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml752(para)
msgid "Roll back configuration files"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml753(para)
msgid "Roll back databases"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml754(para)
msgid "Roll back packages"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml756(para)
msgid ""
"The upgrade instructions provided in earlier sections ensure that you have "
"proper backups of your databases and configuration files. You should read "
"through this section carefully and verify that you have the requisite "
"backups to restore. Rolling back upgrades is a tricky process because "
"distributions tend to put much more effort into testing upgrades than "
"downgrades. Broken downgrades often take significantly more effort to "
"troubleshoot and, hopefully, resolve than broken upgrades. Only you can "
"weigh the risks of trying to push a failed upgrade forward versus rolling it"
" back. Generally, we consider rolling back the very last option."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml766(para)
msgid ""
"The steps described below for Ubuntu have worked on at least one production "
"environment, but they may not work for all environments."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml770(title)
msgid "Perform the Roll Back from Havana to Grizzly"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml772(para)
msgid "Stop all OpenStack services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml775(para)
msgid ""
"Copy contents of configuration backup directories "
"<filename>/etc/&lt;service&gt;.grizzly</filename> that you created during "
"the upgrade process back to <filename>/etc/&lt;service&gt;</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml781(para)
msgid ""
"Restore databases from the backup file <filename>grizzly-db-"
"backup.sql</filename> that you created with <placeholder-1/> during the "
"upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml786(para)
msgid ""
"If you created this backup using the <placeholder-1/> flag as instructed, "
"you can proceed to the next step. If you omitted this flag, MySQL will "
"revert all of the tables that existed in Grizzly, but not drop any tables "
"created during the database migration for Havana. In this case, you need to "
"manually determine which tables should not exist and drop them to prevent "
"issues with your next upgrade attempt."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml797(para)
msgid "Downgrade OpenStack packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml798(para)
msgid ""
"We consider downgrading packages by far the most complicated step and highly"
" dependent on the distribution as well as overall administration of the "
"system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml805(para)
msgid ""
"Determine the OpenStack packages installed on your system. This is done "
"using <placeholder-1/>, filtering for OpenStack packages, filtering again to"
" omit packages explicitly marked in the <code>deinstall</code> state, and "
"saving the final output to a file. For example, the following command covers"
" a controller node with keystone, glance, nova, neutron, and cinder:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml852(para)
msgid ""
"Depending on the type of server, the contents and order of your package list"
" may vary from this example."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml858(para)
msgid ""
"You can determine the package versions available for reversion by using "
"<placeholder-1/>. If you removed the Grizzly repositories, you must first "
"reinstall them and run <placeholder-2/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml883(para)
msgid ""
"This tells us the currently installed version of the package, newest "
"candidate version, and all versions along with the repository that contains "
"each version. Look for the appropriate Grizzly version, in this case "
"<code>1:2013.1.4-0ubuntu1~cloud0</code>. The process of manually picking "
"through this list of packages is rather tedious and prone to errors. You "
"should consider using the following script to help with this process:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml900(para)
msgid ""
"If you decide to continue this step manually, don't forget to change "
"<code>neutron</code> to <code>quantum</code> where applicable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml907(para)
msgid ""
"Use <placeholder-1/> to install specific versions of each package by "
"specifying <code>&lt;package-name&gt;=&lt;version&gt;</code>. The script in "
"the previous step conveniently created a list of "
"<code>package=version</code> pairs for you."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml914(para)
msgid ""
"This completes the roll back procedure. You should remove the Havana "
"repository and run <placeholder-1/> to prevent accidental upgrades until you"
" solve whatever issue caused you to roll back your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml14(title)
msgid "Logging and Monitoring"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml15(para)
msgid ""
"As an OpenStack cloud is composed of so many different services, there are a"
" large number of log files. This chapter aims to assist you in locating and "
"working with them and describes other ways to track the status of your "
"deployment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml20(title)
msgid "Where Are the Logs?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml21(para)
msgid ""
"Most services use the convention of writing their log files to "
"subdirectories of the <code>/var/log directory</code>, as listed in <link "
"linkend=\"openstack-log-locations\">OpenStack Log Locations</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml25(caption)
msgid "OpenStack Log Locations"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml28(th)
msgid "Node Type"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml29(th)
msgid "Service"
msgstr "Szolgáltatás"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml30(th)
msgid "Log Location"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml35(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml44(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml53(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml62(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml71(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml80(para)
msgid "Cloud controller"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml37(code)
msgid "nova-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml40(code)
msgid "/var/log/nova"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml46(code)
msgid "glance-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml49(code)
msgid "/var/log/glance"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml55(code)
msgid "cinder-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml58(code)
msgid "/var/log/cinder"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml64(code)
msgid "keystone-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml67(code)
msgid "/var/log/keystone"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml73(code)
msgid "neutron-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml76(code)
msgid "/var/log/neutron"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml81(para)
#: ./doc/openstack-ops/glossary-terms.xml2180(glossterm)
msgid "horizon"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml83(code)
msgid "/var/log/apache2/"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml87(para)
msgid "All nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml88(para)
msgid "misc (swift, dnsmasq)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml91(code)
msgid "/var/log/syslog"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml95(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml102(para)
msgid "Compute nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml96(para)
#: ./doc/openstack-ops/glossary-terms.xml2717(glossterm)
msgid "libvirt"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml98(code)
msgid "/var/log/libvirt/libvirtd.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml103(para)
msgid "Console (boot up messages) for VM instances:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml105(code)
msgid "/var/lib/nova/instances/instance-&lt;instance id&gt;/console.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml110(para)
msgid "Block Storage nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml111(para)
msgid "cinder-volume"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml113(code)
msgid "/var/log/cinder/cinder-volume.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml120(title)
msgid "Reading the Logs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml121(para)
msgid ""
"OpenStack services use the standard logging levels, at increasing severity: "
"DEBUG, INFO, AUDIT, WARNING, ERROR, CRITICAL, and TRACE. That is, messages "
"only appear in the logs if they are more \"severe\" than the particular log "
"level, with DEBUG allowing all log statements through. For example, TRACE is"
" logged only if the software has a stack trace, while INFO is logged for "
"every message including those that are only for information."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml129(para)
msgid ""
"To disable DEBUG-level logging, edit "
"<filename>/etc/nova/nova.conf</filename> as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml132(para)
msgid ""
"Keystone is handled a little differently. To modify the logging level, edit "
"the <filename>/etc/keystone/logging.conf</filename> file and look at the "
"<code>logger_root</code> and <code>handler_file</code> sections."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml137(para)
msgid ""
"Logging for horizon is configured in "
"<filename>/etc/openstack_dashboard/local_settings.py</filename>. Because "
"horizon is a Django web application, it follows the <link title=\"Django "
"Logging\" "
"href=\"https://docs.djangoproject.com/en/dev/topics/logging/\">Django "
"Logging</link> (https://docs.djangoproject.com/en/dev/topics/logging/) "
"framework conventions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml145(para)
msgid ""
"The first step in finding the source of an error is typically to search for "
"a CRITICAL, TRACE, or ERROR message in the log starting at the bottom of the"
" log file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml148(para)
msgid ""
"Here is an example of a CRITICAL log message, with the corresponding TRACE "
"(Python traceback) immediately following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml181(para)
msgid ""
"In this example, cinder-volumes failed to start and has provided a stack "
"trace, since its volume back-end has been unable to set up the storage "
"volume—probably because the LVM volume that is expected from the "
"configuration does not exist."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml186(para)
msgid "Here is an example error log:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml189(para)
msgid ""
"In this error, a nova service has failed to connect to the RabbitMQ server, "
"because it got a connection refused error."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml194(title)
msgid "Tracing Instance Requests"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml195(para)
msgid ""
"When an instance fails to behave properly, you will often have to trace "
"activity associated with that instance across the log files of various "
"<code>nova-*</code> services, and across both the cloud controller and "
"compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml200(para)
msgid ""
"The typical way is to trace the UUID associated with an instance across the "
"service logs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml202(para)
msgid "Consider the following example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml209(para)
msgid ""
"Here the ID associated with the instance is "
"<code>faf7ded8-4a46-413b-b113-f19590746ffe</code>. If you search for this "
"string on the cloud controller in the "
"<filename>/var/log/nova-*.log</filename> files, it appears in <filename"
">nova-api.log</filename> and <filename>nova-scheduler.log</filename>. If you"
" search for this on the compute nodes in "
"<filename>/var/log/nova-*.log</filename>, it appears in <filename>nova-"
"network.log</filename> and <filename>nova-compute.log</filename>. If no "
"ERROR or CRITICAL messages appear, the most recent log entry that reports "
"this may provide a hint about what has gone wrong."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml223(title)
msgid "Adding Custom Logging Statements"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml224(para)
msgid ""
"If there is not enough information in the existing logs, you may need to add"
" your own custom logging statements to the <code>nova-*</code> services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml227(para)
msgid ""
"The source files are located in <filename>/usr/lib/python2.7/dist-"
"packages/nova</filename>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml230(para)
msgid ""
"To add logging statements, the following line should be near the top of the "
"file. For most files, these should already be there:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml235(para)
msgid "To add a DEBUG logging statement, you would do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml237(para)
msgid ""
"You may notice that all the existing logging messages are preceded by an "
"underscore and surrounded by parentheses, for example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml241(para)
msgid ""
"This formatting is used to support translation of logging messages into "
"different languages using the <link "
"href=\"http://docs.python.org/2/library/gettext.html\">gettext</link> "
"(http://docs.python.org/2/library/gettext.html) internationalization "
"library. You don't need to do this for your own custom log messages. "
"However, if you want to contribute the code back to the OpenStack project "
"that includes logging statements, you must surround your log messages with "
"underscore and parentheses."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml253(title)
msgid "RabbitMQ Web Management Interface or rabbitmqctl"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml255(para)
msgid ""
"Aside from connection failures, RabbitMQ log files are generally not useful "
"for debugging OpenStack related issues. Instead, we recommend you use the "
"RabbitMQ web management interface. Enable it on your cloud controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml262(para)
msgid ""
"The RabbitMQ web management interface is accessible on your cloud controller"
" at http://localhost:55672."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml265(para)
msgid ""
"Ubuntu 12.04 installs RabbitMQ version 2.7.1, which uses port 55672. "
"RabbitMQ versions 3.0 and above use port 15672 instead. You can check which "
"version of RabbitMQ you have running on your local Ubuntu machine by doing:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml273(para)
msgid ""
"An alternative to enabling the RabbitMQ web management interface is to use "
"the <placeholder-1/> commands. For example, <placeholder-2/> displays any "
"messages left in the queue. If any messages are there, it's a possible sign "
"that cinder services didn't connect properly to rabbitmq and might have to "
"be restarted."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml280(para)
msgid ""
"Items to monitor for RabbitMQ include the number of items in each of the "
"queues and the processing time statistics for the server."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml285(title)
msgid "Centrally Managing Logs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml286(para)
msgid ""
"Because your cloud is most likely composed of many servers, you must check "
"logs on each of those servers to properly piece an event together. A better "
"solution is to send the logs of all servers to a central location so that "
"they can all be accessed from the same area."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml291(para)
msgid ""
"Ubuntu uses rsyslog as the default logging service. Since it is natively "
"able to send logs to a remote location, you don't have to install anything "
"extra to enable this feature, just modify the configuration file. In doing "
"this, consider running your logging over a management network or using an "
"encrypted VPN to avoid interception."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml299(title)
msgid "rsyslog Client Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml300(para)
msgid ""
"To begin, configure all OpenStack components to log to syslog in addition to"
" their standard log file location. Also configure each component to log to a"
" different syslog facility. This makes it easier to split the logs into "
"individual components on the central server."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml306(para)
msgid "<filename>nova.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml310(para)
msgid ""
"<filename>glance-api.conf</filename> and <filename>glance-"
"registry.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml315(para)
msgid "<filename>cinder.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml319(para)
msgid "<filename>keystone.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml324(para)
msgid "By default, Object Storage logs to syslog."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml325(para)
msgid ""
"Next, create <filename>/etc/rsyslog.d/client.conf</filename> with the "
"following line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml328(para)
msgid ""
"This instructs rsyslog to send all logs to the IP listed. In this example, "
"the IP points to the cloud controller."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml333(title)
msgid "rsyslog Server Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml334(para)
msgid ""
"Designate a server as the central logging server. The best practice is to "
"choose a server that is solely dedicated to this purpose. Create a file "
"called <filename>/etc/rsyslog.d/server.conf</filename> with the following "
"contents:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml362(para)
msgid ""
"This example configuration handles the nova service only. It first "
"configures rsyslog to act as a server that runs on port 514. Next, it "
"creates a series of logging templates. Logging templates control where "
"received logs are stored. Using the example above, a nova log from "
"c01.example.com goes to the following locations:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml371(filename)
msgid "/var/log/rsyslog/c01.example.com/nova.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml376(filename)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml389(filename)
msgid "/var/log/rsyslog/nova.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml380(para)
msgid "This is useful, as logs from c02.example.com go to:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml384(filename)
msgid "/var/log/rsyslog/c02.example.com/nova.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml393(para)
msgid ""
"You have an individual log file for each compute node as well as an "
"aggregated log that contains nova logs from all nodes."
msgstr ""

#. FIXME This section needs updating, especially with the advent of
#.          ceilometer
#: ./doc/openstack-ops/ch_ops_log_monitor.xml401(title)
#: ./doc/openstack-ops/glossary-terms.xml4297(glossterm)
msgid "StackTach"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml402(para)
msgid ""
"StackTach is a tool created by Rackspace to collect and report the "
"notifications sent by <code>nova</code>. Notifications are essentially the "
"same as logs but can be much more detailed. A good overview of notifications"
" can be found at <link title=\"StackTach GitHub repo\" "
"href=\"https://wiki.openstack.org/wiki/SystemUsageData\">System Usage "
"Data</link> (https://wiki.openstack.org/wiki/SystemUsageData)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml410(para)
msgid ""
"To enable nova to send notifications, add the following to "
"<filename>nova.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml414(para)
msgid ""
"Once <code>nova</code> is sending notifications, install and configure "
"StackTach. Since StackTach is relatively new and constantly changing, "
"installation instructions would quickly become outdated. Please refer to the"
" <link href=\"https://github.com/rackerlabs/stacktach\">StackTach GitHub "
"repo</link> (https://github.com/rackerlabs/stacktach) for instructions as "
"well as a demo video."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml424(title)
msgid "Monitoring"
msgstr "Monitorozás"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml425(para)
msgid ""
"There are two types of monitoring: watching for problems and watching usage "
"trends. The former ensures that all services are up and running, creating a "
"functional cloud. The latter involves monitoring resource usage over time in"
" order to make informed decisions about potential bottlenecks and upgrades."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml432(title)
msgid "Nagios"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml433(para)
msgid ""
"Nagios is an open source monitoring service. It's capable of executing "
"arbitrary commands to check the status of server and network services, "
"remotely executing arbitrary commands directly on servers, and allowing "
"servers to push notifications back in the form of passive monitoring. Nagios"
" has been around since 1999. Although newer monitoring services are "
"available, Nagios is a tried-and-true systems administration staple."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml444(title)
msgid "Process Monitoring"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml445(para)
msgid ""
"A basic type of alert monitoring is to simply check and see whether a "
"required process is running. For example, ensure that the <code>nova-"
"api</code> service is running on the cloud controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml456(para)
msgid ""
"You can create automated alerts for critical processes by using Nagios and "
"NRPE. For example, to ensure that the <code>nova-compute</code> process is "
"running on compute nodes, create an alert on your Nagios server that looks "
"like this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml469(para)
msgid ""
"Then on the actual compute node, create the following NRPE configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml472(para)
msgid ""
"Nagios checks that at least one nova-compute service is running at all "
"times."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml476(title)
msgid "Resource Alerting"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml477(para)
msgid ""
"Resource alerting provides notifications when one or more resources are "
"critically low. While the monitoring thresholds should be tuned to your "
"specific OpenStack environment, monitoring resource usage is not specific to"
" OpenStack at all–any generic type of alert will work fine."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml483(para)
msgid "Some of the resources that you want to monitor include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml487(para)
msgid "Disk usage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml490(para)
msgid "Server load"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml493(para)
msgid "Memory usage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml496(para)
msgid "Network I/O"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml499(para)
msgid "Available vCPUs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml502(para)
msgid ""
"For example, to monitor disk capacity on a compute node with Nagios, add the"
" following to your Nagios configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml512(para)
msgid "On the compute node, add the following to your NRPE configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml515(para)
msgid ""
"Nagios alerts you with a WARNING when any disk on the compute node is 80 "
"percent full and CRITICAL when 90 percent is full."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml520(title)
msgid "Metering and Telemetry with Ceilometer"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml521(para)
msgid ""
"An integrated OpenStack project, code-named ceilometer, collects metering "
"data and provides alerts for Compute, Storage, and Networking. Data "
"collected by the metering system could be used for billing. Depending on "
"deployment configuration, metered data may be accessible to users based on "
"the deployment configuration. The Telemetry service provides a REST API "
"documented at <link href=\"http://api.openstack.org/api-ref-"
"telemetry.html\">http://api.openstack.org/api-ref-telemetry.html</link>. You"
" can read more about the project at <link "
"href=\"http://docs.openstack.org/developer/ceilometer/\">http://docs.openstack.org/developer/ceilometer/</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml534(title)
msgid "OpenStack-Specific Resources"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml535(para)
msgid ""
"Resources such as memory, disk, and CPU are generic resources that all "
"servers (even non-OpenStack servers) have and are important to the overall "
"health of the server. When dealing with OpenStack specifically, these "
"resources are important for a second reason: ensuring that enough are "
"available to launch instances. There are a few ways you can see OpenStack "
"resource usage."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml543(para)
msgid "The first is through the <code>nova</code> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml546(para)
msgid ""
"This command displays a list of how many instances a tenant has running and "
"some light usage statistics about the combined instances. This command is "
"useful for a quick overview of your cloud, but it doesn't really get into a "
"lot of details."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml551(para)
msgid ""
"Next, the <code>nova</code> database contains three tables that store usage "
"information."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml553(para)
msgid ""
"The <code>nova.quotas</code> and <code>nova.quota_usages</code> tables store"
" quota information. If a tenant's quota is different from the default quota "
"settings, its quota is stored in the <code>nova.quotas</code> table. For "
"example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml573(para)
msgid ""
"The <code>nova.quota_usages</code> table keeps track of how many resources "
"the tenant currently has in use:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml588(para)
msgid ""
"By comparing a tenant's hard limit with their current resource usage, you "
"can see their usage percentage. For example, if this tenant is using 1 "
"floating IP out of 10, then they are using 10 percent of their floating IP "
"quota. Rather than doing the calculation manually, you can use SQL or the "
"scripting language of your choice and create a formatted report:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml617(para)
msgid ""
"The above information was generated by using a custom script that can be "
"found on GitHub (https://github.com/cybera/novac/blob/dev/libexec/novac-"
"quota-report)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml621(para)
msgid ""
"This script is specific to a certain OpenStack installation and must be "
"modified to fit your environment. However, the logic should easily be "
"transferable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml628(title)
msgid "Intelligent Alerting"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml629(para)
msgid ""
"Intelligent alerting can be thought of as a form of continuous integration "
"for operations. For example, you can easily check to see whether the Image "
"Service is up and running by ensuring that the <code>glance-api</code> and "
"<code>glance-registry</code> processes are running or by seeing whether "
"<code>glace-api</code> is responding on port 9292."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml636(para)
msgid ""
"But how can you tell whether images are being successfully uploaded to the "
"Image Service? Maybe the disk that Image Service is storing the images on is"
" full or the S3 backend is down. You could naturally check this by doing a "
"quick image upload:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml651(para)
msgid ""
"By taking this script and rolling it into an alert for your monitoring "
"system (such as Nagios), you now have an automated way of ensuring that "
"image uploads to the Image Catalog are working."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml656(para)
msgid ""
"You must remove the image after each test. Even better, test whether you can"
" successfully delete an image from the Image Service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml660(para)
msgid ""
"Intelligent alerting takes considerably more time to plan and implement than"
" the other alerts described in this chapter. A good outline to implement "
"intelligent alerting is:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml666(para)
msgid "Review common actions in your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml669(para)
msgid "Create ways to automatically test these actions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml673(para)
msgid "Roll these tests into an alerting system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml677(para)
msgid "Some other examples for Intelligent Alerting include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml681(para)
msgid "Can instances launch and be destroyed?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml684(para)
msgid "Can users be created?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml687(para)
msgid "Can objects be stored and deleted?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml690(para)
msgid "Can volumes be created and destroyed?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml695(title)
msgid "Trending"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml696(para)
msgid ""
"Trending can give you great insight into how your cloud is performing day to"
" day. You can learn, for example, if a busy day was simply a rare occurrence"
" or if you should start adding new compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml700(para)
msgid ""
"Trending takes a slightly different approach than alerting. While alerting "
"is interested in a binary result (whether a check succeeds or fails), "
"trending records the current state of something at a certain point in time. "
"Once enough points in time have been recorded, you can see how the value has"
" changed over time."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml707(para)
msgid ""
"All of the alert types mentioned earlier can also be used for trend "
"reporting. Some other trend examples include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml712(para)
msgid "The number of instances on each compute node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml716(para)
msgid "The types of flavors in use"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml719(para)
msgid "The number of volumes in use"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml722(para)
msgid "The number of Object Storage requests each hour"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml726(para)
msgid "The number of nova-api requests each hour"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml730(para)
msgid "The I/O statistics of your storage services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml734(para)
msgid ""
"As an example, recording <code>nova-api</code> usage can allow you to track "
"the need to scale your cloud controller. By keeping an eye on <code>nova-"
"api</code> requests, you can determine whether you need to spawn more nova-"
"api processes or go as far as introducing an entirely new server to run "
"<code>nova-api</code>. To get an approximate count of the requests, look for"
" standard INFO messages in <code>/var/log/nova/nova-api.log</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml743(para)
msgid "# grep INFO /var/log/nova/nova-api.log | wc"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml744(para)
msgid ""
"You can obtain further statistics by looking for the number of successful "
"requests:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml746(para)
msgid "# grep \" 200 \" /var/log/nova/nova-api.log | wc"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml748(para)
msgid ""
"By running this command periodically and keeping a record of the result, you"
" can create a trending report over time that shows whether your <code>nova-"
"api</code> usage is increasing, decreasing, or keeping steady."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml753(para)
msgid ""
"A tool such as collectd can be used to store this information. While "
"collectd is out of the scope of this book, a good starting point would be to"
" use collectd to store the result as a COUNTER data type. More information "
"can be found in collectd's documentation "
"(https://collectd.org/wiki/index.php/Data_source)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml764(para)
msgid ""
"For stable operations, you want to detect failure promptly and determine "
"causes efficiently. With a distributed system, it's even more important to "
"track the right items to meet a service-level target. Learning where these "
"logs are located in the file system or API gives you an advantage. This "
"chapter also showed how to read, interpret, and manipulate information from "
"OpenStack services so that you can monitor effectively."
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml14(title)
msgid "Example Architectures"
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml15(para)
msgid ""
"To understand the possibilities OpenStack offers it's best to start with "
"basic architectures that are tried-and-true and have been tested in "
"production environments. We offer two such examples with basic pivots on the"
" base operating system (Ubuntu and Red Hat Enterprise Linux) and the "
"networking architectures. There are other differences between these two "
"examples, but you should find the considerations made for the choices in "
"each as well as a rationale for why it worked well in a given environment."
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml22(para)
msgid ""
"Because OpenStack is highly configurable, with many different back-ends and "
"network configuration options, it is difficult to write documentation that "
"covers all possible OpenStack deployments. Therefore, this guide defines "
"example architectures to simplify the task of documenting, as well as to "
"provide the scope for this guide. Both of the offered architecture examples "
"are currently running in production and serving users."
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml29(para)
msgid ""
"As always, refer to the Glossary if you are unclear about any of the "
"terminology mentioned in these architectures."
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml34(title)
msgid "Parting Thoughts on Architectures"
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml35(para)
msgid ""
"With so many considerations and options available our hope is to provide a "
"few clearly-marked and tested paths for your OpenStack exploration. If "
"you're looking for additional ideas, check out the <link linkend=\"use-"
"cases\">Use Cases</link> appendix, the <link "
"href=\"http://docs.openstack.org/\">OpenStack Installation Guides</link>, or"
" the <link href=\"http://openstack.org/user-stories/\">OpenStack User "
"Stories page</link>."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/part_architecture.xml53(None)
msgid ""
"@@image: 'figures/osog_0001online.png'; md5=94d7426a1c2949fb3439f37d2b120e4b"
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml13(title)
msgid "Architecture"
msgstr "Architektúra"

#: ./doc/openstack-ops/part_architecture.xml15(para)
msgid ""
"Designing an OpenStack cloud is a great achievement. It requires a robust "
"understanding of the requirements and needs of the cloud's users to "
"determine the best possible configuration to meet them. OpenStack provides a"
" great deal of flexibility to achieve your needs, and this part of the book "
"aims to shine light on many of the decisions you need to make during the "
"process."
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml23(para)
msgid ""
"To design, deploy, and configure OpenStack, administrators must understand "
"the logical architecture. A diagram can help you envision all the integrated"
" services within OpenStack and how they interact with each other."
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml27(para)
msgid "OpenStack modules are one of the following types:"
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml30(para)
msgid ""
"Daemon. Runs as a background process. On Linux platforms, a daemon is "
"usually installed as a service."
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml34(para)
msgid "Script. Installs a virtual environment and runs tests."
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml37(para)
msgid ""
"Command-line interface (CLI). Enables users to submit API calls to OpenStack"
" services through commands."
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml41(para)
msgid ""
"As shown, end users can interact through the dashboard, CLIs, and APIs. All "
"services authenticate through a common Identity Service and individual "
"services interact with each other through public APIs, except where "
"privileged administrator commands are necessary. The diagram shows the most "
"common, but not the only logical architecture for an OpenStack cloud."
msgstr ""

#: ./doc/openstack-ops/part_architecture.xml49(title)
msgid "OpenStack Havana Logical Architecture"
msgstr ""

#: ./doc/openstack-ops/ch_ops_dochistory.xml15(title)
msgid "Document Change History"
msgstr ""

#: ./doc/openstack-ops/ch_ops_dochistory.xml17(para)
msgid ""
"This version of the document replaces and obsoletes all previous versions. "
"The following table describes the most recent changes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml14(title)
msgid "Advanced Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml15(para)
msgid ""
"OpenStack is intended to work well across a variety of installation flavors,"
" from very small private clouds to large public clouds. To achieve this, the"
" developers add configuration options to their code that allow the behaviour"
" of the various components to be tweaked depending on your needs. "
"Unfortunately, it is not possible to cover all possible deployments with the"
" default configuration values."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml22(para)
msgid ""
"At the time of writing, OpenStack has more than 1,500 configuration options."
" You can see them documented at <link href=\"http://docs.openstack.org/trunk"
"/config-reference/content/config_overview.html\">the OpenStack configuration"
" reference guide</link>. This chapter cannot hope to document all of these, "
"but we do try to introduce the important concepts so that you know where to "
"go digging for more information."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml29(title)
msgid "Differences Between Various Drivers"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml30(para)
msgid ""
"Many OpenStack projects implement a driver layer, and each of these drivers "
"will implement their own configuration options. For example in OpenStack "
"Compute (nova), there are various hypervisor drivers implemented—libvirt, "
"xenserver, hyper-v, and vmware, for example. Not all of these hypervisor "
"drivers have the same features, and each has different tuning requirements."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml37(para)
msgid ""
"The currently implemented hypervisors are listed on <link "
"href=\"http://docs.openstack.org/trunk/config-reference/content"
"/section_compute-hypervisors.html\">the OpenStack documentation "
"website</link>. You can see a matrix of the various features in OpenStack "
"Compute (nova) hypervisor drivers on the OpenStack wiki at <link "
"href=\"https://wiki.openstack.org/wiki/HypervisorSupportMatrix\">the "
"Hypervisor support matrix page</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml43(para)
msgid ""
"The point we are trying to make here is that just because an option exists "
"doesn't mean that option is relevant to your driver choices. Normally, the "
"documentation notes which drivers the configuration applies to."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml50(title)
msgid "Implementing Periodic Tasks"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml51(para)
msgid ""
"Another common concept across various OpenStack projects is that of periodic"
" tasks. Periodic tasks are much like cron jobs on traditional Unix systems, "
"but they are run inside an OpenStack process. For example, when OpenStack "
"Compute (nova) needs to work out what images it can remove from its local "
"cache, it runs a periodic task to do this."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml57(para)
msgid ""
"Periodic tasks are important to understand because of limitations in the "
"threading model that OpenStack uses. OpenStack uses cooperative threading in"
" python, which means that if something long and complicated is running, it "
"will block other tasks inside that process from running unless it "
"voluntarily yields execution to another cooperative thread."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml64(para)
msgid ""
"A tangible example of this is the nova-compute process. In order to manage "
"the image cache with libvirt, nova-compute has a periodic process that scans"
" the contents of the image cache. Part of this scan is calculating a "
"checksum for each of the images and making sure that checksum matches what "
"nova-compute expects it to be. However, images can be very large, and these "
"checksums can take a long time to generate. At one point, before it was "
"reported as a bug and fixed, nova-compute would block on this task and stop "
"responding to RPC requests. This was visible to users as failure of "
"operations such as spawning or deleting instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml75(para)
msgid ""
"The take away from this is if you observe an OpenStack process that appears "
"to \"stop\" for a while and then continue to process normally, you should "
"check that periodic tasks aren't the problem. One way to do this is to "
"disable the periodic tasks by setting their interval to zero. Additionally, "
"you can configure how often these periodic tasks run—in some cases it might "
"make sense to run them at a different frequency from the default."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml83(para)
msgid ""
"The frequency is defined separately for each periodic task. Therefore, to "
"disable every periodic task in OpenStack Compute (nova), you would need to "
"set a number of configuration options to zero. The current list of "
"configuration options you would need to set to zero are:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml90(para)
msgid "bandwidth_poll_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml91(para)
msgid "sync_power_state_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml92(para)
msgid "heal_instance_info_cache_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml93(para)
msgid "host_state_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml94(para)
msgid "image_cache_manager_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml95(para)
msgid "reclaim_instance_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml96(para)
msgid "volume_usage_poll_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml97(para)
msgid "shelved_poll_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml98(para)
msgid "shelved_offload_time"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml99(para)
msgid "instance_delete_interval"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml102(para)
msgid ""
"To set a configuration option to zero, include a line such as "
"<literal>image_cache_manager_interval=0</literal> in your "
"<filename>nova.conf</filename> file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml106(para)
msgid ""
"This list will change between releases, so please refer to your "
"configuration guide for up to date information."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml112(title)
msgid "Specific Configuration Topics"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml113(para)
msgid ""
"This section covers specific examples of configuration options you might "
"consider tuning. It is by no means an exhaustive list."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml115(title)
msgid "Security Configuration for Compute, Networking, and Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml117(para)
msgid ""
"The <citetitle><link href=\"http://docs.openstack.org/sec/\">OpenStack "
"Security Guide</link></citetitle> provides a deep dive into securing an "
"OpenStack cloud, including SSL/TLS, key management, PKI and certificate "
"management, data transport and privacy concerns, and compliance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml123(title)
msgid "High Availability"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml124(para)
msgid ""
"The <citetitle><link href=\"http://docs.openstack.org/high-availability-"
"guide/content/\">OpenStack High Availability Guide</link></citetitle> offers"
" suggestions for elimination of a single point of failure that could cause "
"system downtime. While it is not a completely prescriptive document, it "
"offers methods and techniques for avoiding downtime and data loss."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml133(title)
msgid "Enabling IPv6 Support"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml134(para)
msgid ""
"The Havana release with OpenStack Networking (neutron) does not offer "
"complete support of IPv6. Better support is planned for the Icehouse "
"release. You can follow along the progress being made by watching the "
"neutron IPv6 Subteam at work (<link "
"href=\"https://wiki.openstack.org/wiki/Meetings/Neutron-"
"IPv6-Subteam\">https://wiki.openstack.org/wiki/Meetings/Neutron-"
"IPv6-Subteam</link>)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml143(para)
msgid ""
"By modifying your configuration setup, you can set up IPv6 when using nova-"
"network for networking, and a tested setup is documented for FlatDHCP and a "
"multi-host configuration. The key is to make nova-network think a radvd "
"command ran successfully. The entire configuration is detailed in a Cybera "
"blog post, <link href=\"http://www.cybera.ca/news-and-events/tech-radar/an-"
"ipv6-enabled-cloud/\">An IPv6 enabled cloud</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml153(title)
msgid "Periodic Task Frequency for Compute"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml154(para)
msgid ""
"Before the Grizzly release, the frequency of periodic tasks was specified in"
" seconds between runs. This meant that if the periodic task took 30 minutes "
"to run and the frequency was set to hourly, then the periodic task actually "
"ran every 90 minutes, because the task would wait an hour after running "
"before running again. This changed in Grizzly, and we now time the frequency"
" of periodic tasks from the start of the work the task does. So, our 30 "
"minute periodic task will run every hour, with a 30 minute wait between the "
"end of the first run and the start of the next."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml166(title)
msgid "Geographical Considerations for Object Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml167(para)
msgid ""
"Enhanced support for global clustering of object storage servers continues "
"to be added since the Grizzly (1.8.0) release, when regions were introduced."
" You would implement these global clusters to ensure replication across "
"geographic areas in case of a natural disaster and also to ensure that users"
" can write or access their objects more quickly based on the closest data "
"center. You configure a default region with one zone for each cluster, but "
"be sure your network (WAN) can handle the additional request and response "
"load between zones as you add more zones and build a ring that handles more "
"zones. Refer to Geographically Distributed Clusters (<link "
"href=\"http://docs.openstack.org/developer/swift/admin_guide.html"
"#geographically-distributed-"
"clusters\">http://docs.openstack.org/developer/swift/admin_guide.html"
"#geographically-distributed-clusters</link>) in the documentation for "
"additional information."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml20(title)
msgid "Storage Decisions"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml21(para)
msgid ""
"Storage is found in many parts of the OpenStack stack, and the differing "
"types can cause confusion to even experienced cloud engineers. This section "
"focuses on persistent storage options you can configure with your cloud. "
"It's important to understand the distinction between <glossterm "
"baseform=\"ephemeral volume\"> ephemeral</glossterm> storage and <glossterm "
"baseform=\"persistent volume\"> persistent</glossterm> storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml29(title)
msgid "Ephemeral Storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml30(para)
msgid ""
"If you deploy only the OpenStack Compute Service (nova), your users do not "
"have access to any form of persistent storage by default. The disks "
"associated with VMs are \"ephemeral,\" meaning that (from the user's point "
"of view) they effectively disappear when a virtual machine is terminated."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml38(title)
msgid "Persistent Storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml39(para)
msgid ""
"Persistent storage means that the storage resource outlives any other "
"resource and is always available, regardless of the state of a running "
"instance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml42(para)
msgid ""
"Today, OpenStack clouds explicitly support two types of persistent storage: "
"<emphasis>object storage</emphasis> and <emphasis>block storage</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml47(para)
msgid ""
"With object storage, users access binary objects through a REST API. You may"
" be familiar with Amazon S3, which is a well-known example of an object "
"storage system. Object storage is implemented in OpenStack by the OpenStack "
"Object Storage (swift) project. If your intended users need to archive or "
"manage large datasets, you want to provide them with object storage. In "
"addition, OpenStack can store your virtual machine (VM) images inside of an "
"object storage system, as an alternative to storing the images on a file "
"system."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml58(para)
msgid ""
"OpenStack Object Storage provides a highly scalable, highly available "
"storage solution by relaxing some of the constraints of traditional file "
"systems. In designing and procuring for such a cluster, it is important to "
"understand some key concepts about its operation. Essentially, this type of "
"storage is built on the idea that all storage hardware fails, at every "
"level, at some point. Infrequently encountered failures that would hamstring"
" other storage systems, such as issues taking down RAID cards, or entire "
"servers are handled gracefully with OpenStack Object Storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml69(para)
msgid ""
"A good document describing the Object Storage architecture is found within "
"<link title=\"OpenStack wiki\" "
"href=\"http://docs.openstack.org/developer/swift/overview_architecture.html\">the"
" developer documentation</link> "
"(http://docs.openstack.org/developer/swift/overview_architecture.html)—read "
"this first. Once you understand the architecture, you should know what a "
"proxy server does and how zones work. However, some important points are "
"often missed at first glance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml79(para)
msgid ""
"When designing your cluster, you must consider durability and availability. "
"Understand that the predominant source of these is the spread and placement "
"of your data, rather than the reliability of the hardware. Consider the "
"default value of the number of replicas, which is three. This means that "
"before an object is marked as having been written, at least two copies "
"exists—in case a single server fails to write, the third copy may or may not"
" yet exist when the write operation initially returns. Altering this number "
"increases the robustness of your data, but reduces the amount of storage you"
" have available. Next, look at the placement of your servers. Consider "
"spreading them widely throughout your data center's network and power-"
"failure zones. Is a zone a rack, a server, or a disk?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml97(para)
msgid ""
"Among <glossterm>object</glossterm>, <glossterm>container</glossterm>, and "
"<glossterm>account server</glossterm>s"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml103(para)
msgid "Between those servers and the proxies"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml106(para)
msgid "Between the proxies and your users"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml94(para)
msgid ""
"Object Storage's network patterns might seem unfamiliar at first. Consider "
"these main traffic flows: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml109(para)
msgid ""
"Object Storage is very \"chatty\" among servers hosting data—even a small "
"cluster does megabytes/second of traffic, which is predominantly \"Do you "
"have the object?\"/\"Yes I have the object!.\" Of course, if the answer to "
"the aforementioned question is negative or the request times out, "
"replication of the object begins."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml115(para)
msgid ""
"Consider the scenario where an entire server fails and 24 TB of data needs "
"to be transferred \"immediately\" to remain at three copies—this can put "
"significant load on the network."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml119(para)
msgid ""
"Another fact that's often forgotten is that when a new file is being "
"uploaded, the proxy server must write out as many streams as there are "
"replicas—giving a multiple of network traffic. For a 3-replica cluster, "
"10Gbps in means 30Gbps out. Combining this with the previous high bandwidth "
"demands of replication is what results in the recommendation that your "
"private network is of significantly higher bandwidth than your public need "
"be. Oh, and OpenStack Object Storage communicates internally with "
"unencrypted, unauthenticated rsync for performance—you do want the private "
"network to be private."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml131(para)
msgid ""
"The remaining point on bandwidth is the public facing portion. The swift-"
"proxy service is stateless, which means that you can easily add more and use"
" HTTP load-balancing methods to share bandwidth and availability between "
"them."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml136(para)
msgid "More proxies means more bandwidth, if your storage can keep up."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml141(para)
msgid ""
"Block storage (sometimes referred to as volume storage) provides users with "
"access to block-storage devices. Users interact with block storage by "
"attaching volumes to their running VM instances."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml146(para)
msgid ""
"These volumes are persistent: they can be detached from one instance and re-"
"attached to another, and the data remains intact. Block storage is "
"implemented in OpenStack by the OpenStack Block Storage (cinder) project, "
"which supports multiple back ends in the form of drivers. Your choice of a "
"storage back end must be supported by a Block Storage driver."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml153(para)
msgid ""
"Most block storage drivers allow the instance to have direct access to the "
"underlying storage hardware's block device. This helps increase the overall "
"read/write IO."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml157(para)
msgid ""
"Experimental support for utilizing files as volumes began in the Folsom "
"release. This initially started as a reference driver for using NFS with "
"cinder. By Grizzly's release, this has expanded into a full NFS driver as "
"well as a GlusterFS driver."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml162(para)
msgid ""
"These drivers work a little differently than a traditional \"block\" storage"
" driver. On an NFS or GlusterFS file system, a single file is created and "
"then mapped as a \"virtual\" volume into the instance. This "
"mapping/translation is similar to how OpenStack utilizes QEMU's file-based "
"virtual machines stored in <code>/var/lib/nova/instances</code>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml172(title)
msgid "OpenStack Storage Concepts"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml173(para)
msgid ""
"<xref linkend=\"openstack_storage\"/> explains the different storage "
"concepts provided by OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml176(caption)
msgid "OpenStack Storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml180(th)
msgid "Ephemeral storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml181(th)
msgid "Block storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml182(th)
#: ./doc/openstack-ops/section_arch_example-nova.xml105(para)
msgid "Object storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml187(para)
msgid "Used to…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml188(para)
msgid "Run operating system and scratch space"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml190(para)
msgid "Add additional persistent storage to a virtual machine (VM)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml192(para)
msgid "Store data, including VM images"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml196(para)
msgid "Accessed through…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml197(para)
msgid "A file system"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml198(para)
msgid ""
"A <glossterm>block device</glossterm> that can be partitioned, formatted, "
"and mounted (such as, /dev/vdc)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml201(para)
msgid "REST API"
msgstr "REST API"

#: ./doc/openstack-ops/ch_arch_storage.xml204(para)
msgid "Accessible from…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml205(para)
#: ./doc/openstack-ops/ch_arch_storage.xml206(para)
msgid "Within a VM"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml207(para)
msgid "Anywhere"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml210(para)
msgid "Managed by…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml211(para)
msgid "OpenStack Compute (nova)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml212(para)
msgid "OpenStack Block Storage (cinder)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml214(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml106(para)
msgid "OpenStack Object Storage (swift)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml218(para)
msgid "Persists until…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml219(para)
msgid "VM is terminated"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml220(para)
#: ./doc/openstack-ops/ch_arch_storage.xml221(para)
msgid "Deleted by user"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml224(para)
msgid "Sizing determined by…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml225(para)
msgid ""
"Administrator configures size settings, known as "
"<emphasis>flavors</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml228(para)
msgid "Specified by user in initial request"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml230(para)
msgid "Amount of available physical storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml234(para)
msgid "Example of typical usage…"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml236(para)
msgid "10 GB first disk, 30 GB second disk"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml238(para)
msgid "1 TB disk"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml240(para)
msgid "10s of TBs of dataset storage"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml246(title)
msgid "File-level Storage (for Live Migration)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml247(para)
msgid ""
"With file-level storage, users access stored data using the operating "
"system's file system interface. Most users, if they have used a network "
"storage solution before, have encountered this form of networked storage. In"
" the Unix world, the most common form of this is NFS. In the Windows world, "
"the most common form is called CIFS (previously, SMB)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml254(para)
msgid ""
"OpenStack clouds do not present file-level storage to end users. However, it"
" is important to consider file-level storage for storing instances under "
"<code>/var/lib/nova/instances</code> when designing your cloud, since you "
"must have a shared file system if you want to support live migration."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml265(title)
msgid "Choosing Storage Back ends"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml266(para)
msgid ""
"Users will indicate different needs for their cloud use cases. Some may need"
" fast access to many objects that do not change often, or they want to set a"
" Time To Live (TTL) value on a file. Others may access only storage that is "
"mounted with the file system itself, but want it to be replicated instantly "
"when starting a new instance. For other systems, ephemeral storage—storage "
"that is released when a VM attached to it is shut down— is the preferred "
"way. When you select <glossterm>storage back end</glossterm>s, ask the "
"following questions on behalf of your users:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml279(para)
msgid "Do my users need block storage?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml282(para)
msgid "Do my users need object storage?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml285(para)
msgid "Do I need to support live migration?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml288(para)
msgid ""
"Should my persistent storage drives be contained in my compute nodes, or "
"should I use external storage?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml293(para)
msgid ""
"What is the platter count I can achieve? Do more spindles result in better "
"I/O despite network access?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml298(para)
msgid ""
"Which one results in the best cost-performance scenario I'm aiming for?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml302(para)
msgid "How do I manage the storage operationally?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml306(para)
msgid ""
"How redundant and distributed is the storage? What happens if a storage node"
" fails? To what extent can it mitigate my data-loss disaster scenarios?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml312(para)
msgid ""
"To deploy your storage by using entirely commodity hardware, you can use a "
"number of open-source packages, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml316(caption)
msgid "Persistent file-based storage support"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml319(th)
#: ./doc/openstack-ops/ch_arch_storage.xml329(para)
#: ./doc/openstack-ops/ch_arch_storage.xml330(para)
#: ./doc/openstack-ops/ch_arch_storage.xml334(para)
#: ./doc/openstack-ops/ch_arch_storage.xml336(para)
#: ./doc/openstack-ops/ch_arch_storage.xml358(para)
#: ./doc/openstack-ops/ch_arch_storage.xml360(para)
msgid " "
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml320(th)
msgid "Object"
msgstr "Objektum"

#: ./doc/openstack-ops/ch_arch_storage.xml321(th)
msgid "Block"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml322(th)
msgid "File-level*"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml327(para)
msgid "Swift"
msgstr "Swift"

#: ./doc/openstack-ops/ch_arch_storage.xml333(para)
msgid "LVM"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml339(para)
#: ./doc/openstack-ops/glossary-terms.xml829(glossterm)
msgid "Ceph"
msgstr "Ceph"

#: ./doc/openstack-ops/ch_arch_storage.xml342(para)
msgid "Experimental"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml345(para)
msgid "Gluster"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml351(para)
msgid "NFS"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml357(para)
msgid "ZFS"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml364(para)
msgid ""
"* This list of open source file-level shared storage solutions is not "
"exhaustive; other open source solutions exist (MooseFS). Your organization "
"may already have deployed a file-level shared storage solution that you can "
"use."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml370(title)
msgid "Storage Driver Support"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml371(para)
msgid ""
"In addition to the open source technologies, there are a number of "
"proprietary solutions that are officially supported by OpenStack Block "
"Storage. They are offered by the following vendors:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml377(para)
msgid "IBM (Storwize family/SVC, XIV)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml380(para)
msgid "NetApp"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml383(para)
msgid "Nexenta"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml386(para)
msgid "SolidFire"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml389(para)
msgid ""
"You can find a matrix of the functionality provided by all of the supported "
"Block Storage drivers on the <link title=\"OpenStack wiki\" "
"href=\"https://wiki.openstack.org/wiki/CinderSupportMatrix\">OpenStack "
"wiki</link> (https://wiki.openstack.org/wiki/CinderSupportMatrix)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml396(para)
msgid ""
"Also, you need to decide whether you want to support object storage in your "
"cloud. The two common use cases for providing object storage in a compute "
"cloud are:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml401(para)
msgid "To provide users with a persistent storage mechanism"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml405(para)
msgid "As a scalable, reliable data store for virtual machine images"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml410(title)
msgid "Commodity Storage Back-end Technologies"
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml411(para)
msgid ""
"This section provides a high-level overview of the differences among the "
"different commodity storage back-end technologies. Depending on your cloud "
"user's needs, you can implement one or many of these technologies in "
"different combinations."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml418(para)
msgid ""
"<emphasis role=\"bold\">OpenStack Object Storage (swift)</emphasis>. The "
"official OpenStack Object Store implementation. It is a mature technology "
"that has been used for several years in production by Rackspace as the "
"technology behind Rackspace Cloud Files. As it is highly scalable, it is "
"well-suited to managing petabytes of storage. OpenStack Object Storage's "
"advantages are better integration with OpenStack (integrates with OpenStack "
"Identity, works with the OpenStack dashboard interface) and better support "
"for multiple data center deployment through support of asynchronous eventual"
" consistency replication."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml433(para)
msgid ""
"Therefore, if you eventually plan on distributing your storage cluster "
"across multiple data centers, if you need unified accounts for your users "
"for both compute and object storage, or if you want to control your object "
"storage with the OpenStack dashboard, you should consider OpenStack Object "
"Storage. More detail can be found about OpenStack Object Storage in the "
"section below."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml444(para)
msgid ""
"<emphasis role=\"bold\">Ceph</emphasis>. A scalable storage solution that "
"replicates data across commodity storage nodes. Ceph was originally "
"developed by one of the founders of DreamHost and is currently used in "
"production there."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml450(para)
msgid ""
"Ceph was designed to expose different types of storage interfaces to the "
"end-user: it supports object storage, block storage, and file-system "
"interfaces, although the file-system interface is not yet considered "
"production-ready. Ceph supports the same API as swift for object storage and"
" can be used as a back end for cinder block storage as well as back-end "
"storage for glance images. Ceph supports \"thin provisioning,\" implemented "
"using copy-on-write."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml461(para)
msgid ""
"This can be useful when booting from volume because a new volume can be "
"provisioned very quickly. Ceph also supports keystone-based authentication "
"(as of version 0.56), so it can be a seamless swap in for the default "
"OpenStack swift implementation."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml467(para)
msgid ""
"Ceph's advantages are that it gives the administrator more fine-grained "
"control over data distribution and replication strategies, enables you to "
"consolidate your object and block storage, enables very fast provisioning of"
" boot-from-volume instances using thin provisioning, and supports a "
"distributed file-system interface, though this interface is <link "
"title=\"OpenStack wiki\" href=\"http://ceph.com/docs/master/faq/\">not yet "
"recommended</link> (http://ceph.com/docs/master/faq/) for use in production "
"deployment by the Ceph project."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml480(para)
msgid ""
"If you want to manage your object and block storage within a single system, "
"or if you want to support fast boot-from-volume, you should consider Ceph."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml486(para)
msgid ""
"<emphasis role=\"bold\">Gluster</emphasis>. A distributed, shared file "
"system. As of Gluster version 3.3, you can use Gluster to consolidate your "
"object storage and file storage into one unified file and object storage "
"solution, which is called Gluster For OpenStack (GFO). GFO uses a customized"
" version of swift that enables Gluster to be used as the back-end storage."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml495(para)
msgid ""
"The main reason to use GFO rather than regular swift is if you also want to "
"support a distributed file system, either to support shared storage live "
"migration or to provide it as a separate service to your end-users. If you "
"want to manage your object and file storage within a single system, you "
"should consider GFO."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml505(para)
msgid ""
"<emphasis role=\"bold\">LVM</emphasis>. The Logical Volume Manager, a Linux-"
"based system that provides an abstraction layer on top of physical disks to "
"expose logical volumes to the operating system. The LVM back end implements "
"block storage as LVM logical partitions."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml512(para)
msgid ""
"On each host that will house block storage, an administrator must initially "
"create a volume group dedicated to Block Storage volumes. Blocks are created"
" from LVM logical volumes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml518(para)
msgid ""
"LVM does <emphasis>not</emphasis> provide any replication. Typically, "
"administrators configure RAID on nodes that use LVM as block storage to "
"protect against failures of individual hard drives. However, RAID does not "
"protect against a failure of the entire host."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml529(para)
msgid ""
"<emphasis role=\"bold\">ZFS</emphasis>. The Solaris iSCSI driver for "
"OpenStack Block Storage implements blocks as ZFS entities. ZFS is a file "
"system that also has the functionality of a volume manager. This is unlike "
"on a Linux system, where there is a separation of volume manager (LVM) and "
"file system (such as, ext3, ext4, xfs, and btrfs). ZFS has a number of "
"advantages over ext4, including improved data-integrity checking."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml539(para)
msgid ""
"The ZFS back end for OpenStack Block Storage supports only Solaris-based "
"systems such as Illumos. While there is a Linux port of ZFS, it is not "
"included in any of the standard Linux distributions, and it has not been "
"tested with OpenStack Block Storage. As with LVM, ZFS does not provide "
"replication across hosts on its own; you need to add a replication solution "
"on top of ZFS if your cloud needs to be able to handle storage-node "
"failures."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml550(para)
msgid ""
"We don't recommend ZFS unless you have previous experience with deploying "
"it, since the ZFS back end for Block Storage requires a Solaris-based "
"operating system, and we assume that your experience is primarily with "
"Linux-based systems."
msgstr ""

#: ./doc/openstack-ops/ch_arch_storage.xml562(para)
msgid ""
"We hope that you now have some considerations in mind and questions to ask "
"your future cloud users about their storage use cases. As you can see, your "
"storage decisions will also influence your network design for performance "
"and security needs. Continue with us to make more informed decisions about "
"your OpenStack cloud design."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml14(title)
msgid "Use Cases"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml15(para)
msgid ""
"This appendix contains a small selection of use cases from the community, "
"with more technical detail than usual. Further examples can be found on the "
"<link title=\"OpenStack User Stories Website\" "
"href=\"https://www.openstack.org/user-stories/\">OpenStack website</link> "
"(https://www.openstack.org/user-stories/)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml23(title)
msgid "NeCTAR"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml24(para)
msgid ""
"Who uses it: researchers from the Australian publicly funded research "
"sector. Use is across a wide variety of disciplines, with the purpose of "
"instances ranging from running simple web servers to using hundreds of cores"
" for high throughput computing."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml30(title)
#: ./doc/openstack-ops/app_usecases.xml85(title)
#: ./doc/openstack-ops/app_usecases.xml171(title)
#: ./doc/openstack-ops/app_usecases.xml214(title)
msgid "Deployment"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml31(para)
msgid ""
"Using OpenStack Compute cells, the NeCTAR Research Cloud spans eight sites "
"with approximately 4,000 cores per site."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml34(para)
msgid ""
"Each site runs a different configuration, as resource "
"<glossterm>cell</glossterm>s in an OpenStack Compute cells setup. Some sites"
" span multiple data centers, some use off compute node storage with a shared"
" file system, and some use on compute node storage with a nonshared file "
"system. Each site deploys the Image Service with an Object Storage back end."
" A central Identity Service, dashboard, and Compute API service is used. A "
"login to the dashboard triggers a SAML login with Shibboleth, which creates "
"an <glossterm>account</glossterm> in the Identity Service with an SQL back "
"end."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml46(para)
msgid ""
"Compute nodes have 24 to 48 cores, with at least 4 GB of RAM per core and "
"approximately 40 GB of ephemeral storage per core."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml49(para)
msgid ""
"All sites are based on Ubuntu 12.04 with KVM as the hypervisor. The "
"OpenStack version in use is typically the current stable version, with 5 to "
"10 percent back-ported code from trunk and modifications. Migration to "
"Ubuntu 14.04 is planned as part of the Havana to Icehouse upgrade."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml59(para)
msgid ""
"<link href=\"https://www.openstack.org/user-stories/nectar/\">OpenStack.org "
"Case Study</link> (https://www.openstack.org/user-stories/nectar/)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml66(para)
msgid ""
"<link href=\"https://github.com/NeCTAR-RC/\">NeCTAR-RC GitHub</link> "
"(https://github.com/NeCTAR-RC/)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml72(para)
msgid ""
"<link href=\"https://www.nectar.org.au/\">NeCTAR website</link> "
"(https://www.nectar.org.au/)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml81(title)
msgid "MIT CSAIL"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml82(para)
msgid ""
"Who uses it: researchers from the MIT Computer Science and Artificial "
"Intelligence Lab."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml86(para)
msgid ""
"The CSAIL cloud is currently 64 physical nodes with a total of 768 physical "
"cores and 3,456 GB of RAM. Persistent data storage is largely outside the "
"cloud on NFS, with cloud resources focused on compute resources. There are "
"more than 130 users in more than 40 projects, typically running 2,000–2,500 "
"vCPUs in 300 to 400 instances."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml93(para)
msgid ""
"We initially deployed on Ubuntu 12.04 with the Essex release of OpenStack "
"using FlatDHCP multi-host networking."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml96(para)
msgid ""
"The software stack is still Ubuntu 12.04 LTS, but now with OpenStack Havana "
"from the Ubuntu Cloud Archive. KVM is the hypervisor, deployed using <link "
"href=\"http://fai-project.org\">FAI</link> (http://fai-project.org/) and "
"Puppet for configuration management. The FAI and Puppet combination is used "
"lab-wide, not only for OpenStack. There is a single cloud controller node, "
"which also acts as network controller, with the remainder of the server "
"hardware dedicated to compute nodes."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml106(para)
msgid ""
"Host aggregates and instance-type extra specs are used to provide two "
"different resource allocation ratios. The default resource allocation ratios"
" we use are 4:1 CPU and 1.5:1 RAM. Compute-intensive workloads use instance "
"types that require non-oversubscribed hosts where cpu_ratio and ram_ratio "
"are both set to 1.0. Since we have hyperthreading enabled on our compute "
"nodes, this provides one vCPU per CPU thread, or two vCPUs per physical "
"core."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml115(para)
msgid ""
"With our upgrade to Grizzly in August 2013, we moved to OpenStack Networking"
" Service, neutron (quantum at the time). Compute nodes have two gigabit "
"network interfaces and a separate management card for IPMI management. One "
"network interface is used for node-to-node communications. The other is used"
" as a trunk port for OpenStack managed VLANs. The controller node uses two "
"bonded 10g network interfaces for its public IP communications. Big pipes "
"are used here because images are served over this port, and it is also used "
"to connect to iSCSI storage, back ending the image storage and database. The"
" controller node also has a gigabit interface that is used in trunk mode for"
" OpenStack managed VLAN traffic. This port handles traffic to the dhcp-agent"
" and metadata-proxy."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml130(para)
msgid ""
"We approximate the older nova-networking multi-host HA setup by using "
"\"provider vlan networks\" that connect instances directly to existing "
"publicly addressable networks and use existing physical routers as their "
"default gateway. This means that if our network controller goes down, "
"running instances still have their network available, and no single Linux "
"host becomes a traffic bottleneck. We are able to do this because we have a "
"sufficient supply of IPv4 addresses to cover all of our instances and thus "
"don't need NAT and don't use floating IP addresses. We provide a single "
"generic public network to all projects and additional existing VLANs on a "
"project-by-project basis as needed. Individual projects are also allowed to "
"create their own private GRE based networks."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml150(para)
msgid ""
"<link href=\"http://www.csail.mit.edu\">CSAIL Homepage</link> "
"(http://www.csail.mit.edu)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml160(title)
msgid "DAIR"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml161(para)
msgid ""
"Who uses it: DAIR is an integrated virtual environment that leverages the "
"CANARIE network to develop and test new information communication technology"
" (ICT) and other digital technologies. It combines such digital "
"infrastructure as advanced networking and cloud computing and storage to "
"create an environment for developing and testing innovative ICT "
"applications, protocols, and services; performing at-scale experimentation "
"for deployment; and facilitating a faster time to market."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml172(para)
msgid ""
"DAIR is hosted at two different data centers across Canada: one in Alberta "
"and the other in Quebec. It consists of a cloud controller at each location,"
" although, one is designated the \"master\" controller which is in charge of"
" central authentication and quotas. This is done through custom scripts and "
"light modifications to OpenStack. DAIR is currently running Grizzly."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml180(para)
msgid "For Object Storage, each region has a swift environment."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml182(para)
msgid ""
"A NetApp appliance is used in each region for both block storage and "
"instance storage. There are future plans to move the instances off the "
"NetApp appliance and onto a distributed file system such as "
"<glossterm>Ceph</glossterm> or GlusterFS."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml187(para)
msgid ""
"VlanManager is used extensively for network management. All servers have two"
" bonded 10GbE NICs that are connected to two redundant switches. DAIR is set"
" up to use single-node networking where the cloud controller is the gateway "
"for all instances on all compute nodes. Internal OpenStack traffic (for "
"example, storage traffic) does not go through the cloud controller."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml200(para)
msgid ""
"<link href=\"http://www.canarie.ca/en/dair-program/about\">DAIR "
"homepage</link> (http://www.canarie.ca/en/dair-program/about)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml209(title)
msgid "CERN"
msgstr "CERN"

#: ./doc/openstack-ops/app_usecases.xml210(para)
msgid ""
"Who uses it: researchers at CERN (European Organization for Nuclear "
"Research) conducting high-energy physics research."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml215(para)
msgid ""
"The environment is largely based on Scientific Linux 6, which is Red Hat "
"compatible. We use KVM as our primary hypervisor, although tests are ongoing"
" with Hyper-V on Windows Server 2008."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml219(para)
msgid ""
"We use the Puppet Labs OpenStack modules to configure Compute, Image "
"Service, Identity, and dashboard. Puppet is used widely for instance "
"configuration, and Foreman is used as a GUI for reporting and instance "
"provisioning."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml224(para)
msgid ""
"Users and groups are managed through Active Directory and imported into the "
"Identity Service using LDAP. CLIs are available for nova and Euca2ools to do"
" this."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml228(para)
msgid ""
"There are three clouds currently running at CERN, totaling about 3,400 "
"compute nodes, with approximately 60,000 cores. The CERN IT cloud aims to "
"expand to 300,000 cores by 2015."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml238(para)
msgid ""
"<link href=\"http://openstack-in-production.blogspot.com/2013/09/a-tale-of-3"
"-openstack-clouds-50000.html\">OpenStack in Production: A tale of 3 "
"OpenStack Clouds</link> (http://openstack-in-"
"production.blogspot.com/2013/09/a-tale-of-3-openstack-clouds-50000.html)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml246(para)
msgid ""
"<link href=\"http://cern.ch/go/N8wp\">Review of CERN Data Centre "
"Infrastructure</link> (http://cern.ch/go/N8wp)"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml253(para)
msgid ""
"<link href=\"http://information-technology.web.cern.ch/book/cern-private-"
"cloud-user-guide\">CERN Cloud Infrastructure User Guide</link> (http"
"://information-technology.web.cern.ch/book/cern-private-cloud-user-guide)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml15(title)
msgid "Network Design"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml16(para)
msgid ""
"OpenStack provides a rich networking environment, and this chapter details "
"the requirements and options to deliberate when designing your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml19(para)
msgid ""
"If this is the first time you are deploying a cloud infrastructure in your "
"organization, after reading this section, your first conversations should be"
" with your networking team. Network usage in a running cloud is vastly "
"different from traditional network deployments and has the potential to be "
"disruptive at both a connectivity and a policy level."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml26(para)
msgid ""
"For example, you must plan the number of IP addresses that you need for both"
" your guest instances as well as management infrastructure. Additionally, "
"you must research and discuss cloud network connectivity through proxy "
"servers and firewalls."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml31(para)
msgid ""
"In this chapter, we'll give some examples of network implementations to "
"consider and provide information about some of the network layouts that "
"OpenStack uses. Finally, we have some brief notes on the networking services"
" that are essential for stable operation."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml36(title)
msgid "Management Network"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml37(para)
msgid ""
"A <glossterm>management network</glossterm> (a separate network for use by "
"your cloud operators), typically consisting of a separate switch and "
"separate NICs (network interface cards), is a recommended option. This "
"segregation prevents system administration and the monitoring of system "
"access from being disrupted by traffic generated by guests."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml44(para)
msgid ""
"Consider creating other private networks for communication between internal "
"components of OpenStack, such as the message queue and OpenStack Compute. "
"Using a virtual local area network (VLAN) works well for these scenarios "
"because it provides a method for creating multiple virtual networks on a "
"physical network."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml53(title)
msgid "Public Addressing Options"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml54(para)
msgid ""
"There are two main types of IP addresses for guest virtual machines: fixed "
"IPs and floating IPs. Fixed IPs are assigned to instances on boot, whereas "
"floating IP addresses can change their association between instances by "
"action of the user. Both types of IP addresses can be either public or "
"private, depending on your use case."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml61(para)
msgid ""
"Fixed IP addresses are required, whereas it is possible to run OpenStack "
"without floating IPs. One of the most common use cases for floating IPs is "
"to provide public IP addresses to a private cloud, where there are a limited"
" number of IP addresses available. Another is for a public cloud user to "
"have a \"static\" IP address that can be reassigned when an instance is "
"upgraded or moved."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml68(para)
msgid ""
"Fixed IP addresses can be private for private clouds, or public for public "
"clouds. When an instance terminates, its fixed IP is lost. It is worth "
"noting that newer users of cloud computing may find their ephemeral nature "
"frustrating."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml75(title)
msgid "IP Address Planning"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml76(para)
msgid ""
"An OpenStack installation can potentially have many subnets (ranges of IP "
"addresses), and different types of services in each. An IP address plan can "
"assist with a shared understanding of network partition purposes and "
"scalability. Control services can have public and private IP addresses, and "
"as noted above there are a couple of options for an instance's public "
"addresses."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml84(para)
msgid "An IP address plan might be broken down into the following sections:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml89(emphasis)
msgid "subnet router"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml90(para)
msgid ""
"Packets leaving the subnet go via this address, which could be a dedicated "
"router or a nova-network service."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml95(emphasis)
msgid "control services public interfaces"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml97(para)
msgid ""
"Public access to <code>swift-proxy</code>, <code>nova-api</code>, <code"
">glance-api</code>, and horizon come to these addresses, which could be on "
"one side of a load balancer or pointing at individual machines."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml106(emphasis)
msgid "Object Storage cluster internal communications"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml108(para)
msgid ""
"Traffic among object/account/container servers and between these and the "
"proxy server's internal interface uses this private network."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml114(emphasis)
msgid "compute and storage communications"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml116(para)
msgid ""
"If ephemeral or block storage is external to the compute node, this network "
"is used."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml121(emphasis)
msgid "out-of-band remote management"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml123(para)
msgid ""
"If a dedicated remote access controller chip is included in servers, often "
"these are on a separate network."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml128(emphasis)
msgid "in-band remote management"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml129(para)
msgid ""
"Often, an extra (such as 1 GB) interface on compute or storage nodes is used"
" for system administrators or monitoring tools to access the host instead of"
" going through the public interface."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml137(emphasis)
msgid "spare space for future growth"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml139(para)
msgid ""
"Adding more public-facing control services or guest instance IPs should "
"always be part of your plan."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml145(para)
msgid ""
"For example, take a deployment that has both OpenStack Compute and Object "
"Storage, with private ranges 172.22.42.0/24 and 172.22.87.0/26 available. "
"One way to segregate the space might be as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml162(para)
msgid ""
"A similar approach can be taken with public IP addresses, taking note that "
"large, flat ranges are preferred for use with guest instance IPs. Take into "
"account that for some OpenStack networking options, a public IP address in "
"the range of a guest instance public IP address is assigned to the nova-"
"compute host."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml171(title)
msgid "Network Topology"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml172(para)
msgid ""
"OpenStack Compute with nova-network provides pre-defined network deployment "
"models, each with its own strengths and weaknesses. The selection of a "
"network manager changes your network topology, so the choice should be made "
"carefully. You also have a choice between the tried-and-true legacy nova-"
"network settings or the neutron project for OpenStack Networking. Both offer"
" networking for launched instances with different implementations and "
"requirements."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml179(para)
msgid ""
"For OpenStack Networking with the neutron project, typical configurations "
"are documented with the idea that any setup you can configure with real "
"hardware you can re-create with a software-defined equivalent. Each tenant "
"can contain typical network elements such as routers and services such as "
"DHCP."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml184(para)
msgid ""
"<xref linkend=\"network_deployment_options\"/> discusses the networking "
"deployment options for both legacy nova-network options and an equivalent "
"neutron configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml189(caption)
msgid "Networking Deployment Options"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml196(th)
msgid "Network Deployment Model"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml197(th)
msgid "Strengths"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml198(th)
msgid "Weaknesses"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml199(th)
msgid "Neutron Equivalent"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml205(para)
msgid "Flat"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml208(para)
msgid "Extremely simple topology."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml209(para)
msgid "No DHCP overhead."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml212(para)
msgid ""
"Requires file injection into the instance to configure network interfaces."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml215(td)
msgid ""
"Configure a single bridge as the integration bridge (br-int) and connect it "
"to a physical network interface with the Modular Layer 2 (ML2) plug-in, "
"which uses Open vSwitch by default."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml222(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml78(para)
msgid "FlatDHCP"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml225(para)
msgid "Relatively simple to deploy."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml226(para)
msgid "Standard networking."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml227(para)
msgid "Works with all guest operating systems."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml230(para)
#: ./doc/openstack-ops/ch_arch_network_design.xml245(para)
msgid "Requires its own DHCP broadcast domain."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml232(td)
msgid ""
"Configure DHCP agents and routing agents. Network Address Translation (NAT) "
"performed outside of compute nodes, typically on one or more network nodes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml238(para)
msgid "VlanManager"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml241(para)
msgid "Each tenant is isolated to its own VLANs."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml244(para)
#: ./doc/openstack-ops/ch_arch_network_design.xml273(para)
msgid "More complex to set up."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml246(para)
msgid "Requires many VLANs to be trunked onto a single port."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml247(para)
msgid "Standard VLAN number limitation."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml248(para)
msgid "Switches must support 802.1q VLAN tagging."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml251(para)
msgid ""
"Isolated tenant networks implement some form of isolation of layer 2 traffic"
" between distinct networks. VLAN tagging is key concept, where traffic is "
"“tagged” with an ordinal identifier for the VLAN. Isolated network "
"implementations may or may not include additional services like DHCP, NAT, "
"and routing."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml262(para)
msgid "FlatDHCP Multi-host with high availability (HA)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml265(para)
msgid ""
"Networking failure is isolated to the VMs running on the affected "
"hypervisor."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml267(para)
msgid "DHCP traffic can be isolated within an individual host."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml269(para)
msgid "Network traffic is distributed to the compute nodes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml274(para)
msgid ""
"Compute nodes typically need IP addresses accessible by external networks."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml276(para)
msgid ""
"Options must be carefully configured for live migration to work with "
"networking services."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml280(para)
msgid ""
"Configure neutron with multiple DHCP and layer 3 agents. Network nodes are "
"not able to failover to each other, so the controller runs networking "
"services such as DHCP. Compute nodes run the ML2 plug-in with support for "
"agents such as Open vSwitch or Linux Bridge."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml290(para)
msgid ""
"Both nova-network and neutron services provide similar capabilities, such as"
" VLAN between VMs. You also can provide multiple NICs on VMs with either "
"service. Further discussion follows."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml295(title)
msgid "VLAN Configuration within OpenStack VMs"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml296(para)
msgid ""
"VLAN configuration can be as simple or as complicated as desired. The use of"
" VLANs has the benefit of allowing each project its own subnet and broadcast"
" segregation from other projects. To allow OpenStack to efficiently use "
"VLANs, you must allocate a VLAN range (one for each project) and turn each "
"compute node switch port into a trunk port."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml303(para)
msgid ""
"For example, if you estimate that your cloud must support a maximum of 100 "
"projects, pick a free VLAN range that your network infrastructure is "
"currently not using (such as VLAN 200–299). You must configure OpenStack "
"with this range and also configure your switch ports to allow VLAN traffic "
"from that range."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml313(title)
msgid "Multi-NIC Provisioning"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml314(para)
msgid ""
"OpenStack Compute has the ability to assign multiple NICs to instances on a "
"per-project basis. This is generally an advanced feature and not an everyday"
" request. This can easily be done on a per-request basis, though. However, "
"be aware that a second NIC uses up an entire subnet or VLAN. This decrements"
" your total number of supported projects by one."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml323(title)
msgid "Multi-Host and Single-Host Networking"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml324(para)
msgid ""
"The nova-network service has the ability to operate in a multi-host or "
"single-host mode. Multi-host is when each compute node runs a copy of nova-"
"network and the instances on that compute node use the compute node as a "
"gateway to the Internet. The compute nodes also host the floating IPs and "
"security groups for instances on that node. Single-host is when a central "
"server—for example, the cloud controller—runs the <code>nova-network</code> "
"service. All compute nodes forward traffic from the instances to the cloud "
"controller. The cloud controller then forwards traffic to the Internet. The "
"cloud controller hosts the floating IPs and security groups for all "
"instances on all compute nodes in the cloud."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml338(para)
msgid ""
"There are benefits to both modes. Single-node has the downside of a single "
"point of failure. If the cloud controller is not available, instances cannot"
" communicate on the network. This is not true with multi-host, but multi-"
"host requires that each compute node has a public IP address to communicate "
"on the Internet. If you are not able to obtain a significant block of public"
" IP addresses, multi-host might not be an option."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml350(title)
msgid "Services for Networking"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml351(para)
msgid ""
"OpenStack, like any network application, has a number of standard "
"considerations to apply, such as NTP and DNS."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml355(title)
msgid "NTP"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml356(para)
msgid ""
"Time synchronization is a critical element to ensure continued operation of "
"OpenStack components. Correct time is necessary to avoid errors in instance "
"scheduling, replication of objects in the object store, and even matching "
"log timestamps for debugging."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml362(para)
msgid ""
"All servers running OpenStack components should be able to access an "
"appropriate NTP server. You may decide to set up one locally or use the "
"public pools available from the <link href=\"http://www.pool.ntp.org\"> "
"Network Time Protocol project</link> (http://www.pool.ntp.org/)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml370(title)
#: ./doc/openstack-ops/glossary-terms.xml1511(glossterm)
msgid "DNS"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml371(para)
msgid ""
"OpenStack does not currently provide DNS services, aside from the dnsmasq "
"daemon, which resides on <code>nova-network</code> hosts. You could consider"
" providing a dynamic DNS service to allow instances to update a DNS entry "
"with new IP addresses. You can also consider making a generic forward and "
"reverse DNS mapping for instances' IP addresses, such as "
"vm-203-0-113-123.example.com."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml384(para)
msgid ""
"Armed with your IP address layout and numbers and knowledge about the "
"topologies and services you can use, it's now time to prepare the network "
"for your installation. Be sure to also check out the <citetitle>OpenStack "
"Security Guide</citetitle> for tips on securing your network. We wish you a "
"good relationship with your networking team!"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml15(title)
msgid "Lay of the Land"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml16(para)
msgid ""
"This chapter helps you set up your working environment and use it to take a "
"look around your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml19(title)
msgid "Using the OpenStack dashboard for Administration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml20(para)
msgid ""
"As a cloud administrative user, you can use the OpenStack dashboard to "
"create and manage projects, users, images, and flavors. Users are allowed to"
" create and manage images within specified projects and to share images "
"depending on the Image Service configuration. Typically, the policy "
"configuration allows admin users only to set quotas and create and manage "
"services. The dashboard provides an <guilabel>Admin</guilabel> tab with a "
"<guilabel>System Panel</guilabel> and <guilabel>Identity Panel</guilabel>. "
"These interfaces give you access to system information and usage as well as "
"to settings for configuring what end-users can do. Refer to the <link "
"href=\"http://docs.openstack.org/user-guide-"
"admin/content/ch_dashboard.html\">OpenStack Admin User Guide</link> for "
"detailed how-to information about using the dashboard as an admin user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml35(title)
msgid "Command-Line Tools"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml36(para)
msgid ""
"We recommend using a combination of the OpenStack command-line interface "
"(CLI) tools and the OpenStack dashboard for administration. Some users with "
"a background in other cloud technologies may be using the EC2 Compatibility "
"API, which uses naming conventions somewhat different from the native API. "
"We highlight those differences."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml42(para)
msgid ""
"We strongly suggest that you install the command-line clients from the <link"
" href=\"https://pypi.python.org/\">Python Package Index</link> (PyPI) "
"(https://pypi.python.org/) instead of from the distribution packages. The "
"clients are under heavy development, and it is very likely at any given time"
" that the version of the packages distributed by your operating-system "
"vendor are out of date."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml51(para)
msgid ""
"The \"pip\" utility is used to manage package installation from the PyPI "
"archive and is available in the \"python-pip\" package in most Linux "
"distributions. Each OpenStack project has its own client, so depending on "
"which services your site runs, install some or all of the following "
"packages:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml59(para)
msgid "python-novaclient (<glossterm>nova</glossterm> CLI)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml63(para)
msgid "python-glanceclient (<glossterm>glance</glossterm> CLI)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml67(para)
msgid "python-keystoneclient (<glossterm>keystone</glossterm> CLI)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml71(para)
msgid "python-cinderclient (<glossterm>cinder</glossterm> CLI)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml75(para)
msgid "python-swiftclient (<glossterm>swift</glossterm> CLI)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml79(para)
msgid "python-neutronclient (<glossterm>neutron</glossterm> CLI)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml84(title)
msgid "Installing the Tools"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml85(para)
msgid ""
"To install (or upgrade) a package from the PyPI archive with pip, as root:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml88(para)
msgid "To remove the package:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml90(para)
msgid ""
"If you need even newer versions of the clients, pip can install directly "
"from the upstream git repository using the <code>-e</code> flag. You must "
"specify a name for the Python egg that is installed. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml96(para)
msgid ""
"If you support the EC2 API on your cloud, you should also install the "
"\"euca2ools\" package or some other EC2 API tool so that you can get the "
"same view your users have. Using EC2 API-based tools is mostly out of the "
"scope of this guide, though we discuss getting credentials for use with it."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml104(title)
msgid "Administrative Command-Line Tools"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml105(para)
msgid ""
"There are also several <emphasis>*-</emphasis>manage command-line tools. "
"These are installed with the project's services on the cloud controller and "
"do not need to be installed separately:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml111(para)
msgid "nova-manage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml114(para)
msgid "glance-manage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml117(para)
msgid "keystone-manage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml120(para)
msgid "cinder-manage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml123(para)
msgid ""
"Unlike the CLI tools mentioned above, the <code>*-manage</code> tools must "
"be run from the cloud controller, as root, because they need read access to "
"the config files such as <code>/etc/nova/nova.conf</code> and to make "
"queries directly against the database rather than against the OpenStack "
"<glossterm>API endpoint</glossterm>s."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml131(para)
msgid ""
"The existence of the <code>*-manage</code> tools is a legacy issue. It is a "
"goal of the OpenStack project to eventually migrate all of the remaining "
"functionality in the <code>*-manage</code> tools into the API-based tools. "
"Until that day, you need to SSH into the <glossterm>cloud controller "
"node</glossterm> to perform some maintenance operations that require one of "
"the <code>*-manage</code> tools."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml144(title)
msgid "Getting Credentials"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml145(para)
msgid ""
"You must have the appropriate credentials if you want to use the command-"
"line tools to make queries against your OpenStack cloud. By far the easiest "
"way to obtain <glossterm>authentication</glossterm> credentials to use with "
"command-line clients is to use the OpenStack dashboard. From the top-right "
"navigation row, select <guimenuitem>Project</guimenuitem>, then "
"<guimenuitem>Access &amp; Security</guimenuitem>, then <guimenuitem>API "
"Access</guimenuitem> to access the user settings page where you can set your"
" language and timezone preferences for the dashboard view. This action "
"displays two buttons, <guilabel>Download OpenStack RC File</guilabel> and "
"<guilabel>Download EC2 Credentials</guilabel>, which let you generate files "
"that you can source in your shell to populate the environment variables the "
"command-line tools require to know where your service endpoints and your "
"authentication information are. The user you logged in to the dashboard "
"dictates the filename for the openrc file, such as <filename>demo-"
"openrc.sh</filename>. When logged in as admin, the file is named <filename"
">admin-openrc.sh</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml166(para)
msgid "The generated file looks something like this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml193(para)
msgid ""
"This does not save your password in plain text, which is a good thing. But "
"when you source or run the script, it prompts you for your password and then"
" stores your response in the environment variable <code>OS_PASSWORD</code>. "
"It is important to note that this does require interactivity. It is possible"
" to store a value directly in the script if you require a noninteractive "
"operation, but you then need to be extremely cautious with the security and "
"permissions of this file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml203(para)
msgid ""
"EC2 compatibility credentials can be downloaded by selecting "
"<guimenuitem>Project</guimenuitem>, then <guimenuitem>Access &amp; "
"Security</guimenuitem>, then <guimenuitem>API Access</guimenuitem> to "
"display the <guilabel>Download EC2 Credentials</guilabel> button. Click the "
"button to generate a zip file with server x509 certificates and a shell "
"script fragment. Create a new directory in a secure location because these "
"are live credentials containing all the authentication information required "
"to access your cloud identity, unlike the default <code>user-openrc</code>. "
"Extract the zip file here. You should have <filename>cacert.pem</filename>, "
"<filename>cert.pem</filename>, <filename>ec2rc.sh</filename>, and "
"<filename>pk.pem</filename>. The <filename>ec2rc.sh</filename> is similar to"
" this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml236(para)
msgid ""
"To put the EC2 credentials into your environment, source the "
"<code>ec2rc.sh</code> file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml240(title)
msgid "Inspecting API Calls"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml241(para)
msgid ""
"The command-line tools can be made to show the OpenStack API calls they make"
" by passing the <code>--debug</code> flag to them. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml245(para)
msgid ""
"This example shows the HTTP requests from the client and the responses from "
"the endpoints, which can be helpful in creating custom tools written to the "
"OpenStack API."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml249(para)
msgid ""
"<link href=\"https://wiki.openstack.org/wiki/KeyringSupport\">Keyring "
"Support</link> (https://wiki.openstack.org/wiki/KeyringSupport) enables you "
"to securely save your OpenStack password in an encrypted file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml256(para)
msgid ""
"This feature is disabled by default. To enable it, add the <code>--os-"
"cache</code> flag or set the environment variable <code>OS_CACHE=1</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml259(para)
msgid ""
"Configuring OS_CACHE causes the command-line tool to authenticate on each "
"and every interaction with the cloud. This can assist with working around "
"this scenario. However, it increases the time taken to run commands and also"
" the load on the server."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml266(title)
msgid "Using cURL for Further Inspection"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml267(para)
msgid ""
"Underlying the use of the command-line tools is the OpenStack API, which is "
"a RESTful API that runs over HTTP. There may be cases where you want to "
"interact with the API directly or need to use it because of a suspected bug "
"in one of the CLI tools. The best way to do this is to use a combination of "
"<link href=\"http://curl.haxx.se/\">cURL</link> (http://curl.haxx.se/) and "
"another tool, such as <link "
"href=\"http://stedolan.github.com/jq/\">jq</link> "
"(http://stedolan.github.com/jq/), to parse the JSON from the responses."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml280(para)
msgid ""
"The first thing you must do is authenticate with the cloud using your "
"credentials to get an <glossterm>authentication token</glossterm>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml283(para)
msgid ""
"Your credentials are a combination of username, password, and tenant "
"(project). You can extract these values from the <code>openrc.sh</code> "
"discussed above. The token allows you to interact with your other service "
"endpoints without needing to reauthenticate for every request. Tokens are "
"typically good for 24 hours, and when the token expires, you are alerted "
"with a 401 (Unauthorized) response and you can request another token."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml294(para)
msgid "Look at your OpenStack service <glossterm>catalog</glossterm>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml302(para)
msgid ""
"Read through the JSON response to get a feel for how the catalog is laid "
"out."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml305(para)
msgid ""
"To make working with subsequent requests easier, store the token in an "
"environment variable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml312(para)
msgid "Now you can refer to your token on the command line as $TOKEN."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml316(para)
msgid ""
"Pick a service endpoint from your service catalog, such as compute. Try a "
"request, for example, listing instances (servers)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml328(para)
msgid ""
"To discover how API requests should be structured, read the <link "
"href=\"http://api.openstack.org/api-ref.html\">OpenStack API "
"Reference</link> (http://api.openstack.org/api-ref.html). To chew through "
"the responses using jq, see the <link "
"href=\"http://stedolan.github.com/jq/manual/\">jq Manual</link> "
"(http://stedolan.github.com/jq/manual/)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml337(para)
msgid ""
"The <code>-s flag</code> used in the cURL commands above are used to prevent"
" the progress meter from being shown. If you are having trouble running cURL"
" commands, you'll want to remove it. Likewise, to help you troubleshoot cURL"
" commands you can include the <code>-v</code> flag to show you the verbose "
"output. There are many more extremely useful features in cURL; refer to the "
"man page for all the options."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml349(title)
msgid "Servers and Services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml350(para)
msgid ""
"As an administrator, you have a few ways to discover what your OpenStack "
"cloud looks like simply by using the OpenStack tools available. This section"
" gives you an idea of how to get an overview of your cloud, its shape, size,"
" and current state."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml355(para)
msgid ""
"First, you can discover what servers belong to your OpenStack cloud by "
"running:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml358(para)
msgid "The output looks like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml370(para)
msgid ""
"The output shows that there are five compute nodes and one cloud controller."
" You see a smiley face, such as <code>:-)</code> which indicates that the "
"services are up and running. If a service is no longer available, the "
"<code>:-)</code> symbol changes to <code>XXX</code>. This is an indication "
"that you should troubleshoot why the service is down."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml377(para)
msgid ""
"If you are using cinder, run the following command to see a similar listing:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml387(para)
msgid ""
"With these two tables, you now have a good overview of what servers and "
"services make up your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml390(para)
msgid ""
"You can also use the Identity Service (keystone) to see what services are "
"available in your cloud as well as what endpoints have been configured for "
"the services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml393(para)
msgid ""
"The following command requires you to have your shell environment configured"
" with the proper administrative variables."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml418(para)
msgid ""
"The preceding output has been truncated to show only two services. You will "
"see one service block for each service that your cloud provides. Note how "
"the endpoint domain can be different depending on the endpoint type. "
"Different endpoint domains per type are not required, but this can be done "
"for different reasons, such as endpoint privacy or network traffic "
"segregation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml426(para)
msgid ""
"You can find the version of the Compute installation by using the "
"<placeholder-1/> command: <placeholder-2/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml431(title)
msgid "Diagnose Your Compute Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml432(para)
msgid ""
"You can obtain extra information about virtual machines that are "
"running—their CPU usage, the memory, the disk I/O or network I/O—per "
"instance, by running the <placeholder-1/> command with a server ID:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml437(para)
msgid ""
"The output of this command varies depending on the hypervisor because "
"hypervisors support different attributes. The following demonstrates the "
"difference between the two most popular hypervisors. Example output when the"
" hypervisor is Xen: <placeholder-1/>While the command should work with any "
"hypervisor that is controlled through libvirt (e.g., KVM, QEMU, LXC), it has"
" been tested only with KVM. Example output when the hypervisor is KVM:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml481(title)
msgid "Network Inspection"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml482(para)
msgid ""
"To see which fixed IP networks are configured in your cloud, you can use the"
" <placeholder-1/> command-line client to get the IP ranges.<placeholder-2/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml492(para)
msgid "The <placeholder-1/> tool can provide some additional details."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml498(para)
msgid ""
"This output shows that two networks are configured, each network containing "
"255 IPs (a /24 subnet). The first network has been assigned to a certain "
"project, while the second network is still open for assignment. You can "
"assign this network manually, or it is automatically assigned when a project"
" launches its first instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml504(para)
msgid "To find out whether any floating IPs are available in your cloud, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml511(para)
msgid ""
"Here, two floating IPs are available. The first has been allocated to a "
"project, while the other is unallocated."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml515(title)
msgid "Users and Projects"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml516(para)
msgid "To see a list of projects that have been added to the cloud, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml537(para)
msgid "To see a list of users, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml559(para)
msgid ""
"Sometimes a user and a group have a one-to-one mapping. This happens for "
"standard system accounts, such as cinder, glance, nova, and swift, or when "
"only one user is ever part of a group."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml566(title)
msgid "Running Instances"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml567(para)
msgid "To see a list of running instances, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml582(para)
msgid ""
"Unfortunately, this command does not tell you various details about the "
"running instances, such as what compute node the instance is running on, "
"what flavor the instance is, and so on. You can use the following command to"
" view details about individual instances:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml590(para)
msgid "For example: <placeholder-1/><placeholder-2/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml620(para)
msgid ""
"This output shows that an instance named <placeholder-1/> was created from "
"an Ubuntu 12.04 image using a flavor of m1.small and is hosted on the "
"compute node c02.example.com."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml627(para)
msgid ""
"We hope you have enjoyed this quick tour of your working environment, "
"including how to interact with your cloud and extract useful information. "
"From here, you can use the <link href=\" http://docs.openstack.org/user-"
"guide-admin/content/\"><citetitle>Admin User Guide</citetitle></link> as "
"your reference for all of the command line functionality in your cloud."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-nova.xml271(None)
msgid ""
"@@image: 'figures/os-ref-arch.png'; md5=d14dd97ceaea1a78af7f292c5d6bd605"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-nova.xml308(None)
msgid ""
"@@image: 'figures/os_physical_network.png'; "
"md5=1dea1a64bd3be35646459de1b33f3c48"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml16(title)
msgid "Example Architecture - Legacy Networking (nova)"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml17(para)
msgid ""
"This particular example architecture has been upgraded from Grizzly to "
"Havana and tested in production environments where many public IP addresses "
"are available for assignment to multiple instances. You can find a second "
"example architecture that uses OpenStack Networking (neutron) after this "
"section. Each example offers high availability, meaning that if a particular"
" node goes down, another node with the same configuration can take over the "
"tasks so that service continues to be available."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml26(para)
msgid ""
"The simplest architecture you can build upon for Compute has a single cloud "
"controller and multiple compute nodes. The simplest architecture for Object "
"Storage has five nodes: one for identifying users and proxying requests to "
"the API, then four for storage itself to provide enough replication for "
"eventual consistency. This example architecture does not dictate a "
"particular number of nodes, but shows the thinking and considerations that "
"went into choosing this architecture including the features offered."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml46(para)
msgid ""
"Ubuntu 12.04 LTS or Red Hat Enterprise Linux 6.5 including derivatives such "
"as CentOS and Scientific Linux"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml51(para)
msgid ""
"<link href=\"https://wiki.ubuntu.com/ServerTeam/CloudArchive\">Ubuntu Cloud "
"Archive</link> (https://wiki.ubuntu.com/ServerTeam/CloudArchive) or <link "
"href=\"http://openstack.redhat.com/Frequently_Asked_Questions\">RDO</link> "
"(http://openstack.redhat.com/Frequently_Asked_Questions) *"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml65(para)
msgid "MySQL*"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml69(para)
msgid "RabbitMQ for Ubuntu, Qpid for Red Hat Enterprise Linux and derivatives"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml74(para)
#: ./doc/openstack-ops/glossary-terms.xml3169(glossterm)
msgid "nova-network"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml77(para)
msgid "Network manager"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml81(para)
msgid "Single nova-network or multi-host?"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml83(para)
msgid "multi-host*"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml88(para)
msgid "file"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml98(para)
msgid "LVM/iSCSI"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml101(para)
msgid "Live Migration back-end"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml102(para)
msgid "shared storage using NFS *"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml111(para)
msgid ""
"An asterisk (*) indicates when the example architecture deviates from the "
"settings of a default installation. We'll offer explanations for those "
"deviations next."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml120(para)
msgid ""
"<glossterm>dashboard</glossterm>: You probably want to offer a dashboard, "
"but your users may be more interested in API access only."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml123(para)
msgid ""
"<glossterm>block storage</glossterm>: You don't have to offer users block "
"storage if their use case only needs ephemeral storage on compute nodes, for"
" example."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml127(para)
msgid ""
"<glossterm>floating IP address</glossterm>es: Floating IP addresses are "
"public IP addresses that you allocate from a pre-defined pool to assign to "
"virtual machines at launch. Floating IP address ensure that the public IP "
"address is available whenever an instance is booted. Not every organization "
"can offer thousands of public floating IP addresses for thousands of "
"instances, so this feature is considered optional."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml131(para)
msgid ""
"<glossterm>live migration</glossterm>: If you need to move running virtual "
"machine instances from one host to another with little or no service "
"interruption you would enable live migration, but it is considered optional."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml135(para)
msgid ""
"<glossterm>object storage</glossterm>: You may choose to store machine "
"images on a file system rather than in object storage if you do not have the"
" extra hardware for the required replication and redundancy that OpenStack "
"Object Storage offers."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml116(para)
msgid ""
"The following features of OpenStack are supported by the example "
"architecture documented in this guide, but are optional:<placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml147(para)
msgid ""
"This example architecture has been selected based on the current default "
"feature set of OpenStack <glossterm>Havana</glossterm>, with an emphasis on "
"stability. We believe that many clouds that currently run OpenStack in "
"production have made similar choices."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml153(para)
msgid ""
"You must first choose the operating system that runs on all of the physical "
"nodes. While OpenStack is supported on several distributions of Linux, we "
"used <emphasis role=\"bold\">Ubuntu 12.04 LTS (Long Term "
"Support)</emphasis>, which is used by the majority of the development "
"community, has feature completeness compared with other distributions, and "
"has clear future support plans."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml161(para)
msgid ""
"We recommend that you do not use the default Ubuntu OpenStack install "
"packages and instead use the <link "
"href=\"https://wiki.ubuntu.com/ServerTeam/CloudArchive\">Ubuntu Cloud "
"Archive</link> (https://wiki.ubuntu.com/ServerTeam/CloudArchive). The Cloud "
"Archive is a package repository supported by Canonical that allows you to "
"upgrade to future OpenStack releases while remaining on Ubuntu 12.04."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml169(para)
msgid ""
"<emphasis role=\"bold\">KVM</emphasis> as a "
"<glossterm>hypervisor</glossterm> complements the choice of Ubuntu - being a"
" matched pair in terms of support, and also because of the significant "
"degree of attention it garners from the OpenStack development community "
"(including the authors, who mostly use KVM). It is also feature complete, "
"free from licensing charges and restrictions."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml176(para)
msgid ""
"<emphasis role=\"bold\">MySQL</emphasis> follows a similar trend. Despite "
"its recent change of ownership, this database is the most tested for use "
"with OpenStack and is heavily documented. We deviate from the default "
"database, <emphasis>SQLite</emphasis>, because SQLite is not an appropriate "
"database for production usage."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml181(para)
msgid ""
"The choice of <emphasis role=\"bold\"> RabbitMQ</emphasis> over other AMQP "
"compatible options that are gaining support in OpenStack, such as ZeroMQ and"
" Qpid is due to its ease of use and significant testing in production. It "
"also is the only option which supports features such as Compute cells. We "
"recommend clustering with RabbitMQ, as it is an integral component of the "
"system, and fairly simple to implement due to its inbuilt nature."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml188(para)
msgid ""
"As discussed in previous chapters, there are several options for networking "
"in OpenStack Compute. We recommend <emphasis "
"role=\"bold\">FlatDHCP</emphasis> and to use <emphasis role=\"bold\">Multi-"
"Host</emphasis> networking mode for high availability, running one <code"
">nova-network</code> daemon per OpenStack Compute host. This provides a "
"robust mechanism for ensuring network interruptions are isolated to "
"individual compute hosts, and allows for the direct use of hardware network "
"gateways."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml196(para)
msgid ""
"<emphasis role=\"bold\">Live Migration</emphasis> is supported by way of "
"shared storage, with <emphasis role=\"bold\">NFS</emphasis> as the "
"distributed file system."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml199(para)
msgid ""
"Acknowledging that many small-scale deployments see running Object Storage "
"just for the storage of virtual machine images as too costly, we opted for "
"the file back-end in the OpenStack Image Service (Glance). If your cloud "
"will include Object Storage, you can easily add it as a back-end."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml204(para)
msgid ""
"We chose the <emphasis role=\"bold\">SQL back-end for Identity Service "
"(keystone)</emphasis> over others, such as LDAP. This back-end is simple to "
"install and is robust. The authors acknowledge that many installations want "
"to bind with existing directory services, and caution careful understanding "
"of the <link title=\"LDAP config options\" "
"href=\"http://docs.openstack.org/havana/config-reference/content"
"/ch_configuring-openstack-identity.html#configuring-keystone-for-ldap-"
"backend\">array of options available</link> "
"(http://docs.openstack.org/havana/config-reference/content/ch_configuring-"
"openstack-identity.html#configuring-keystone-for-ldap-backend)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml213(para)
msgid ""
"Block Storage (cinder) is installed natively on external storage nodes and "
"uses the <emphasis role=\"bold\">LVM/iSCSI plugin</emphasis>. Most Block "
"Storage Service plugins are tied to particular vendor products and "
"implementations limiting their use to consumers of those hardware platforms,"
" but LVM/iSCSI is robust and stable on commodity hardware."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml219(para)
msgid ""
"While the cloud can be run without the <emphasis role=\"bold\">OpenStack "
"Dashboard</emphasis>, we consider it to be indispensable, not just for user "
"interaction with the cloud, but also as a tool for operators. Additionally, "
"the dashboard's use of Django makes it a flexible framework for extension."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml226(title)
msgid "Why Not Use the OpenStack Network Service (neutron)?"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml228(para)
msgid ""
"This example architecture does not use the OpenStack Network Service "
"(neutron), because it does not yet support multi-host networking and our "
"organizations (university, government) have access to a large range of "
"publicly-accessible IPv4 addresses."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml235(title)
msgid "Why Use Multi-host Networking?"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml236(para)
msgid ""
"In a default OpenStack deployment, there is a single <code>nova-"
"network</code> service that runs within the cloud (usually on the cloud "
"controller) that provides services such as network address translation "
"(NAT), DHCP, and DNS to the guest instances. If the single node that runs "
"the <code>nova-network</code> service goes down, you cannot access your "
"instances and the instances cannot access the Internet. The single node that"
" runs the nova-network service can become a bottleneck if excessive network "
"traffic comes in and goes out of the cloud."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml246(para)
msgid ""
"<link href=\"http://docs.openstack.org/havana/install-"
"guide/install/apt/content/nova-network.html\">Multi-host</link> "
"(http://docs.openstack.org/havana/install-guide/install/apt/content/nova-"
"network.html) is a high-availability option for the network configuration "
"where the nova-network service is run on every compute node instead of "
"running on only a single node."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml259(para)
msgid ""
"The reference architecture consists of multiple compute nodes, a cloud "
"controller, an external NFS storage server for instance storage and an "
"OpenStack Block Storage server for <glossterm>volume</glossterm> storage. A "
"network time service (Network Time Protocol, NTP) synchronizes time on all "
"the nodes. FlatDHCPManager in multi-host mode is used for the networking. A "
"logical diagram for this example architecture shows which services are "
"running on each node:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml275(para)
msgid ""
"The cloud controller runs: the dashboard, the API services, the database "
"(MySQL), a message queue server (RabbitMQ), the scheduler for choosing "
"compute resources (nova-scheduler), Identity services (keystone, <code>nova-"
"consoleauth</code>), Image services (<code>glance-api</code>, <code>glance-"
"registry</code>), services for console access of guests, and Block Storage "
"services including the scheduler for storage resources (<code>cinder-"
"api</code> and <code>cinder-scheduler</code>)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml285(para)
msgid ""
"Compute nodes are where the computing resources are held, and in our example"
" architecture they run the hypervisor (KVM), libvirt (the driver for the "
"hypervisor, which enables live migration from node to node), <code>nova-"
"compute</code>, <code>nova-api-metadata</code> (generally only used when "
"running in multi-host mode, it retrieves instance-specific metadata), <code"
">nova-vncproxy</code>, and <code>nova-network</code>."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml295(para)
msgid ""
"The network consists of two switches, one for the management or private "
"traffic, and one which covers public access including Floating IPs. To "
"support this, the cloud controller and the compute nodes have two network "
"cards. The OpenStack Block Storage and NFS storage servers only need to "
"access the private network and therefore only need one network card, but "
"multiple cards run in a bonded configuration are recommended if possible. "
"Floating IP access is direct to the internet, whereas Flat IP access goes "
"through a NAT. To envision the network traffic use this diagram:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml315(title)
msgid "Optional Extensions"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml316(para)
msgid "You can extend this reference architecture as follows:"
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml320(para)
msgid "Add additional cloud controllers (see <xref linkend=\"maintenance\"/>)."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml324(para)
msgid ""
"Add an OpenStack Storage service (see the Object Storage chapter in the "
"<citetitle>OpenStack Installation Guide</citetitle> for your distribution."
msgstr ""

#: ./doc/openstack-ops/section_arch_example-nova.xml329(para)
msgid ""
"Add additional OpenStack Block Storage hosts (see <xref "
"linkend=\"maintenance\"/>)."
msgstr ""

#: ./doc/openstack-ops/bk_ops_guide.xml16(title)
msgid "OpenStack Operations Guide"
msgstr ""

#: ./doc/openstack-ops/bk_ops_guide.xml18(titleabbrev)
msgid "OpenStack Ops Guide"
msgstr ""

#: ./doc/openstack-ops/bk_ops_guide.xml26(orgname)
#: ./doc/openstack-ops/bk_ops_guide.xml32(holder)
msgid "OpenStack Foundation"
msgstr "OpenStack Alapítvány"

#: ./doc/openstack-ops/bk_ops_guide.xml31(year)
msgid "2014"
msgstr "2014"

#: ./doc/openstack-ops/bk_ops_guide.xml38(remark)
msgid "Copyright details are filled in by the template."
msgstr "Copyright adatok kitöltése a sablonból"

#: ./doc/openstack-ops/bk_ops_guide.xml43(para)
msgid ""
"This book provides information about designing and operating OpenStack "
"clouds."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml14(title)
msgid "Tales From the Cryp^H^H^H^H Cloud"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml16(para)
msgid ""
"Herein lies a selection of tales from OpenStack cloud operators. Read and "
"learn from their wisdom."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml20(title)
msgid "Double VLAN"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml21(para)
msgid ""
"I was on-site in Kelowna, British Columbia, Canada, setting up a new "
"OpenStack cloud. The deployment was fully automated: Cobbler deployed the OS"
" on the bare metal, bootstrapped it, and Puppet took over from there. I had "
"run the deployment scenario so many times in practice and took for granted "
"that everything was working."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml27(para)
msgid ""
"On my last day in Kelowna, I was in a conference call from my hotel. In the "
"background, I was fooling around on the new cloud. I launched an instance "
"and logged in. Everything looked fine. Out of boredom, I ran "
"<placeholder-1/>, and all of the sudden the instance locked up."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml33(para)
msgid ""
"Thinking it was just a one-off issue, I terminated the instance and launched"
" a new one. By then, the conference call ended, and I was off to the data "
"center."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml36(para)
msgid ""
"At the data center, I was finishing up some tasks and remembered the lock-"
"up. I logged in to the new instance and ran <placeholder-1/> again. It "
"worked. Phew. I decided to run it one more time. It locked up. WTF."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml41(para)
msgid ""
"After reproducing the problem several times, I came to the unfortunate "
"conclusion that this cloud did indeed have a problem. Even worse, my time "
"was up in Kelowna, and I had to return to Calgary."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml45(para)
msgid ""
"Where do you even begin troubleshooting something like this? An instance "
"just randomly locks when a command is issued. Is it the image? Nope—it "
"happens on all images. Is it the compute node? Nope—all nodes. Is the "
"instance locked up? No! New SSH connections work just fine!"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml50(para)
msgid ""
"We reached out for help. A networking engineer suggested it was an MTU "
"issue. Great! MTU! Something to go on! What's MTU, and why would it cause a "
"problem?"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml53(para)
msgid ""
"MTU is <emphasis role=\"italic\">maximum transmission unit</emphasis>. It "
"specifies the maximum number of bytes that the interface accepts for each "
"packet. If two interfaces have two different MTUs, bytes might get chopped "
"off and weird things happen—such as random session lockups."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml60(para)
msgid ""
"Not all packets have a size of 1,500. Running the <placeholder-1/> command "
"over SSH might create only a single packet, less than 1,500 bytes. However, "
"running a command with heavy output, such as <placeholder-2/>, requires "
"several packets of 1,500 bytes."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml66(para)
msgid ""
"OK, so where is the MTU issue coming from? Why haven't we seen this in any "
"other deployment? What's new in this situation? Well, new data center, new "
"uplink, new switches, new model of switches, new servers, first time using "
"this model of servers… so, basically, everything was new. Wonderful. We "
"toyed around with raising the MTU at various areas: the switches, the NICs "
"on the compute nodes, the virtual NICs in the instances; we even had the "
"data center raise the MTU for our uplink interface. Some changes worked, "
"some didn't. This line of troubleshooting didn't feel right, though. We "
"shouldn't have to be changing the MTU in these areas."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml78(para)
msgid ""
"As a last resort, our network admin (Alvaro) and I sat down with four "
"terminal windows, a pencil, and a piece of paper. In one window, we ran "
"<placeholder-1/>. In the second window, we ran <placeholder-2/> on the cloud"
" controller. In the third, <placeholder-3/> on the compute node. And the "
"forth had <placeholder-4/> on the instance. For background, this cloud was a"
" multi-node, non-multi-host setup."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml86(para)
msgid ""
"One cloud controller acted as a gateway to all compute nodes. VlanManager "
"was used for the network config. This means that the cloud controller and "
"all compute nodes had a different VLAN for each OpenStack project. We used "
"the -s option of <placeholder-1/> to change the packet size. We watched as "
"sometimes packets would fully return, sometimes they'd only make it out and "
"never back in, and sometimes the packets would stop at a random point. We "
"changed <placeholder-2/> to start displaying the hex dump of the packet. We "
"pinged between every combination of outside, controller, compute, and "
"instance."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml98(para)
msgid ""
"Finally, Alvaro noticed something. When a packet from the outside hits the "
"cloud controller, it should not be configured with a VLAN. We verified this "
"as true. When the packet went from the cloud controller to the compute node,"
" it should have a VLAN only if it was destined for an instance. This was "
"still true. When the ping reply was sent from the instance, it should be in "
"a VLAN. True. When it came back to the cloud controller and on its way out "
"to the public Internet, it should no longer have a VLAN. False. Uh oh. It "
"looked as though the VLAN part of the packet was not being removed."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml109(para)
msgid "That made no sense."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml110(para)
msgid ""
"While bouncing this idea around in our heads, I was randomly typing commands"
" on the compute node: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml117(para)
msgid "\"Hey Alvaro, can you run a VLAN on top of a VLAN?\""
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml119(para)
msgid "\"If you did, you'd add an extra 4 bytes to the packet.\""
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml121(para)
msgid "Then it all made sense… <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml125(para)
msgid ""
"In <filename>nova.conf</filename>, <code>vlan_interface</code> specifies "
"what interface OpenStack should attach all VLANs to. The correct setting "
"should have been: <code>vlan_interface=bond0</code>."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml129(para)
msgid "This would be the server's bonded NIC."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml130(para)
msgid ""
"The vlan20 setting is the VLAN that the data center gave us for outgoing "
"public Internet access. It's a correct VLAN and is also attached to bond0."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml133(para)
msgid ""
"By mistake, I configured OpenStack to attach all tenant VLANs to vlan20 "
"instead of bond0, thereby stacking one VLAN on top of another. This then "
"added an extra 4 bytes to each packet, which caused a packet of 1,504 bytes "
"to be sent out, which would cause problems when it arrived at an interface "
"that accepted 1,500!"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml139(para)
msgid "As soon as this setting was fixed, everything worked."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml143(title)
msgid "The Issue"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml144(para)
msgid ""
"At the end of August 2012, a post-secondary school in Alberta, Canada, "
"migrated its infrastructure to an OpenStack cloud. As luck would have it, "
"within the first day or two of it running, one of its servers just "
"disappeared from the network. Blip. Gone."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml149(para)
msgid ""
"After restarting the instance, everything was back up and running. We "
"reviewed the logs and saw that at some point, network communication stopped "
"and then everything went idle. We chalked this up to a random occurrence."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml154(para)
msgid "A few nights later, it happened again."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml155(para)
msgid ""
"We reviewed both sets of logs. The one thing that stood out the most was "
"DHCP. At the time, OpenStack, by default, set DHCP leases for one minute "
"(it's now two minutes). This means that every instance contacts the cloud "
"controller (DHCP server) to renew its fixed IP. For some reason, this "
"instance could not renew its IP. We correlated the instance's logs with the "
"logs on the cloud controller and put together a conversation:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml166(para)
msgid "Instance tries to renew IP."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml169(para)
msgid "Cloud controller receives the renewal request and sends a response."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml173(para)
msgid "Instance \"ignores\" the response and resends the renewal request."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml177(para)
msgid "Cloud controller receives the second request and sends a new response."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml181(para)
msgid ""
"Instance begins sending a renewal request to <code>255.255.255.255</code> "
"since it hasn't heard back from the cloud controller."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml186(para)
msgid ""
"The cloud controller receives the <code>255.255.255.255</code> request and "
"sends a third response."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml191(para)
msgid "The instance finally gives up."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml194(para)
msgid ""
"With this information in hand, we were sure that the problem had to do with "
"DHCP. We thought that, for some reason, the instance wasn't getting a new IP"
" address, and with no IP, it shut itself off from the network."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml198(para)
msgid ""
"A quick Google search turned up this: <link "
"href=\"https://lists.launchpad.net/openstack/msg11696.html\">DHCP lease "
"errors in VLAN mode</link> "
"(https://lists.launchpad.net/openstack/msg11696.html), which further "
"supported our DHCP theory."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml203(para)
msgid ""
"An initial idea was to just increase the lease time. If the instance renewed"
" only once every week, the chances of this problem happening would be "
"tremendously smaller than every minute. This didn't solve the problem, "
"though. It was just covering the problem up."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml208(para)
msgid ""
"We decided to have <placeholder-1/> run on this instance and see whether we "
"could catch it in action again. Sure enough, we did."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml211(para)
msgid ""
"The <placeholder-1/> looked very, very weird. In short, it looked as though "
"network communication stopped before the instance tried to renew its IP. "
"Since there is so much DHCP chatter from a one-minute lease, it's very hard "
"to confirm it, but even with only milliseconds difference between packets, "
"if one packet arrives first, it arrives first, and if that packet reported "
"network issues, then it had to have happened before DHCP."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml219(para)
msgid ""
"Additionally, the instance in question was responsible for a very, very "
"large backup job each night. While \"the Issue\" (as we were now calling it)"
" didn't happen exactly when the backup happened, it was close enough (a few "
"hours) that we couldn't ignore it."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml224(para)
msgid ""
"More days go by and we catch the Issue in action more and more. We find that"
" dhclient is not running after the Issue happens. Now we're back to thinking"
" it's a DHCP issue. Running <placeholder-1/> brings everything back up and "
"running."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml229(para)
msgid ""
"Ever have one of those days where all of the sudden you get the Google "
"results you were looking for? Well, that's what happened here. I was looking"
" for information on dhclient and why it dies when it can't renew its lease, "
"and all of the sudden I found a bunch of OpenStack and dnsmasq discussions "
"that were identical to the problem we were seeing!"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml236(para)
msgid ""
"<link href=\"http://www.gossamer-"
"threads.com/lists/openstack/operators/18197\">Problem with Heavy Network IO "
"and Dnsmasq</link> (http://www.gossamer-"
"threads.com/lists/openstack/operators/18197)"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml242(para)
msgid ""
"<link href=\"http://www.gossamer-"
"threads.com/lists/openstack/dev/14696\">instances losing IP address while "
"running, due to No DHCPOFFER</link> (http://www.gossamer-"
"threads.com/lists/openstack/dev/14696)"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml248(para)
msgid "Seriously, Google."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml249(para)
msgid ""
"This bug report was the key to everything: <link "
"href=\"https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978\"> KVM"
" images lose connectivity with bridged network</link> "
"(https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978)"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml255(para)
msgid ""
"It was funny to read the report. It was full of people who had some strange "
"network problem but didn't quite explain it in the same way."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml258(para)
msgid "So it was a QEMU/KVM bug."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml259(para)
msgid ""
"At the same time I found the bug report, a co-worker was able to "
"successfully reproduce the Issue! How? He used <placeholder-1/> to spew a "
"ton of bandwidth at an instance. Within 30 minutes, the instance just "
"disappeared from the network."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml264(para)
msgid ""
"Armed with a patched QEMU and a way to reproduce, we set out to see if we "
"had finally solved the Issue. After 48 straight hours of hammering the "
"instance with bandwidth, we were confident. The rest is history. You can "
"search the bug report for \"joe\" to find my comments and actual tests."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml272(title)
msgid "Disappearing Images"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml273(para)
msgid ""
"At the end of 2012, Cybera (a nonprofit with a mandate to oversee the "
"development of cyberinfrastructure in Alberta, Canada) deployed an updated "
"OpenStack cloud for their <link title=\"DAIR project\" "
"href=\"http://www.canarie.ca/en/dair-program/about\">DAIR project</link> "
"(http://www.canarie.ca/en/dair-program/about). A few days into production, a"
" compute node locked up. Upon rebooting the node, I checked to see what "
"instances were hosted on that node so I could boot them on behalf of the "
"customer. Luckily, only one instance."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml284(para)
msgid ""
"The <placeholder-1/> command wasn't working, so I used <placeholder-2/>, but"
" it immediately came back with an error saying it was unable to find the "
"backing disk. In this case, the backing disk is the glance image that is "
"copied to <filename>/var/lib/nova/instances/_base</filename> when the image "
"is used for the first time. Why couldn't it find it? I checked the "
"directory, and sure enough it was gone."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml293(para)
msgid ""
"I reviewed the <code>nova</code> database and saw the instance's entry in "
"the <code>nova.instances</code> table. The image that the instance was using"
" matched what <placeholder-1/> was reporting, so no inconsistency there."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml298(para)
msgid ""
"I checked glance and noticed that this image was a snapshot that the user "
"created. At least that was good news—this user would have been the only user"
" affected."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml302(para)
msgid ""
"Finally, I checked StackTach and reviewed the user's events. They had "
"created and deleted several snapshots—most likely experimenting. Although "
"the timestamps didn't match up, my conclusion was that they launched their "
"instance and then deleted the snapshot and it was somehow removed from "
"<filename>/var/lib/nova/instances/_base</filename>. None of that made sense,"
" but it was the best I could come up with."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml311(para)
msgid ""
"It turns out the reason that this compute node locked up was a hardware "
"issue. We removed it from the DAIR cloud and called Dell to have it "
"serviced. Dell arrived and began working. Somehow or another (or a fat "
"finger), a different compute node was bumped and rebooted. Great."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml317(para)
msgid ""
"When this node fully booted, I ran through the same scenario of seeing what "
"instances were running so that I could turn them back on. There were a total"
" of four. Three booted and one gave an error. It was the same error as "
"before: unable to find the backing disk. Seriously, what?"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml323(para)
msgid ""
"Again, it turns out that the image was a snapshot. The three other instances"
" that successfully started were standard cloud images. Was it a problem with"
" snapshots? That didn't make sense."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml327(para)
msgid ""
"A note about DAIR's architecture: "
"<filename>/var/lib/nova/instances</filename> is a shared NFS mount. This "
"means that all compute nodes have access to it, which includes the "
"<code>_base</code> directory. Another centralized area is "
"<filename>/var/log/rsyslog</filename> on the cloud controller. This "
"directory collects all OpenStack logs from all compute nodes. I wondered if "
"there were any entries for the file that <placeholder-1/> is reporting: "
"<placeholder-2/>"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml342(para)
msgid "Ah-hah! So OpenStack was deleting it. But why?"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml343(para)
msgid ""
"A feature was introduced in Essex to periodically check and see whether "
"there were any <code>_base</code> files not in use. If there were, nova "
"would delete them. This idea sounds innocent enough and has some good "
"qualities to it. But how did this feature end up turned on? It was disabled "
"by default in Essex. As it should be. It was <link "
"href=\"https://bugs.launchpad.net/nova/+bug/1029674\">decided to enable it "
"in Folsom</link> (https://bugs.launchpad.net/nova/+bug/1029674). I cannot "
"emphasize enough that:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml355(emphasis)
msgid "Actions that delete things should not be enabled by default."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml358(para)
msgid "Disk space is cheap these days. Data recovery is not."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml360(para)
msgid ""
"Secondly, DAIR's shared <filename>/var/lib/nova/instances</filename> "
"directory contributed to the problem. Since all compute nodes have access to"
" this directory, all compute nodes periodically review the _base directory. "
"If there is only one instance using an image, and the node that the instance"
" is on is down for a few minutes, it won't be able to mark the image as "
"still in use. Therefore, the image seems like it's not in use and is "
"deleted. When the compute node comes back online, the instance hosted on "
"that node is unable to start."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml373(title)
msgid "The Valentine's Day Compute Node Massacre"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml374(para)
msgid ""
"Although the title of this story is much more dramatic than the actual "
"event, I don't think, or hope, that I'll have the opportunity to use "
"\"Valentine's Day Massacre\" again in a title."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml378(para)
msgid ""
"This past Valentine's Day, I received an alert that a compute node was no "
"longer available in the cloud—meaning,"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml382(para)
msgid "showed this particular node with a status of <code>XXX</code>."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml384(para)
msgid ""
"I logged in to the cloud controller and was able to both <placeholder-1/> "
"and SSH into the problematic compute node, which seemed very odd. Usually "
"when I receive this type of alert, the compute node has totally locked up "
"and would be inaccessible."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml389(para)
msgid "After a few minutes of troubleshooting, I saw the following details:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml393(para)
msgid "A user recently tried launching a CentOS instance on that node"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml397(para)
msgid "This user was the only user on the node (new node)"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml401(para)
msgid "The load shot up to 8 right before I received the alert"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml405(para)
msgid "The bonded 10gb network device (bond0) was in a DOWN state"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml409(para)
msgid "The 1gb NIC was still alive and active"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml412(para)
msgid ""
"I looked at the status of both NICs in the bonded pair and saw that neither "
"was able to communicate with the switch port. Seeing as how each NIC in the "
"bond is connected to a separate switch, I thought that the chance of a "
"switch port dying on each switch at the same time was quite improbable. I "
"concluded that the 10gb dual port NIC had died and needed to be replaced. I "
"created a ticket for the hardware support department at the data center "
"where the node was hosted. I felt lucky that this was a new node and no one "
"else was hosted on it yet."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml422(para)
msgid ""
"An hour later I received the same alert, but for another compute node. Crap."
" OK, now there's definitely a problem going on. Just as with the original "
"node, I was able to log in by SSH. The bond0 NIC was DOWN, but the 1gb NIC "
"was active."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml427(para)
msgid ""
"And the best part: the same user had just tried creating a CentOS instance. "
"What?"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml429(para)
msgid ""
"I was totally confused at this point, so I texted our network admin to see "
"if he was available to help. He logged in to both switches and immediately "
"saw the problem: the switches detected spanning tree packets coming from the"
" two compute nodes and immediately shut the ports down to prevent spanning "
"tree loops: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml442(para)
msgid ""
"He reenabled the switch ports, and the two compute nodes immediately came "
"back to life."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml444(para)
msgid ""
"Unfortunately, this story has an open ending... we're still looking into why"
" the CentOS image was sending out spanning tree packets. Further, we're "
"researching a proper way for how to mitigate this from happening. It's a "
"bigger issue than one might think. While it's extremely important for "
"switches to prevent spanning tree loops, it's very problematic to have an "
"entire compute node be cut from the network when this happens. If a compute "
"node is hosting 100 instances and one of them sends a spanning tree packet, "
"that instance has effectively DDOS'd the other 99 instances."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml455(para)
msgid ""
"This is an ongoing and hot topic in networking circles—especially with the "
"rise of virtualization and virtual switches."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml460(title)
msgid "Down the Rabbit Hole"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml461(para)
msgid ""
"Users being able to retrieve console logs from running instances is a boon "
"for support—many times they can figure out what's going on inside their "
"instance and fix what's going on without bothering you. Unfortunately, "
"sometimes overzealous logging of failures can cause problems of its own."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml467(para)
msgid ""
"A report came in: VMs were launching slowly, or not at all. Cue the standard"
" checks—nothing on the Nagios, but there was a spike in network toward the "
"current master of our RabbitMQ cluster. Investigation started, but soon the "
"other parts of the queue cluster were leaking memory like a sieve. Then the "
"alert came in: the master rabbit server went down. Connections failed over "
"to the slave."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml474(para)
msgid ""
"At that time, our control services were hosted by another team. We didn't "
"have much debugging information to determine what was going on with the "
"master, and couldn't reboot it. That team noted that the master failed "
"without alert, but they managed to reboot it. After an hour, the cluster had"
" returned to its normal state, and we went home for the day."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml481(para)
msgid ""
"Continuing the diagnosis the next morning was kick-started by another "
"identical failure. We quickly got the message queue running again and tried "
"to work out why Rabbit was suffering from so much network traffic. Enabling "
"debug logging on <systemitem class=\"service\">nova-api</systemitem> quickly"
" brought understanding. A <placeholder-1/> was scrolling by faster than we'd"
" ever seen before. CTRL+C on that, and we could plainly see the contents of "
"a system log spewing failures over and over again—a system log from one of "
"our users' instances."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml493(para)
msgid ""
"After finding the instance ID, we headed over to "
"<filename>/var/lib/nova/instances</filename> to find the "
"<filename>console.log</filename>: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml501(para)
msgid ""
"Sure enough, the user had been periodically refreshing the console log page "
"on the dashboard and the 5 GB file was traversing the rabbit cluster to get "
"to the dashboard."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml505(para)
msgid ""
"We called the user and asked her to stop for a while, and she was happy to "
"abandon the horribly broken VM. After that, we started monitoring the size "
"of console logs."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml509(para)
msgid ""
"To this day, <link href=\"https://bugs.launchpad.net/nova/+bug/832507\">the "
"issue</link> (https://bugs.launchpad.net/nova/+bug/832507) doesn't have a "
"permanent resolution, but we look forward to the discussion at the next "
"summit."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml517(title)
msgid "Havana Haunted by the Dead"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml518(para)
msgid ""
"Felix Lee of Academia Sinica Grid Computing Centre in Taiwan contributed "
"this story."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml520(para)
msgid ""
"I just upgraded OpenStack from Grizzly to Havana 2013.2-2 using the RDO "
"repository and everything was running pretty well—except the EC2 API."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml523(para)
msgid ""
"I noticed that the API would suffer from a heavy load and respond slowly to "
"particular EC2 requests, such as <literal>RunInstances</literal>."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml526(para)
msgid "Output from <filename>/var/log/nova/nova-api.log</filename> on Havana:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml535(para)
msgid ""
"This request took more than two minutes to process, but it executed quickly "
"on another co-existing Grizzly deployment using the same hardware and system"
" configuration."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml538(para)
msgid ""
"Output from <filename>/var/log/nova/nova-api.log</filename> on Grizzly:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml547(para)
msgid ""
"While monitoring system resources, I noticed a significant increase in "
"memory consumption while the EC2 API processed this request. I thought it "
"wasn't handling memory properly—possibly not releasing memory. If the API "
"received several of these requests, memory consumption quickly grew until "
"the system ran out of RAM and began using swap. Each node has 48 GB of RAM, "
"and the \"nova-api\" process would consume all of it within minutes. Once "
"this happened, the entire system would become unusably slow until I "
"restarted the <systemitem class=\"service\">nova-api</systemitem> service."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml557(para)
msgid ""
"So, I found myself wondering what changed in the EC2 API on Havana that "
"might cause this to happen. Was it a bug or normal behavior that I now need "
"to work around?"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml560(para)
msgid ""
"After digging into the nova code, I noticed two areas in "
"<filename>api/ec2/cloud.py</filename> potentially impacting my system:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml572(para)
msgid ""
"Since my database contained many records—over 1 million metadata records and"
" over 300,000 instance records in \"deleted\" or \"errored\" states—each "
"search took ages. I decided to clean up the database by first archiving a "
"copy for backup and then performing some deletions using the MySQL client. "
"For example, I ran the following SQL command to remove rows of instances "
"deleted for more than a year:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml580(para)
msgid ""
"Performance increased greatly after deleting the old records and my new "
"deployment continues to behave well."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml14(title)
msgid "Scaling"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml15(para)
msgid ""
"Whereas traditional applications required larger hardware to scale "
"(\"vertical scaling\"), cloud-based applications typically request more, "
"discrete hardware (\"horizontal scaling\"). If your cloud is successful, "
"eventually you must add resources to meet the increasing demand."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml20(para)
msgid ""
"To suit the cloud paradigm, OpenStack itself is designed to be horizontally "
"scalable. Rather than switching to larger servers, you procure more servers "
"and simply install identically configured services. Ideally, you scale out "
"and load balance among groups of functionally identical services (for "
"example, compute nodes, nova-api nodes), that communicate on a message bus."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml28(title)
msgid "The Starting Point"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml29(para)
msgid ""
"Determining the scalability of your cloud and how to improve it is an "
"exercise with many variables to balance. No one solution meets everyone's "
"scalability goals. However, it is helpful to track a number of metrics. "
"Since you can define virtual hardware templates called \"flavors\" in "
"OpenStack, you can start to make scaling decisions based on the flavors "
"you'll provide. These templates define sizes for memory in RAM, root disk "
"size, amount of ephemeral data disk space available, and number of cores for"
" starters."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml37(para)
msgid "The default OpenStack flavors are:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml42(th)
msgid "Virtual cores"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml43(th)
msgid "Memory"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml50(para)
msgid "m1.tiny"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml52(para)
msgid "512 MB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml53(para)
msgid "1 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml54(para)
msgid "0 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml57(para)
msgid "m1.small"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml59(para)
msgid "2 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml60(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml67(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml74(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml81(para)
msgid "10 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml61(para)
msgid "20 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml64(para)
msgid "m1.medium"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml66(para)
msgid "4 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml68(para)
msgid "40 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml71(para)
msgid "m1.large"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml73(para)
msgid "8 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml75(para)
msgid "80 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml78(para)
msgid "m1.xlarge"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml79(para)
msgid "8"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml80(para)
msgid "16 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml82(para)
msgid "160 GB"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml90(para)
msgid ""
"The number of virtual machines (VMs) you expect to run, <code>((overcommit "
"fraction × cores) / virtual cores per instance)</code>,"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml94(para)
msgid ""
"How much storage is required <code>(flavor disk size × number of "
"instances)</code>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml86(para)
msgid ""
"The starting point for most is the core count of your cloud. By applying "
"some ratios, you can gather information about: <placeholder-1/> You can use "
"these ratios to determine how much additional infrastructure you need to "
"support your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml100(para)
msgid ""
"Here is an example using the ratios for gathering scalability information "
"for the number of VMs expected as well as the storage needed. The following "
"numbers support (200 / 2) × 16 = 1600 VM instances and require 80 TB of "
"storage for <code>/var/lib/nova/instances</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml107(para)
msgid "200 physical cores"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml110(para)
msgid ""
"Most instances are size m1.medium (two virtual cores, 50 GB of storage)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml114(para)
msgid ""
"Default CPU over-commit ratio (<code>cpu_allocation_ratio</code> in "
"nova.conf) of 16:1"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml119(para)
msgid ""
"However, you need more than the core count alone to estimate the load that "
"the API services, database servers, and queue servers are likely to "
"encounter. You must also consider the usage patterns of your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml123(para)
msgid ""
"As a specific example, compare a cloud that supports a managed web-hosting "
"platform with one running integration tests for a development project that "
"creates one VM per code commit. In the former, the heavy work of creating a "
"VM happens only every few months, whereas the latter puts constant heavy "
"load on the cloud controller. You must consider your average VM lifetime, as"
" a larger number generally means less load on the cloud controller."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml131(para)
msgid ""
"Aside from the creation and termination of VMs, you must consider the impact"
" of users accessing the service—particularly on nova-api and its associated "
"database. Listing instances garners a great deal of information and, given "
"the frequency with which users run this operation, a cloud with a large "
"number of users can increase the load significantly. This can occur even "
"without their knowledge—leaving the OpenStack dashboard instances tab open "
"in the browser refreshes the list of VMs every 30 seconds."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml142(para)
msgid ""
"After you consider these factors, you can determine how many cloud "
"controller cores you require. A typical eight core, 8 GB of RAM server is "
"sufficient for up to a rack of compute nodes — given the above caveats."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml146(para)
msgid ""
"You must also consider key hardware specifications for the performance of "
"user VMs. You must consider both budget and performance needs. Examples "
"include: storage performance (spindles/core), memory availability "
"(RAM/core), network bandwidth (Gbps/core), and overall CPU performance "
"(CPU/core)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml152(para)
msgid ""
"For a discussion of metric tracking, including how to extract metrics from "
"your cloud, see <xref linkend=\"logging_monitoring\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml159(title)
msgid "Adding Cloud Controller Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml160(para)
msgid ""
"You can facilitate the horizontal expansion of your cloud by adding nodes. "
"Adding compute nodes is straightforward—they are easily picked up by the "
"existing installation. However, you must consider some important points when"
" you design your cluster to be highly available."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml166(para)
msgid ""
"Recall that a cloud controller node runs several different services. You can"
" install services that communicate only using the message queue "
"internally—<code>nova-scheduler</code> and <code>nova-console</code>—on a "
"new server for expansion. However, other integral parts require more care."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml173(para)
msgid ""
"You should load balance user-facing services such as Dashboard, <code>nova-"
"api</code>, or the Object Storage proxy. Use any standard HTTP load-"
"balancing method (DNS round robin, hardware load balancer, software such as "
"Pound or HAProxy). One caveat with Dashboard is the VNC proxy, which uses "
"the WebSocket protocol—something that an L7 load balancer might struggle "
"with. See also <link title=\"Horizon session storage\" "
"href=\"http://docs.openstack.org/developer/horizon/topics/deployment.html"
"#session-storage\">Horizon session storage</link> "
"(http://docs.openstack.org/developer/horizon/topics/deployment.html#session-"
"storage)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml184(para)
msgid ""
"You can configure some services, such as <code>nova-api</code> and <code"
">glance-api</code>, to use multiple processes by changing a flag in their "
"configuration file—allowing them to share work between multiple cores on the"
" one machine."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml190(para)
msgid ""
"Several options are available for MySQL load balancing, and the supported "
"AMQP brokers have in-built clustering support. Information on how to "
"configure these and many of the other services can be found in <emphasis "
"role=\"bold\">Part II: Operations</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml200(title)
msgid "Segregating Your Cloud"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml201(para)
msgid ""
"When you want to offer users different regions to provide legal "
"considerations for data storage, redundancy across earthquake fault lines, "
"or for low-latency API calls, you segregate your cloud. Use one of the "
"following OpenStack methods to segregate your cloud: "
"<emphasis>cells</emphasis>, <emphasis>regions</emphasis>, "
"<emphasis>zones</emphasis>, and <emphasis>host aggregates</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml209(para)
msgid ""
"Each method provides different functionality, and can be best divided into "
"two groups:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml213(para)
msgid ""
"Cells and regions, which segregate an entire cloud and result in running "
"separate Compute deployments."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml217(para)
msgid ""
"<glossterm baseform=\"Availability zone\">Availability zones</glossterm> and"
" host aggregates, which merely divide a single Compute deployment."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml221(para)
msgid ""
"<xref linkend=\"segragation_methods\"/> provides a comparison view of each "
"segregation method currently provided by OpenStack Compute."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml225(caption)
msgid "OpenStack Segregation Methods"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml229(th)
msgid "Cells"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml230(th)
msgid "Regions"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml231(th)
msgid "Availability Zones"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml232(th)
msgid "Host Aggregates"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml237(emphasis)
msgid "Use when you need"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml240(para)
msgid ""
"A single <glossterm>API endpoint</glossterm> for compute, or you require a "
"second level of scheduling."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml244(para)
msgid ""
"Discrete regions with separate API endpoints and no coordination between "
"regions."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml247(para)
msgid ""
"Logical separation within your nova deployment for physical isolation or "
"redundancy."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml250(para)
msgid "To schedule a group of hosts with common features."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml254(emphasis)
msgid "Example"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml256(para)
msgid ""
"A cloud with multiple sites where you can schedule VMs \"anywhere\" or on a "
"particular site."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml259(para)
msgid ""
"A cloud with multiple sites, where you schedule VMs to a particular site and"
" you want a shared infrastructure."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml262(para)
msgid "A single-site cloud with equipment fed by separate power supplies."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml264(para)
msgid "Scheduling to hosts with trusted hardware support."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml269(emphasis)
msgid "Overhead"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml274(para)
msgid "Considered experimental."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml277(para)
msgid "A new service, <code>nova-cells</code>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml280(para)
msgid "Each cell has a full nova installation except <code>nova-api</code>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml287(para)
msgid "A different API endpoint for every region."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml291(para)
msgid "Each region has a full nova installation."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml299(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml306(para)
msgid "Configuration changes to <filename>nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml312(emphasis)
msgid "Shared services"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml315(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml317(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml318(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml320(para)
msgid "Keystone"
msgstr "Keystone"

#: ./doc/openstack-ops/ch_arch_scaling.xml315(code)
msgid "nova-api"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml318(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml320(para)
msgid "All nova services"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml327(title)
msgid "Cells and Regions"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml328(para)
msgid ""
"OpenStack Compute cells are designed to allow running the cloud in a "
"distributed fashion without having to use more complicated technologies, or "
"being invasive to existing nova installations. Hosts in a cloud are "
"partitioned into groups called <emphasis>cells</emphasis>. Cells are "
"configured in a tree. The top-level cell (\"API cell\") has a host that runs"
" the <code>nova-api</code> service, but no <code>nova-compute</code> "
"services. Each child cell runs all of the other typical <code>nova-*</code> "
"services found in a regular installation, except for the <code>nova-"
"api</code> service. Each cell has its own message queue and database "
"service, and also runs <code>nova-cells</code> — which manages the "
"communication between the API cell and child cells."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml344(para)
msgid ""
"This allows for a single API server being used to control access to multiple"
" cloud installations. Introducing a second level of scheduling (the cell "
"selection), in addition to the regular <code>nova-scheduler</code> selection"
" of hosts, provides greater flexibility to control where virtual machines "
"are run."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml351(para)
msgid ""
"Contrast this with regions. Regions have a separate API endpoint per "
"installation, allowing for a more discrete separation. Users wanting to run "
"instances across sites have to explicitly select a region. However, the "
"additional complexity of a running a new service is not required."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml357(para)
msgid ""
"The OpenStack dashboard (horizon) currently uses only a single region, so "
"one dashboard service should be run per region. Regions are a robust way to "
"share some infrastructure between OpenStack Compute installations, while "
"allowing for a high degree of failure tolerance."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml365(title)
msgid "Availability Zones and Host Aggregates"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml366(para)
msgid ""
"You can use availability zones, host aggregates, or both to partition a nova"
" deployment."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml368(para)
msgid ""
"Availability zones are implemented through and configured in a similar way "
"to host aggregates."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml370(para)
msgid "However, you use them for different reasons:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml373(para)
msgid ""
"<emphasis role=\"bold\">Availability zone</emphasis>. Enables you to arrange"
" OpenStack Compute hosts into logical groups, and provides a form of "
"physical isolation and redundancy from other availability zones, such as by "
"using a separate power supply or network equipment."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml379(para)
msgid ""
"You define the availability zone in which a specified Compute host resides "
"locally on each server. An availability zone is commonly used to identify a "
"set of servers that have a common attribute. For instance, if some of the "
"racks in your data center are on a separate power source, you can put "
"servers in those racks in their own availability zone. Availability zones "
"can also help separate different classes of hardware."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml387(para)
msgid ""
"When users provision resources, they can specify from which availability "
"zone they want their instance to be built. This allows cloud consumers to "
"ensure that their application resources are spread across disparate machines"
" to achieve high availability in the event of hardware failure."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml395(para)
msgid ""
"<emphasis role=\"bold\">Host aggregates</emphasis>. Enable you to partition "
"OpenStack Compute deployments into logical groups for load balancing and "
"instance distribution. You can use host aggregates to further partition an "
"availability zone. For example, you might use host aggregates to partition "
"an availability zone into groups of hosts that either share common "
"resources, such as storage and network, or have a special property, such as "
"trusted computing hardware."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml404(para)
msgid ""
"A common use of host aggregates is to provide information for use with the "
"nova-scheduler. For example, you might use a host aggregate to group a set "
"of hosts that share specific flavors or images."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml408(para)
msgid ""
"The general case for this is setting key-value pairs in the aggregate "
"metadata and matching key-value pairs in instance type extra specs. The "
"<parameter>AggregateInstanceExtraSpecsFilter</parameter> in the filter "
"scheduler will enforce that instances be scheduled only on hosts in "
"aggregates that define the same key to the same value."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml415(para)
msgid ""
"An advanced use of this general concept allows different instance types to "
"run with different CPU and RAM allocation rations so that high-intensity "
"computing loads and low-intensity development and testing systems can share "
"the same cloud without either starving the high-use systems or wasting "
"resources on low-utilization systems. This works by setting "
"<parameter>metadata</parameter> in your host aggregates and matching "
"<parameter>extra_specs</parameter> in your instance types."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml426(para)
msgid ""
"The first step is setting the aggregate metadata keys "
"<parameter>cpu_allocation_ratio</parameter> and "
"<parameter>ram_allocation_ration</parameter> to a floating point value. The "
"filter schedulers <parameter>AggregateCoreFilter</parameter> and "
"<parameter>AggregateRamFilter</parameter> will use those values rather than "
"the global defaults in <filename>nova.conf</filename> when scheduling to "
"hosts in the aggregate. It is important to be cautious when using this "
"feature since each host can be in multiple aggregates but should have only "
"one allocation ratio for each resources. It is up to you to avoid putting a "
"host in multiple aggregates that define different values for the same "
"resource."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml440(para)
msgid ""
"This is the first half of the equation. To get instance types that are "
"guaranteed a particular ratio, you must set the "
"<parameter>extra_specs</parameter> in the instance type to the key value "
"pair you want to match in the aggregate. For example if you define "
"<parameter>extra "
"specs</parameter><parameter>cpu_allocation_ratio</parameter> to \"1.0\", "
"then instances of that type will run in aggregates only where the metadata "
"key <parameter>cpu_allocation_ratio</parameter> is also defined as \"1.0.\" "
"In practice, it is better to define an additional key-value pair in the "
"aggregate metadata to match on rather than match directly on "
"<parameter>cpu_allocation_ratio</parameter> or "
"<parameter>core_allocation_ratio</parameter>. This allows better "
"abstraction. For example, by defining a key "
"<parameter>overcommit</parameter> and setting a value of \"high,\" "
"\"medium,\" or \"low,\" you could then tune the numeric allocation ratios in"
" the aggregates without also needing to change all instance types relating "
"to them."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml463(para)
msgid ""
"Previously, all services had an availability zone. Currently, only the nova-"
"compute service has its own availability zone. Services such as nova-"
"scheduler, nova-network, and nova-conductor have always spanned all "
"availability zones."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml472(para)
msgid "nova host-list (os-hosts)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml475(para)
msgid "euca-describe-availability-zones verbose"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml479(para)
msgid "nova-manage service list"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml468(para)
msgid ""
"When you run any of the following operations, the services appear in their "
"own internal availability zone (CONF.internal_service_availability_zone): "
"<placeholder-1/>The internal availability zone is hidden in euca-describe-"
"availability_zones (non-verbose)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml484(para)
msgid ""
"CONF.node_availability_zone has been renamed to "
"CONF.default_availability_zone and is used only by the nova-api and nova-"
"scheduler services."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml487(para)
msgid "CONF.node_availability_zone still works but is deprecated."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml492(title)
msgid "Scalable Hardware"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml493(para)
msgid ""
"While several resources already exist to help with deploying and installing "
"OpenStack, it's very important to make sure that you have your deployment "
"planned out ahead of time. This guide presumes that you have at least set "
"aside a rack for the OpenStack cloud but also offers suggestions for when "
"and what to scale."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml500(title)
msgid "Hardware Procurement"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml501(para)
msgid ""
"“The Cloud” has been described as a volatile environment where servers can "
"be created and terminated at will. While this may be true, it does not mean "
"that your servers must be volatile. Ensuring that your cloud’s hardware is "
"stable and configured correctly means that your cloud environment remains up"
" and running. Basically, put effort into creating a stable hardware "
"environment so that you can host a cloud that users may treat as unstable "
"and volatile."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml510(para)
msgid ""
"OpenStack can be deployed on any hardware supported by an OpenStack-"
"compatible Linux distribution."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml512(para)
msgid ""
"Hardware does not have to be consistent, but it should at least have the "
"same type of CPU to support instance migration."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml515(para)
msgid ""
"The typical hardware recommended for use with OpenStack is the standard "
"value-for-money offerings that most hardware vendors stock. It should be "
"straightforward to divide your procurement into building blocks such as "
"\"compute,\" \"object storage,\" and \"cloud controller,\" and request as "
"many of these as you need. Alternatively, should you be unable to spend "
"more, if you have existing servers—provided they meet your performance "
"requirements and virtualization technology—they are quite likely to be able "
"to support OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml528(title)
msgid "Capacity Planning"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml529(para)
msgid ""
"OpenStack is designed to increase in size in a straightforward manner. "
"Taking into account the considerations that we've mentioned in this "
"chapter—particularly on the sizing of the cloud controller—it should be "
"possible to procure additional compute or object storage nodes as needed. "
"New nodes do not need to be the same specification, or even vendor, as "
"existing nodes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml537(para)
msgid ""
"For compute nodes, <code>nova-scheduler</code> will take care of differences"
" in sizing having to do with core count and RAM amounts, however you should "
"consider that the user experience changes with differing CPU speeds. When "
"adding object storage nodes, a <glossterm>weight</glossterm> should be "
"specified that reflects the <glossterm>capability</glossterm> of the node."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml545(para)
msgid ""
"Monitoring the resource usage and user growth will enable you to know when "
"to procure. The <xref linkend=\"logging_monitoring\"/> chapter details some "
"useful metrics."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml551(title)
msgid "Burn-in Testing"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml552(para)
msgid ""
"Server hardware's chance of failure is high at the start and the end of its "
"life. As a result, much effort in dealing with hardware failures while in "
"production can be avoided by appropriate burn-in testing to attempt to "
"trigger the early-stage failures. The general principle is to stress the "
"hardware to its limits. Examples of burn-in tests include running a CPU or "
"disk benchmark for several days."
msgstr ""

#. Add role="auto" above if you want to only generate a glossary
#.      with entries that are marked with glossterm/firstterm
#: ./doc/openstack-ops/glossary-terms.xml15(title)
msgid "Glossary"
msgstr "Szójegyzék"

#: ./doc/openstack-ops/glossary-terms.xml16(para)
msgid ""
"Use this glossary to get definitions of OpenStack-related words and phrases."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml18(para)
msgid ""
"To add to this glossary, fork the <literal>openstack/openstack-"
"manuals</literal> repository on github.com and update the source files "
"through the OpenStack contribution process."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml25(title)
msgid "A"
msgstr "A"

#: ./doc/openstack-ops/glossary-terms.xml27(glossterm)
msgid "absolute limit"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml29(para)
msgid ""
"Impassable limits for guest VMs. Settings include total RAM size, maximum "
"number of vCPUs, and maximum disk size."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml35(glossterm)
msgid "access control list"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml37(para)
msgid ""
"A list of permissions attached to an object. An ACL specifies which users or"
" system processes have access to objects. It also defines which operations "
"can be performed on specified objects. Each entry in a typical ACL specifies"
" a subject and an operation. For instance, the ACL entry <code>(Alice, "
"delete)</code> for a file gives Alice permission to delete the file."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml50(glossterm)
msgid "access key"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml52(para)
msgid "Alternative term for an Amazon EC2 access key. See EC2 access key."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml57(glossterm)
msgid "account"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml59(para)
msgid ""
"The Object Storage context of an account. Do not confuse with a user account"
" from an authentication service such as Active Directory, /etc/passwd, "
"OpenLDAP, OpenStack Identity Service, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml66(glossterm)
msgid "account auditor"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml68(para)
msgid ""
"Checks for missing replicas and incorrect or corrupted objects in a "
"specified Object Storage account by running queries against the back-end "
"SQLite database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml75(glossterm)
msgid "account database"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml77(para)
msgid ""
"A SQLite database that contains Object Storage accounts and related metadata"
" and that the accounts server accesses."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml83(glossterm)
msgid "account reaper"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml85(para)
msgid ""
"An Object Storage worker that scans for and deletes account databases and "
"that the account server has marked for deletion."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml92(glossterm)
msgid "account server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml94(para)
msgid ""
"Lists containers in Object Storage and stores container information in the "
"account database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml99(glossterm)
msgid "account service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml101(para)
msgid ""
"An Object Storage component that provides account services such as list, "
"create, modify, and audit. Do not confuse with OpenStack Identity Service, "
"OpenLDAP, or similar user account services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml108(glossterm)
msgid "accounting"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml110(para)
msgid ""
"The Compute Service provides accounting information through the event "
"notification and system usage data facilities."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml116(glossterm)
msgid "ACL"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml118(para)
msgid "See access control list."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml122(glossterm)
msgid "active/active configuration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml124(para)
msgid ""
"In a high availability setup with an active/active configuration, several "
"systems share the load together and if one fails, the load is distributed to"
" the remaining systems."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml132(glossterm)
msgid "Active Directory"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml134(para)
msgid ""
"Authentication and identity service by Microsoft, based on LDAP. Supported "
"in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml140(glossterm)
msgid "active/passive configuration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml142(para)
msgid ""
"In a high-availability setup with an active/passive configuration, systems "
"are set up to bring additional resources online to replace those that have "
"failed."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml150(glossterm)
msgid "address pool"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml152(para)
msgid ""
"A group of fixed and/or floating IP addresses that are assigned to a project"
" and can be used by or assigned to the VM instances in a project."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml159(glossterm)
msgid "admin API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml161(para)
msgid ""
"A subset of API calls that are accessible to authorized administrators and "
"are generally not accessible to end users or the public Internet. They can "
"exist as a separate service (keystone) or can be a subset of another API "
"(nova)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml169(glossterm)
msgid "admin server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml171(para)
msgid ""
"In the context of the Identity Service, the worker process that provides "
"access to the admin API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml176(glossterm)
msgid "Advanced Message Queuing Protocol (AMQP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml179(para)
msgid ""
"The open standard messaging protocol used by OpenStack components for intra-"
"service communications, provided by RabbitMQ, Qpid, or ZeroMQ."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml186(glossterm)
msgid "Advanced RISC Machine (ARM)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml188(para)
msgid ""
"Lower power consumption CPU often found in mobile and embedded devices. "
"Supported by OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml194(glossterm)
msgid "alert"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml196(para)
msgid ""
"The Compute Service can send alerts through its notification system, which "
"includes a facility to create custom notification drivers. Alerts can be "
"sent to and displayed on the horizon dashboard."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml203(glossterm)
msgid "allocate"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml205(para)
msgid ""
"The process of taking a floating IP address from the address pool so it can "
"be associated with a fixed IP on a guest VM instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml211(glossterm)
msgid "Amazon Kernel Image (AKI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml213(para)
#: ./doc/openstack-ops/glossary-terms.xml220(para)
#: ./doc/openstack-ops/glossary-terms.xml227(para)
msgid ""
"Both a VM container format and disk format. Supported by Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml218(glossterm)
msgid "Amazon Machine Image (AMI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml225(glossterm)
msgid "Amazon Ramdisk Image (ARI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml232(glossterm)
msgid "Anvil"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml234(para)
msgid ""
"A project that ports the shell script-based project named DevStack to "
"Python."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml239(glossterm)
msgid "Apache"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml241(para)
msgid ""
"The Apache Software Foundation supports the Apache community of open-source "
"software projects. These projects provide software products for the public "
"good."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml248(glossterm)
msgid "Apache License 2.0"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml250(para)
msgid ""
"All OpenStack core projects are provided under the terms of the Apache "
"License 2.0 license."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml256(glossterm)
msgid "Apache Web Server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml258(para)
msgid "The most common web server software currently used on the Internet."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml263(glossterm)
msgid "API"
msgstr "API"

#: ./doc/openstack-ops/glossary-terms.xml265(para)
msgid "Application programming interface."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml269(glossterm)
msgid "API endpoint"
msgstr "API végpont"

#: ./doc/openstack-ops/glossary-terms.xml271(para)
msgid ""
"The daemon, worker, or service that a client communicates with to access an "
"API. API endpoints can provide any number of services, such as "
"authentication, sales data, performance metrics, Compute VM commands, census"
" data, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml280(glossterm)
msgid "API extension"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml282(para)
msgid "Custom modules that extend some OpenStack core APIs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml288(glossterm)
msgid "API extension plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml290(para)
msgid "Alternative term for a Networking plug-in or Networking API extension."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml295(glossterm)
msgid "API key"
msgstr "API kulcs"

#: ./doc/openstack-ops/glossary-terms.xml297(para)
msgid "Alternative term for an API token."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml301(glossterm)
msgid "API server"
msgstr "API kiszolgáló"

#: ./doc/openstack-ops/glossary-terms.xml303(para)
msgid "Any node running a daemon or worker that provides an API endpoint."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml308(glossterm)
msgid "API token"
msgstr "API token"

#: ./doc/openstack-ops/glossary-terms.xml310(para)
msgid ""
"Passed to API requests and used by OpenStack to verify that the client is "
"authorized to run the requested operation."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml316(glossterm)
msgid "API version"
msgstr "API verzió"

#: ./doc/openstack-ops/glossary-terms.xml318(para)
msgid ""
"In OpenStack, the API version for a project is part of the URL. For example,"
" <filename>example.com/nova/v1/foobar</filename>."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml324(glossterm)
msgid "applet"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml326(para)
msgid "A Java program that can be embedded into a web page."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml331(glossterm)
#: ./doc/openstack-ops/ch_arch_cloud_controller.xml355(title)
msgid "Application Programming Interface (API)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml334(para)
msgid ""
"A collection of specifications used to access a service, application, or "
"program. Includes service calls, required parameters for each call, and the "
"expected return values."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml341(glossterm)
msgid "application server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml343(para)
msgid ""
"A piece of software that makes available another piece of software over a "
"network."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml348(glossterm)
msgid "Application Service Provider (ASP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml350(para)
msgid ""
"Companies that rent specialized applications that help businesses and "
"organizations provide additional services with less cost."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml356(glossterm)
msgid "arptables"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml358(para)
msgid ""
"Tool used for maintaining Address Resolution Protocol packet filter rules in"
" the Linux kernel firewall modules. Used along with iptables, ebtables, and "
"ip6tables in Compute to provide firewall services for VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml365(glossterm)
msgid "associate"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml367(para)
msgid ""
"The process associating a Compute floating IP address with a fixed IP "
"address."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml372(glossterm)
msgid "Asynchronous JavaScript and XML (AJAX)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml375(para)
msgid ""
"A group of interrelated web development techniques used on the client-side "
"to create asynchronous web applications. Used extensively in horizon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml382(glossterm)
msgid "ATA over Ethernet (AoE)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml384(para)
msgid "A disk storage protocol tunneled within Ethernet."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml389(glossterm)
msgid "attach"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml391(para)
msgid ""
"The process of connecting a VIF or vNIC to a L2 network in Networking. In "
"the context of Compute, this process connects a storage volume to an "
"instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml398(glossterm)
msgid "attachment (network)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml400(para)
msgid ""
"Association of an interface ID to a logical port. Plugs an interface into a "
"port."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml405(glossterm)
msgid "auditing"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml407(para)
msgid "Provided in Compute through the system usage data facility."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml412(glossterm)
msgid "auditor"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml414(para)
msgid ""
"A worker process that verifies the integrity of Object Storage objects, "
"containers, and accounts. Auditors is the collective term for the Object "
"Storage account auditor, container auditor, and object auditor."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml424(para)
msgid "Project name for the initial release of OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml429(glossterm)
msgid "auth node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml431(para)
msgid "Alternative term for an Object Storage authorization node."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml436(glossterm)
msgid "authentication"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml438(para)
msgid ""
"The process that confirms that the user, process, or client is really who "
"they say they are through private key, secret token, password, fingerprint, "
"or similar method."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml445(glossterm)
msgid "authentication token"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml447(para)
msgid ""
"A string of text provided to the client after authentication. Must be "
"provided by the user or process in subsequent requests to the API endpoint."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml454(glossterm)
msgid "AuthN"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml456(para)
msgid "The Identity Service component that provides authentication services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml461(glossterm)
msgid "authorization"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml463(para)
msgid ""
"The act of verifying that a user, process, or client is authorized to "
"perform an action."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml468(glossterm)
msgid "authorization node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml470(para)
msgid "An Object Storage node that provides authorization services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml475(glossterm)
msgid "AuthZ"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml477(para)
msgid ""
"The Identity Service component that provides high-level authorization "
"services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml482(glossterm)
msgid "Auto ACK"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml484(para)
msgid ""
"Configuration setting within RabbitMQ that enables or disables message "
"acknowledgment. Enabled by default."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml490(glossterm)
msgid "auto declare"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml492(para)
msgid ""
"A Compute RabbitMQ setting that determines whether a message exchange is "
"automatically created when the program starts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml498(glossterm)
msgid "availability zone"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml500(para)
msgid ""
"An Amazon EC2 concept of an isolated area that is used for fault tolerance. "
"Do not confuse with an OpenStack Compute zone or cell."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml506(glossterm)
msgid "AWS"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml508(para)
msgid "Amazon Web Services."
msgstr "Amazon Web Services."

#: ./doc/openstack-ops/glossary-terms.xml514(title)
msgid "B"
msgstr "B"

#: ./doc/openstack-ops/glossary-terms.xml516(glossterm)
msgid "back end"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml518(para)
msgid ""
"Interactions and processes that are obfuscated from the user, such as "
"Compute volume mount, data transmission to an iSCSI target by a daemon, or "
"Object Storage object integrity checks."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml526(glossterm)
msgid "back-end catalog"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml528(para)
msgid ""
"The storage method used by the Identity Service catalog service to store and"
" retrieve information about API endpoints that are available to the client. "
"Examples include a SQL database, LDAP database, or KVS back end."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml536(glossterm)
msgid "back-end store"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml538(para)
msgid ""
"The persistent data store used to save and retrieve information for a "
"service, such as lists of Object Storage objects, current state of guest "
"VMs, lists of user names, and so on. Also, the method that the Image Service"
" uses to get and store VM images. Options include Object Storage, local file"
" system, S3, and HTTP."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml548(glossterm)
msgid "bandwidth"
msgstr "sávszélesség"

#: ./doc/openstack-ops/glossary-terms.xml550(para)
msgid ""
"The amount of available data used by communication resources such as the "
"Internet. Represents the amount of data that is used to download things or "
"the amount of data available to download."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml558(glossterm)
msgid "bare"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml560(para)
msgid ""
"An Image Service container format that indicates that no container exists "
"for the VM image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml565(glossterm)
msgid "base image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml567(para)
msgid "An OpenStack-provided image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml573(para)
msgid ""
"A grouped release of projects related to OpenStack that came out in February"
" of 2011. It included Compute (nova) and Object Storage (swift) only."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml580(glossterm)
msgid "binary"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml582(para)
msgid ""
"Information that consists solely of ones and zeroes, which is the language "
"of computers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml587(glossterm)
msgid "bit"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml589(para)
msgid ""
"A bit is a single digit number that is in base of 2 (either a zero or one). "
"Bandwidth usage is measured in bits-per-second."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml595(glossterm)
msgid "bits-per-second (BPS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml597(para)
msgid ""
"The universal measurement of how quickly data is transferred from place to "
"place."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml602(glossterm)
msgid "block device"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml604(para)
msgid ""
"A device that moves data in the form of blocks. These device nodes interface"
" the devices, such as hard disks, CD-ROM drives, flash drives, and other "
"addressable regions of memory."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml611(glossterm)
msgid "block migration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml613(para)
msgid ""
"A method of VM live migration used by KVM to evacuate instances from one "
"host to another with very little downtime during a user-initiated switch-"
"over. Does not require shared storage. Supported by Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml623(para)
msgid ""
"The OpenStack core project that enables management of volumes, volume "
"snapshots, and volume types. The project name of Block Storage is cinder."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml630(glossterm)
msgid "BMC"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml632(para)
msgid ""
"Baseboard Management Controller. The intelligence in the IPMI architecture, "
"which is a specialized micro-controller that is embedded on the motherboard "
"of a computer and acts as a server. Manages the interface between system "
"management software and platform hardware."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml641(glossterm)
msgid "bootable disk image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml643(para)
msgid "A type of VM image that exists as a single, bootable file."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml648(glossterm)
msgid "Bootstrap Protocol (BOOTP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml650(para)
msgid ""
"A network protocol used by a network client to obtain an IP address from a "
"configuration server. Provided in Compute through the dnsmasq daemon when "
"using either the FlatDHCP manager or VLAN manager network manager."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml658(glossterm)
msgid "browser"
msgstr "böngésző"

#: ./doc/openstack-ops/glossary-terms.xml660(para)
msgid ""
"Any client software that enables a computer or device to access the "
"Internet."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml665(glossterm)
msgid "builder file"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml667(para)
msgid ""
"Contains configuration information that Object Storage uses to reconfigure a"
" ring or to re-create it from scratch after a serious failure."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml674(glossterm)
msgid "button class"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml676(para)
msgid ""
"A group of related button types within horizon. Buttons to start, stop, and "
"suspend VMs are in one class. Buttons to associate and disassociate floating"
" IP addresses are in another class, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml684(glossterm)
msgid "byte"
msgstr "báj"

#: ./doc/openstack-ops/glossary-terms.xml686(para)
msgid ""
"Set of bits that make up a single character; there are usually 8 bits to a "
"byte."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml693(title)
msgid "C"
msgstr "C"

#: ./doc/openstack-ops/glossary-terms.xml695(glossterm)
msgid "CA"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml697(para)
msgid ""
"Certificate Authority or Certification Authority. In cryptography, an entity"
" that issues digital certificates. The digital certificate certifies the "
"ownership of a public key by the named subject of the certificate. This "
"enables others (relying parties) to rely upon signatures or assertions made "
"by the private key that corresponds to the certified public key. In this "
"model of trust relationships, a CA is a trusted third party for both the "
"subject (owner) of the certificate and the party relying upon the "
"certificate. CAs are characteristic of many public key infrastructure (PKI) "
"schemes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml713(glossterm)
msgid "cache pruner"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml715(para)
msgid ""
"A program that keeps the Image Service VM image cache at or below its "
"configured maximum size."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml722(para)
msgid ""
"An OpenStack grouped release of projects that came out in the spring of "
"2011. It included Compute (nova), Object Storage (swift), and the Image "
"Service (glance)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml729(glossterm)
msgid "CALL"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml731(para)
msgid ""
"One of the RPC primitives used by the OpenStack message queue software. "
"Sends a message and waits for a response."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml737(glossterm)
msgid "capability"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml739(para)
msgid ""
"Defines resources for a cell, including CPU, storage, and networking. Can "
"apply to the specific services within a cell or a whole cell."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml745(glossterm)
msgid "capacity cache"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml747(para)
msgid ""
"A Compute back-end database table that contains the current workload, amount"
" of free RAM, and number of VMs running on each host. Used to determine on "
"which VM a host starts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml754(glossterm)
msgid "capacity updater"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml756(para)
msgid ""
"A notification driver that monitors VM instances and updates the capacity "
"cache as needed."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml761(glossterm)
msgid "CAST"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml763(para)
msgid ""
"One of the RPC primitives used by the OpenStack message queue software. "
"Sends a message and does not wait for a response."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml769(glossterm)
msgid "catalog"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml771(para)
msgid ""
"A list of API endpoints that are available to a user after authentication "
"with the Identity Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml778(glossterm)
msgid "catalog service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml780(para)
msgid ""
"An Identity Service that lists API endpoints that are available to a user "
"after authentication with the Identity Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml788(glossterm)
msgid "ceilometer"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml790(para)
msgid ""
"The project name for the Telemetry service, which is an integrated project "
"that provides metering and measuring facilities for OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml796(glossterm)
msgid "cell"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml798(para)
msgid ""
"Provides logical partitioning of Compute resources in a child and parent "
"relationship. Requests are passed from parent cells to child cells if the "
"parent cannot provide the requested resource."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml806(glossterm)
msgid "cell forwarding"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml808(para)
msgid ""
"A Compute option that enables parent cells to pass resource requests to "
"child cells if the parent cannot provide the requested resource."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml814(glossterm)
msgid "cell manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml816(para)
msgid ""
"The Compute component that contains a list of the current capabilities of "
"each host within the cell and routes requests as appropriate."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml822(glossterm)
msgid "CentOS"
msgstr "CentOS"

#: ./doc/openstack-ops/glossary-terms.xml824(para)
#: ./doc/openstack-ops/glossary-terms.xml1325(para)
#: ./doc/openstack-ops/glossary-terms.xml3321(para)
#: ./doc/openstack-ops/glossary-terms.xml3772(para)
#: ./doc/openstack-ops/glossary-terms.xml4375(para)
msgid "A Linux distribution that is compatible with OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml831(para)
msgid ""
"Massively scalable distributed storage system that consists of an object "
"store, block store, and POSIX-compatible distributed file system. Compatible"
" with OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml838(glossterm)
msgid "CephFS"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml840(para)
msgid "The POSIX-compliant file system provided by Ceph."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml845(glossterm)
msgid "certificate authority"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml847(para)
msgid ""
"A simple certificate authority provided by Compute for cloudpipe VPNs and VM"
" image decryption."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml852(glossterm)
msgid "Challenge-Handshake Authentication Protocol (CHAP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml855(para)
msgid "An iSCSI authentication method supported by Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml860(glossterm)
msgid "chance scheduler"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml862(para)
msgid ""
"A scheduling method used by Compute that randomly chooses an available host "
"from the pool."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml867(glossterm)
msgid "changes since"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml869(para)
msgid ""
"A Compute API parameter that downloads changes to the requested item since "
"your last request, instead of downloading a new, fresh set of data and "
"comparing it against the old data."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml877(glossterm)
msgid "Chef"
msgstr "Chef"

#: ./doc/openstack-ops/glossary-terms.xml879(para)
msgid ""
"An operating system configuration management tool supporting OpenStack "
"deployments."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml884(glossterm)
msgid "child cell"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml886(para)
msgid ""
"If a requested resource such as CPU time, disk storage, or memory is not "
"available in the parent cell, the request is forwarded to its associated "
"child cells. If the child cell can fulfill the request, it does. Otherwise, "
"it attempts to pass the request to any of its children."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml895(glossterm)
msgid "cinder"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml897(para)
msgid "A core OpenStack project that provides block storage services for VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml902(glossterm)
msgid "Cisco neutron plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml904(para)
msgid ""
"A Networking plug-in for Cisco devices and technologies including UCS and "
"Nexus."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml909(glossterm)
msgid "cloud architect"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml911(para)
msgid "A person who plans, designs, and oversees the creation of clouds."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml916(glossterm)
msgid "cloud computing"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml918(para)
msgid ""
"A model that enables access to a shared pool of configurable computing "
"resources, such as networks, servers, storage, applications, and services, "
"that can be rapidly provisioned and released with minimal management effort "
"or service provider interaction."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml927(glossterm)
msgid "cloud controller"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml929(para)
msgid ""
"Collection of Compute components that represent the global state of the "
"cloud, talks to services such as Identity Service authentication, Object "
"Storage, and node/storage workers through a queue."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml936(glossterm)
msgid "cloud controller node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml938(para)
msgid ""
"A node that runs network, volume, API, scheduler, and image services. Each "
"service may be broken out into separate nodes for scalability or "
"availability."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml945(glossterm)
msgid "Cloud Data Management Interface (CDMI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml948(para)
msgid ""
"SINA standard that defines a RESTful API for managing objects in the cloud, "
"currently unsupported in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml954(glossterm)
msgid "Cloud Infrastructure Management Interface (CIMI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml957(para)
msgid ""
"An in-progress specification for cloud management. Currently unsupported in "
"OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml963(glossterm)
msgid "cloud-init"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml965(para)
msgid ""
"A package commonly installed in VM images that performs initialization of an"
" instance after boot using information that it retrieves from the metadata "
"service, such as the SSH public key and user data."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml973(glossterm)
msgid "cloudadmin"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml975(para)
msgid ""
"One of the default roles in the Compute RBAC system. Grants complete system "
"access."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml980(glossterm)
msgid "cloudpipe"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml982(para)
msgid "A Compute service that creates VPNs on a per-project basis."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml987(glossterm)
msgid "cloudpipe image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml989(para)
msgid ""
"A pre-made VM image that serves as a cloudpipe server. Essentially, OpenVPN "
"running on Linux."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml995(glossterm)
msgid "CMDB"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml997(para)
msgid "Configuration Management Database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1001(glossterm)
msgid "command filter"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1003(para)
msgid "Lists allowed commands within the Compute rootwrap facility."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1008(glossterm)
msgid "community project"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1010(para)
msgid ""
"A project that is not officially endorsed by the OpenStack Foundation. If "
"the project is successful enough, it might be elevated to an incubated "
"project and then to a core project, or it might be merged with the main code"
" trunk."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1018(glossterm)
msgid "compression"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1020(para)
msgid ""
"Reduce the size of files by special encoding, the file can be decompressed "
"again to its original content. OpenStack supports compression at the Linux "
"file system level but does not support compression for things such as Object"
" Storage objects or Image Service VM images."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1031(para)
msgid ""
"The OpenStack core project that provides compute services. The project name "
"of the Compute Service is nova."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1037(glossterm)
msgid "Compute API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1039(para)
msgid ""
"The <systemitem class=\"service\">nova-api</systemitem> daemon provides "
"access to nova services. Can communicate with other APIs, such as the Amazon"
" EC2 API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1046(glossterm)
msgid "compute controller"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1048(para)
msgid ""
"The Compute component that chooses suitable hosts on which to start VM "
"instances."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1053(glossterm)
msgid "compute host"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1055(para)
msgid "Physical host dedicated to running compute nodes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1060(glossterm)
msgid "compute node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1062(para)
msgid ""
"A node that runs the <systemitem class=\"service\">nova-compute</systemitem>"
" daemon which manages VM instances that provide a wide range of services "
"such as a web applications and analytics."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1072(glossterm)
msgid "compute service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1074(para)
msgid "Name for the Compute component that manages VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1079(glossterm)
msgid "compute worker"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1081(para)
msgid ""
"The Compute component that runs on each compute node and manages the VM "
"instance life cycle, including run, reboot, terminate, attach/detach "
"volumes, and so on. Provided by the <systemitem class=\"service\">nova-"
"compute</systemitem> daemon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1090(glossterm)
msgid "concatenated object"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1092(para)
msgid ""
"A set of segment objects that Object Storage combines and sends to the "
"client."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1098(glossterm)
msgid "conductor"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1100(para)
msgid ""
"In Compute, conductor is the process that proxies database requests from the"
" compute process. Using conductor improves security because compute nodes do"
" not need direct access to the database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1107(glossterm)
msgid "consistency window"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1109(para)
msgid ""
"The amount of time it takes for a new Object Storage object to become "
"accessible to all clients."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1114(glossterm)
msgid "console log"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1116(para)
msgid "Contains the output from a Linux VM console in Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1121(glossterm)
msgid "container"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1123(para)
msgid ""
"Organizes and stores objects in Object Storage. Similar to the concept of a "
"Linux directory but cannot be nested. Alternative term for an Image Service "
"container format."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1130(glossterm)
msgid "container auditor"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1132(para)
msgid ""
"Checks for missing replicas or incorrect objects in specified Object Storage"
" containers through queries to the SQLite back-end database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1138(glossterm)
msgid "container database"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1140(para)
msgid ""
"A SQLite database that stores Object Storage containers and container "
"metadata. The container server accesses this database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1148(glossterm)
msgid "container format"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1150(para)
msgid ""
"A wrapper used by the Image Service that contains a VM image and its "
"associated metadata, such as machine state, OS disk size, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1158(glossterm)
msgid "container server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1160(para)
msgid "An Object Storage server that manages containers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1164(glossterm)
msgid "container service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1166(para)
msgid ""
"The Object Storage component that provides container services, such as "
"create, delete, list, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1172(glossterm)
msgid "controller node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1174(para)
msgid "Alternative term for a cloud controller node."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1179(glossterm)
msgid "core API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1181(para)
msgid ""
"Depending on context, the core API is either the OpenStack API or the main "
"API of a specific core project, such as Compute, Networking, Image Service, "
"and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1188(glossterm)
msgid "core project"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1190(para)
msgid ""
"An official OpenStack project. Currently consists of Compute (nova), Object "
"Storage (swift), Image Service (glance), Identity (keystone), Dashboard "
"(horizon), Networking (neutron), and Block Storage (cinder). The Telemetry "
"module (ceilometer) and Orchestration module (heat) are integrated projects "
"as of the Havana release. In the Icehouse release, the Database module "
"(trove) gains integrated project status."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1204(glossterm)
msgid "cost"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1206(para)
msgid ""
"Under the Compute distributed scheduler this is calculated by looking at the"
" capabilities of each host relative to the flavor of the VM instance being "
"requested."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1213(glossterm)
msgid "credentials"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1215(para)
msgid ""
"Data that is only known to or accessible by a user and used to verify that "
"the user is who they say they are. Credentials are presented to the server "
"during authentication. Examples include a password, secret key, digital "
"certificate, fingerprint, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1225(glossterm)
msgid "Crowbar"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1227(para)
msgid ""
"An open source community project by Dell that aims to provide all necessary "
"services to quickly deploy clouds."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1233(glossterm)
msgid "current workload"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1235(para)
msgid ""
"An element of the Compute capacity cache that is calculated based on the "
"number of build, snapshot, migrate, and resize operations currently in "
"progress on a given host."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1242(glossterm)
msgid "customer"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1244(para)
msgid "Alternative term for tenant."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1248(glossterm)
msgid "customization module"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1250(para)
msgid ""
"A user-created Python module that is loaded by horizon to change the look "
"and feel of the dashboard."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1258(title)
msgid "D"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1260(glossterm)
msgid "daemon"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1262(para)
msgid ""
"A process that runs in the background and waits for requests. May or may not"
" listen on a TCP or UDP port. Do not confuse with a worker."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1268(glossterm)
msgid "DAC"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1270(para)
msgid ""
"Discretionary access control. Governs the ability of subjects to access "
"objects, while enabling users to make policy decisions and assign security "
"attributes. The traditional UNIX system of users, groups, and read-write-"
"execute permissions is an example of DAC."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1279(glossterm)
msgid "dashboard"
msgstr "vezérlőpult"

#: ./doc/openstack-ops/glossary-terms.xml1281(para)
msgid ""
"The web-based management interface for OpenStack. An alternative name for "
"horizon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1286(glossterm)
msgid "data encryption"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1288(para)
msgid ""
"Both Image Service and Compute support encrypted virtual machine (VM) images"
" (but not instances). In-transit data encryption is supported in OpenStack "
"using technologies such as HTTPS, SSL, TLS, and SSH. Object Storage does not"
" support object encryption at the application level but may support storage "
"that uses disk encryption."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1298(glossterm)
msgid "database ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1300(para)
msgid "A unique ID given to each replica of an Object Storage database."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1305(glossterm)
msgid "database replicator"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1307(para)
msgid ""
"An Object Storage component that copies changes in the account, container, "
"and object databases to other nodes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1313(glossterm)
msgid "deallocate"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1315(para)
msgid ""
"The process of removing the association between a floating IP address and a "
"fixed IP address. Once this association is removed, the floating IP returns "
"to the address pool."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1323(glossterm)
msgid "Debian"
msgstr "Debian"

#: ./doc/openstack-ops/glossary-terms.xml1330(glossterm)
msgid "deduplication"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1332(para)
msgid ""
"The process of finding duplicate data at the disk block, file, and/or object"
" level to minimize storage use—currently unsupported within OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1339(glossterm)
msgid "default panel"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1341(para)
msgid ""
"The default panel that is displayed when a user accesses the horizon "
"dashboard."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1346(glossterm)
msgid "default tenant"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1348(para)
msgid ""
"New users are assigned to this tenant if no tenant is specified when a user "
"is created."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1354(glossterm)
msgid "default token"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1356(para)
msgid ""
"An Identity Service token that is not associated with a specific tenant and "
"is exchanged for a scoped token."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1362(glossterm)
msgid "delayed delete"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1364(para)
msgid ""
"An option within Image Service so that an image is deleted after a "
"predefined number of seconds instead of immediately."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1372(glossterm)
msgid "delivery mode"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1374(para)
msgid ""
"Setting for the Compute RabbitMQ message delivery mode; can be set to either"
" transient or persistent."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1380(glossterm)
msgid "deprecated auth"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1382(para)
msgid ""
"An option within Compute that enables administrators to create and manage "
"users through the <placeholder-1/> command as opposed to using the Identity "
"Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1389(glossterm)
msgid "developer"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1391(para)
msgid ""
"One of the default roles in the Compute RBAC system and is the default role "
"assigned to a new user."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1397(glossterm)
msgid "device ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1399(para)
msgid "Maps Object Storage partitions to physical storage devices."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1404(glossterm)
msgid "device weight"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1406(para)
msgid ""
"Distributes partitions proportionately across Object Storage devices based "
"on the storage capacity of each device."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1414(glossterm)
msgid "DevStack"
msgstr "DevStack"

#: ./doc/openstack-ops/glossary-terms.xml1416(para)
msgid ""
"Community project that uses shell scripts to quickly build complete "
"OpenStack development environments."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1422(glossterm)
msgid "DHCP"
msgstr "DHCP"

#: ./doc/openstack-ops/glossary-terms.xml1424(para)
msgid ""
"Dynamic Host Configuration Protocol. A network protocol that configures "
"devices that are connected to a network so that they can communicate on that"
" network by using the Internet Protocol (IP). The protocol is implemented in"
" a client-server model where DHCP clients request configuration data such "
"as, an IP address, a default route, and one or more DNS server addresses "
"from a DHCP server."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1439(para)
msgid ""
"A grouped release of projects related to OpenStack that came out in the fall"
" of 2011, the fourth release of OpenStack. It included Compute (nova "
"2011.3), Object Storage (swift 1.4.3), and the Image Service (glance)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1447(glossterm)
msgid "direct consumer"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1449(para)
msgid ""
"An element of the Compute RabbitMQ that comes to life when a RPC call is "
"executed. It connects to a direct exchange through a unique exclusive queue,"
" sends the message, and terminates."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1456(glossterm)
msgid "direct exchange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1458(para)
msgid ""
"A routing table that is created within the Compute RabbitMQ during RPC "
"calls, one is created for each RPC call that is invoked."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1464(glossterm)
msgid "direct publisher"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1466(para)
msgid ""
"Element of RabbitMQ that provides a response to an incoming MQ message."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1471(glossterm)
msgid "disassociate"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1473(para)
msgid ""
"The process of removing the association between a floating IP address and "
"fixed IP and thus returning the floating IP address to the address pool."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1480(glossterm)
msgid "disk encryption"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1482(para)
msgid ""
"The ability to encrypt data at the file system, disk partition, or whole-"
"disk level. Supported within Compute VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1488(glossterm)
msgid "disk format"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1490(para)
msgid ""
"The underlying format that a disk image for a VM is stored as within the "
"Image Service back-end store. For example, AMI, ISO, QCOW2, VMDK, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1496(glossterm)
msgid "dispersion"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1498(para)
msgid ""
"In Object Storage, tools to test and ensure dispersion of objects and "
"containers to ensure fault tolerance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1504(glossterm)
msgid "Django"
msgstr "Django"

#: ./doc/openstack-ops/glossary-terms.xml1506(para)
msgid "A web framework used extensively in horizon."
msgstr "A Horizon által használt web keretrendszer."

#: ./doc/openstack-ops/glossary-terms.xml1513(para)
msgid ""
"Domain Name Server. A hierarchical and distributed naming system for "
"computers, services, and resources connected to the Internet or a private "
"network. Associates a human-friendly names to IP addresses."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1521(glossterm)
msgid "DNS record"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1523(para)
msgid ""
"A record that specifies information about a particular domain and belongs to"
" the domain."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1529(glossterm)
msgid "dnsmasq"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1531(para)
msgid ""
"Daemon that provides DNS, DHCP, BOOTP, and TFTP services, used by the "
"Compute VLAN manager and FlatDHCP manager."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1537(glossterm)
msgid "domain"
msgstr "domain"

#: ./doc/openstack-ops/glossary-terms.xml1539(para)
msgid ""
"Separates a web site from other sites. Often, the domain name has two or "
"more parts that are separated by dots. For example, yahoo.com, usa.gov, "
"Harvard.edu, or mail.yahoo.com."
msgstr "Megkülönbözteti az egyik weboldalt a másiktól. A domain név gyakran két vagy több részt tartalmaz, pontokkal elválasztva. Például yahoo.com, usa.gov, Harvard.eu vagy mail. yahoo.com"

#: ./doc/openstack-ops/glossary-terms.xml1543(para)
msgid ""
"A domain is an entity or container of all DNS-related information containing"
" one or more records."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1549(glossterm)
msgid "Domain Name Service (DNS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1551(para)
msgid ""
"In Compute, the support that enables associating DNS entries with floating "
"IP addresses, nodes, or cells so that hostnames are consistent across "
"reboots."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1558(glossterm)
msgid "Domain Name System (DNS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1560(para)
msgid ""
"A system by which Internet domain name-to-address and address-to-name "
"resolutions are determined."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1563(para)
msgid ""
"DNS helps navigate the Internet by translating the IP address into an "
"address that is easier to remember For example, translating 111.111.111.1 "
"into www.yahoo.com."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1567(para)
msgid ""
"All domains and their components, such as mail servers, utilize DNS to "
"resolve to the appropriate locations. DNS servers are usually set up in a "
"master-slave relationship such that failure of the master invokes the slave."
" DNS servers might also be clustered or replicated such that changes made to"
" one DNS server are automatically propagated to other active servers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1578(glossterm)
msgid "download"
msgstr "letöltés"

#: ./doc/openstack-ops/glossary-terms.xml1580(para)
msgid ""
"The transfer of data, usually in the form of files, from one computer to "
"another."
msgstr "Adattovábbítás módja, általában fájlok formájában, egyik gépről a másikra."

#: ./doc/openstack-ops/glossary-terms.xml1585(glossterm)
msgid "DRTM"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1587(para)
msgid "Dynamic root of trust measurement."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1591(glossterm)
msgid "durable exchange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1593(para)
msgid ""
"The Compute RabbitMQ message exchange that remains active when the server "
"restarts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1598(glossterm)
msgid "durable queue"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1600(para)
msgid ""
"A Compute RabbitMQ message queue that remains active when the server "
"restarts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1605(glossterm)
msgid "Dynamic Host Configuration Protocol (DHCP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1608(para)
msgid ""
"A method to automatically configure networking for a host at boot time. "
"Provided by both Networking and Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1614(glossterm)
msgid "Dynamic HyperText Markup Language (DHTML)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1617(para)
msgid ""
"Pages that use HTML, JavaScript, and Cascading Style Sheets to enable users "
"to interact with a web page or show simple animation."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1625(title)
msgid "E"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1627(glossterm)
msgid "EBS boot volume"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1629(para)
msgid ""
"An Amazon EBS storage volume that contains a bootable VM image, currently "
"unsupported in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1635(glossterm)
#: ./doc/openstack-ops/glossary-terms.xml1764(glossterm)
msgid "ebtables"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1637(para)
msgid ""
"Used in Compute along with arptables, iptables, and ip6tables to create "
"firewalls and to ensure isolation of network communications."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1643(glossterm)
msgid "EC2"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1645(para)
msgid "The Amazon commercial compute product, similar to Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1650(glossterm)
msgid "EC2 access key"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1652(para)
msgid "Used along with an EC2 secret key to access the Compute EC2 API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1657(glossterm)
msgid "EC2 API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1659(para)
msgid "OpenStack supports accessing the Amazon EC2 API through Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1664(glossterm)
msgid "EC2 Compatibility API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1666(para)
msgid ""
"A Compute component that enables OpenStack to communicate with Amazon EC2."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1671(glossterm)
msgid "EC2 secret key"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1673(para)
msgid ""
"Used along with an EC2 access key when communicating with the Compute EC2 "
"API; used to digitally sign each request."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1679(glossterm)
msgid "Elastic Block Storage (EBS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1681(para)
msgid "The Amazon commercial block storage product."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1686(glossterm)
msgid "encryption"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1688(para)
msgid ""
"OpenStack supports encryption technologies such as HTTPS, SSH, SSL, TLS, "
"digital certificates, and data encryption."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1694(glossterm)
msgid "endpoint"
msgstr "végpont"

#: ./doc/openstack-ops/glossary-terms.xml1696(para)
msgid "See API endpoint."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1700(glossterm)
msgid "endpoint registry"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1702(para)
msgid "Alternative term for an Identity Service catalog."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1706(glossterm)
msgid "endpoint template"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1708(para)
msgid ""
"A list of URL and port number endpoints that indicate where a service, such "
"as Object Storage, Compute, Identity, and so on, can be accessed."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1715(glossterm)
msgid "entity"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1717(para)
msgid ""
"Any piece of hardware or software that wants to connect to the network "
"services provided by Networking, the network connectivity service. An entity"
" can make use of Networking by implementing a VIF."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1725(glossterm)
msgid "ephemeral image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1727(para)
msgid ""
"A VM image that does not save changes made to its volumes and reverts them "
"to their original state after the instance is terminated."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1733(glossterm)
msgid "ephemeral volume"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1735(para)
msgid ""
"Volume that does not save the changes made to it and reverts to its original"
" state when the current user relinquishes control."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1743(para)
msgid ""
"A grouped release of projects related to OpenStack that came out in April "
"2012, the fifth release of OpenStack. It included Compute (nova 2012.1), "
"Object Storage (swift 1.4.8), Image (glance), Identity (keystone), and "
"Dashboard (horizon)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1752(glossterm)
msgid "ESX"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1754(para)
#: ./doc/openstack-ops/glossary-terms.xml1760(para)
#: ./doc/openstack-ops/glossary-terms.xml2674(para)
#: ./doc/openstack-ops/glossary-terms.xml2742(para)
#: ./doc/openstack-ops/glossary-terms.xml4654(para)
#: ./doc/openstack-ops/glossary-terms.xml4769(para)
#: ./doc/openstack-ops/glossary-terms.xml4912(para)
#: ./doc/openstack-ops/glossary-terms.xml4970(para)
#: ./doc/openstack-ops/glossary-terms.xml4984(para)
msgid "An OpenStack-supported hypervisor."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1758(glossterm)
msgid "ESXi"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1766(para)
msgid ""
"Filtering tool for a Linux bridging firewall, enabling filtering of network "
"traffic passing through a Linux bridge. Used to restrict communications "
"between hosts and/or nodes in OpenStack Compute along with iptables, "
"arptables, and ip6tables."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1774(glossterm)
msgid "ETag"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1776(para)
msgid ""
"MD5 hash of an object within Object Storage, used to ensure data integrity."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1781(glossterm)
msgid "euca2ools"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1783(para)
msgid ""
"A collection of command-line tools for administering VMs, most are "
"compatible with OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1789(glossterm)
msgid "Eucalyptus Kernel Image (EKI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1791(para)
msgid "Used along with an ERI to create an EMI."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1795(glossterm)
msgid "Eucalyptus Machine Image (EMI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1797(para)
msgid "VM image container format supported by Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1802(glossterm)
msgid "Eucalyptus Ramdisk Image (ERI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1804(para)
msgid "Used along with an EKI to create an EMI."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1808(glossterm)
msgid "evacuate"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1810(para)
msgid ""
"The process of migrating one or all virtual machine (VM) instances from one "
"host to another, compatible with both shared storage live migration and "
"block migration."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1817(glossterm)
msgid "exchange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1819(para)
msgid "Alternative term for a RabbitMQ message exchange."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1824(glossterm)
msgid "exchange type"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1826(para)
msgid "A routing algorithm in the Compute RabbitMQ."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1830(glossterm)
msgid "exclusive queue"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1832(para)
msgid ""
"Connected to by a direct consumer in RabbitMQ—Compute, the message can be "
"consumed only by the current connection."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1840(glossterm)
msgid "extended attributes (xattrs)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1842(para)
msgid ""
"File system option that enables storage of additional information beyond "
"owner, group, permissions, modification time, and so on. The underlying "
"Object Storage file system must support extended attributes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1850(glossterm)
msgid "extension"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1852(para)
msgid ""
"Alternative term for an API extension or plug-in. In the context of Identity"
" Service, this is a call that is specific to the implementation, such as "
"adding support for OpenID."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1861(glossterm)
msgid "extra specs"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1863(para)
msgid ""
"Specifies additional requirements when Compute determines where to start a "
"new instance. Examples include a minimum amount of network bandwidth or a "
"GPU."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1872(title)
msgid "F"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1874(glossterm)
msgid "FakeLDAP"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1876(para)
msgid ""
"An easy method to create a local LDAP directory for testing Identity Service"
" and Compute. Requires Redis."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1882(glossterm)
msgid "fan-out exchange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1884(para)
msgid ""
"Within RabbitMQ and Compute it is the messaging interface that is used by "
"the scheduler service to receive capability messages from the compute, "
"volume, and network nodes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1891(glossterm)
msgid "Fedora"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1893(para)
msgid "A Linux distribution compatible with OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1898(glossterm)
msgid "Fibre Channel"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1900(para)
msgid ""
"Storage protocol similar in concept to TCP/IP, encapsulates SCSI commands "
"and data."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1905(glossterm)
msgid "Fibre Channel over Ethernet (FCoE)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1907(para)
msgid "The fibre channel protocol tunneled within Ethernet."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1912(glossterm)
msgid "fill-first scheduler"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1914(para)
msgid ""
"The Compute scheduling method that attempts to fill a host with VMs rather "
"than starting new VMs on a variety of hosts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1920(glossterm)
msgid "filter"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1922(para)
msgid ""
"The step in the Compute scheduling process when hosts that cannot run VMs "
"are eliminated and not chosen."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1928(glossterm)
msgid "firewall"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1930(para)
msgid ""
"Used to restrict communications between hosts and/or nodes, implemented in "
"Compute using iptables, arptables, ip6tables, and etables."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1936(glossterm)
msgid "Firewall-as-a-Service (FWaaS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1938(para)
msgid "A Networking extension that provides perimeter firewall functionality."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1945(glossterm)
msgid "fixed IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1947(para)
msgid ""
"An IP address that is associated with the same instance each time that "
"instance boots, is generally not accessible to end users or the public "
"Internet, and used for management of the instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1955(glossterm)
msgid "Flat Manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1957(para)
msgid ""
"The Compute component that gives IP addresses to authorized nodes and "
"assumes DHCP, DNS, and routing configuration and services are provided by "
"something else."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1964(glossterm)
msgid "flat mode injection"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1966(para)
msgid ""
"A Compute networking method where the OS network configuration information "
"is injected into the VM image before the instance starts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1972(glossterm)
msgid "flat network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1974(para)
msgid ""
"The Network Controller provides virtual networks to enable compute servers "
"to interact with each other and with the public network. All machines must "
"have a public and private network interface. A flat network is a private "
"network interface, which is controlled by the flat_interface option with "
"flat managers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1984(glossterm)
msgid "FlatDHCP Manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1986(para)
msgid ""
"The Compute component that provides dnsmasq (DHCP, DNS, BOOTP, TFTP) and "
"radvd (routing) services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1992(glossterm)
msgid "flavor"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1994(para)
msgid "Alternative term for a VM instance type."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml1998(glossterm)
msgid "flavor ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2000(para)
msgid "UUID for each Compute or Image Service VM flavor or instance type."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2005(glossterm)
msgid "floating IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2007(para)
msgid ""
"An IP address that a project can associate with a VM so that the instance "
"has the same public IP address each time that it boots. You create a pool of"
" floating IP addresses and assign them to instances as they are launched to "
"maintain a consistent IP address for maintaining DNS assignment."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2019(para)
msgid ""
"A grouped release of projects related to OpenStack that came out in the fall"
" of 2012, the sixth release of OpenStack. It includes Compute (nova), Object"
" Storage (swift), Identity (keystone), Networking (neutron), Image Service "
"(glance), and Volumes or Block Storage (cinder)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2029(glossterm)
msgid "FormPost"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2031(para)
msgid ""
"Object Storage middleware that uploads (posts) an image through a form on a "
"web page."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2037(glossterm)
msgid "frontend"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2039(para)
msgid ""
"The point where a user interacts with a service; can be an API endpoint, the"
" horizon dashboard, or a command-line tool."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2047(title)
msgid "G"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2049(glossterm)
msgid "gateway"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2051(para)
msgid "Hardware or software that translates between two different protocols."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2056(glossterm)
msgid "glance"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2058(para)
msgid "A core project that provides the OpenStack Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2063(glossterm)
msgid "glance API server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2065(para)
msgid ""
"Processes client requests for VMs, updates Image Service metadata on the "
"registry server, and communicates with the store adapter to upload VM images"
" from the back-end store."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2072(glossterm)
msgid "glance registry"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2074(para)
msgid "Alternative term for the Image Service image registry."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2079(glossterm)
msgid "global endpoint template"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2081(para)
msgid ""
"The Identity Service endpoint template that contains services available to "
"all tenants."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2088(para)
msgid ""
"A file system designed to aggregate NAS hosts, compatible with OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2093(glossterm)
msgid "golden image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2095(para)
msgid ""
"A method of operating system installation where a finalized disk image is "
"created and then used by all nodes without modification."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2101(glossterm)
msgid "Graphic Interchange Format (GIF)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2103(para)
msgid ""
"A type of image file that is commonly used for animated images on web pages."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2108(glossterm)
msgid "Graphics Processing Unit (GPU)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2110(para)
msgid ""
"Choosing a host based on the existence of a GPU is currently unsupported in "
"OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2115(glossterm)
msgid "Green Threads"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2117(para)
msgid ""
"The cooperative threading model used by Python; reduces race conditions and "
"only context switches when specific library calls are made. Each OpenStack "
"service is its own thread."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2126(para)
msgid "Project name for the seventh release of OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2131(glossterm)
msgid "guest OS"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2133(para)
msgid ""
"An operating system instance running under the control of a hypervisor."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2140(title)
msgid "H"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2142(glossterm)
msgid "Hadoop"
msgstr "Hadoop"

#: ./doc/openstack-ops/glossary-terms.xml2144(para)
msgid ""
"Apache Hadoop is an open-source software framework that supports data-"
"intensive distributed applications."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2150(glossterm)
msgid "handover"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2152(para)
msgid ""
"An object state in Object Storage where a new replica of the object is "
"automatically created due to a drive failure."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2158(glossterm)
msgid "hard reboot"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2160(para)
msgid ""
"A type of reboot where a physical or virtual power button is pressed as "
"opposed to a graceful, proper shutdown of the operating system."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2168(para)
msgid "Project name for the eighth release of OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2173(glossterm)
msgid "heat"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2175(para)
msgid ""
"An integrated project that aims to orchestrate multiple cloud applications "
"for OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2182(para)
msgid "OpenStack project that provides a dashboard, which is a web interface."
msgstr "OpenStack projekt, amely egy webes vezérlőpult felületet biztosít."

#: ./doc/openstack-ops/glossary-terms.xml2187(glossterm)
msgid "horizon plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2189(para)
msgid "A plug-in for the OpenStack dashboard (horizon)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2194(glossterm)
msgid "host"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2196(para)
msgid "A physical computer, not a VM instance (node)."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2201(glossterm)
msgid "host aggregate"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2203(para)
msgid ""
"A method to further subdivide availability zones into hypervisor pools, a "
"collection of common hosts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2209(glossterm)
msgid "Host Bus Adapter (HBA)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2211(para)
msgid ""
"Device plugged into a PCI slot such as a fibre channel or network card."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2216(glossterm)
msgid "HTTP"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2218(para)
msgid ""
"Hypertext Transfer Protocol. HTTP is an application protocol for "
"distributed, collaborative, hypermedia information systems. It is the "
"foundation of data communication for the World Wide Web. Hypertext is "
"structured text that uses logical links (hyper links) between nodes "
"containing text. HTTP is the protocol to exchange or transfer hypertext."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2229(glossterm)
msgid "HTTPS"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2231(para)
msgid ""
"Hypertext Transfer Protocol Secure (HTTPS) is a communications protocol for "
"secure communication over a computer network, with especially wide "
"deployment on the Internet. Technically, it is not a protocol in and of "
"itself; rather, it is the result of simply layering the Hypertext Transfer "
"Protocol (HTTP) on top of the SSL/TLS protocol, thus adding the security "
"capabilities of SSL/TLS to standard HTTP communications."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2244(glossterm)
msgid "Hyper-V"
msgstr "Hyper-V"

#: ./doc/openstack-ops/glossary-terms.xml2246(para)
msgid "One of the hypervisors supported by OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2251(glossterm)
msgid "hyper link"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2253(para)
msgid ""
"Any kind of text that contains a link to some other site, commonly found in "
"documents where clicking on a word or words opens up a different web site."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2260(glossterm)
msgid "Hypertext Transfer Protocol (HTTP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2262(para)
msgid "The protocol that tells browsers where to go to find information."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2267(glossterm)
msgid "Hypertext Transfer Protocol Secure (HTTPS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2270(para)
msgid ""
"Encrypted HTTP communications using SSL or TLS; most OpenStack API endpoints"
" and many inter-component communications support HTTPS communication."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2277(glossterm)
msgid "hypervisor"
msgstr "hypervisor"

#: ./doc/openstack-ops/glossary-terms.xml2279(para)
msgid ""
"Software that arbitrates and controls VM access to the actual underlying "
"hardware."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2284(glossterm)
msgid "hypervisor pool"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2286(para)
msgid "A collection of hypervisors grouped together through host aggregates."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2293(title)
msgid "I"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2295(glossterm)
msgid "IaaS"
msgstr "IaaS"

#: ./doc/openstack-ops/glossary-terms.xml2297(para)
msgid ""
"Infrastructure-as-a-Service. IaaS is a provisioning model in which an "
"organization outsources physical components of a data center such as "
"storage, hardware, servers and networking components. A service provider "
"owns the equipment and is responsible for housing, operating and maintaining"
" it. The client typically pays on a per-use basis. IaaS is a model for "
"providing cloud services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2312(para)
msgid "Project name for the ninth release of OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2316(glossterm)
msgid "ID number"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2318(para)
msgid ""
"Unique numeric ID associated with each user in Identity Service, "
"conceptually similar to a Linux or LDAP UID."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2324(glossterm)
msgid "Identity API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2326(para)
msgid "Alternative term for the Identity Service API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2331(glossterm)
msgid "Identity back end"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2333(para)
msgid ""
"The source used by Identity Service to retrieve user information; an "
"OpenLDAP server for example."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2338(glossterm)
msgid "Identity Service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2340(para)
msgid ""
"The OpenStack core project that provides a central directory of users mapped"
" to the OpenStack services they can access. It also registers endpoints for "
"OpenStack services. It acts as a common authentication system. The project "
"name of the Identity Service is keystone."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2349(glossterm)
msgid "Identity Service API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2351(para)
msgid ""
"The API used to access the OpenStack Identity Service provided through "
"keystone."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2356(glossterm)
msgid "IDS"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2358(para)
msgid "Intrusion Detection System"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2363(glossterm)
msgid "image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2365(para)
msgid ""
"A collection of files for a specific operating system (OS) that you use to "
"create or rebuild a server. OpenStack provides pre-built images. You can "
"also create custom images, or snapshots, from servers that you have "
"launched. Custom images can be used for data backups or as \"gold\" images "
"for additional servers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2375(glossterm)
msgid "Image API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2377(para)
msgid "The Image Service API endpoint for management of VM images."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2382(glossterm)
msgid "image cache"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2384(para)
msgid ""
"Used by Image Service to obtain images on the local host rather than re-"
"downloading them from the image server each time one is requested."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2391(glossterm)
msgid "image ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2393(para)
msgid ""
"Combination of a URI and UUID used to access Image Service VM images through"
" the image API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2398(glossterm)
msgid "image membership"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2400(para)
#: ./doc/openstack-ops/glossary-terms.xml2842(para)
msgid ""
"A list of tenants that can access a given VM image within Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2405(glossterm)
msgid "image owner"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2407(para)
msgid "The tenant who owns an Image Service virtual machine image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2412(glossterm)
msgid "image registry"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2414(para)
msgid "A list of VM images that are available through Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2419(glossterm)
msgid "Image Service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2421(para)
msgid ""
"An OpenStack core project that provides discovery, registration, and "
"delivery services for disk and server images. The project name of the Image "
"Service is glance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2428(glossterm)
msgid "Image Service API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2430(para)
msgid "Alternative name for the glance image API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2435(glossterm)
msgid "image status"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2437(para)
msgid ""
"The current status of a VM image in Image Service, not to be confused with "
"the status of a running instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2443(glossterm)
msgid "image store"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2445(para)
msgid ""
"The back-end store used by Image Service to store VM images, options include"
" Object Storage, local file system, S3, or HTTP."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2451(glossterm)
msgid "image UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2453(para)
msgid "UUID used by Image Service to uniquely identify each VM image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2458(glossterm)
msgid "incubated project"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2460(para)
msgid ""
"A community project may be elevated to this status and is then promoted to a"
" core project."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2466(glossterm)
msgid "ingress filtering"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2468(para)
msgid ""
"The process of filtering incoming network traffic. Supported by Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2473(glossterm)
msgid "injection"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2475(para)
msgid ""
"The process of putting a file into a virtual machine image before the "
"instance is started."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2481(glossterm)
msgid "instance"
msgstr "példány"

#: ./doc/openstack-ops/glossary-terms.xml2483(para)
msgid ""
"A running VM, or a VM in a known state such as suspended, that can be used "
"like a hardware server."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2489(glossterm)
msgid "instance ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2491(para)
msgid "Alternative term for instance UUID."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2495(glossterm)
msgid "instance state"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2497(para)
msgid "The current state of a guest VM image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2501(glossterm)
msgid "instance type"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2503(para)
msgid ""
"Describes the parameters of the various virtual machine images that are "
"available to users, includes parameters such as CPU, storage, and memory. "
"Alternative term for flavor."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2510(glossterm)
msgid "instance type ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2512(para)
msgid "Alternative term for a flavor ID."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2516(glossterm)
msgid "instance UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2518(para)
#: ./doc/openstack-ops/glossary-terms.xml4088(para)
msgid "Unique ID assigned to each guest VM instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2523(glossterm)
msgid "interface ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2525(para)
msgid "Unique ID for a Networking VIF or vNIC in the form of a UUID."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2530(glossterm)
msgid "Internet Service Provider (ISP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2532(para)
msgid ""
"Any business that provides Internet access to individuals or businesses."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2537(glossterm)
msgid "ironic"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2539(para)
msgid ""
"OpenStack project that provisions bare metal, as opposed to virtual, "
"machines."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2544(glossterm)
msgid "IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2546(para)
msgid ""
"Number that is unique to every computer system on the Internet. Two versions"
" of the Internet Protocol (IP) are in use for addresses: IPv4 and IPv6."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2553(glossterm)
msgid "IP Address Management (IPAM)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2555(para)
msgid ""
"The process of automating IP address allocation, deallocation, and "
"management. Currently provided by Compute, melange, and Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2561(glossterm)
msgid "IPL"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2563(para)
msgid "Initial Program Loader."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2567(glossterm)
msgid "IPMI"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2569(para)
msgid ""
"Intelligent Platform Management Interface. IPMI is a standardized computer "
"system interface used by system administrators for out-of-band management of"
" computer systems and monitoring of their operation. In layman's terms, it "
"is a way to manage a computer using a direct network connection, whether it "
"is turned on or not; connecting to the hardware rather than an operating "
"system or login shell."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2581(glossterm)
msgid "ip6tables"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2583(para)
msgid ""
"Tool used to set up, maintain, and inspect the tables of IPv6 packet filter "
"rules in the Linux kernel. In OpenStack Compute, ip6tables is used along "
"with arptables, ebtables, and iptables to create firewalls for both nodes "
"and VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2591(glossterm)
#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml580(title)
msgid "iptables"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2593(para)
msgid ""
"Used along with arptables and ebtables, iptables create firewalls in "
"Compute. iptables are the tables provided by the Linux kernel firewall "
"(implemented as different Netfilter modules) and the chains and rules it "
"stores. Different kernel modules and programs are currently used for "
"different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables "
"to ARP, and ebtables to Ethernet frames. Requires root privilege to "
"manipulate."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2606(glossterm)
msgid "iSCSI"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2608(para)
msgid ""
"The SCSI disk protocol tunneled within Ethernet, supported by Compute, "
"Object Storage, and Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2614(glossterm)
msgid "ISO9960"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2616(para)
#: ./doc/openstack-ops/glossary-terms.xml3607(para)
#: ./doc/openstack-ops/glossary-terms.xml4678(para)
#: ./doc/openstack-ops/glossary-terms.xml4685(para)
#: ./doc/openstack-ops/glossary-terms.xml4795(para)
msgid "One of the VM image disk formats supported by Image Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2621(glossterm)
msgid "itsec"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2623(para)
msgid ""
"A default role in the Compute RBAC system that can quarantine an instance in"
" any project."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2631(title)
msgid "J"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2633(glossterm)
msgid "Java"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2635(para)
msgid ""
"A programming language that is used to create systems that involve more than"
" one computer by way of a network."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2641(glossterm)
msgid "JavaScript"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2643(para)
msgid "A scripting language that is used to build web pages."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2648(glossterm)
msgid "JavaScript Object Notation (JSON)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2650(para)
msgid "One of the supported response formats in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2655(glossterm)
msgid "Jenkins"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2657(para)
msgid "Tool used to run jobs automatically for OpenStack development."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2662(glossterm)
msgid "Juno"
msgstr "Juno"

#: ./doc/openstack-ops/glossary-terms.xml2664(para)
msgid "Project name for the tenth release of OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2670(title)
msgid "K"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2672(glossterm)
msgid "kernel-based VM (KVM)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2678(glossterm)
msgid "keystone"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2680(para)
msgid "The project that provides OpenStack Identity services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2685(glossterm)
msgid "Kickstart"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2687(para)
msgid ""
"A tool to automate system configuration and installation on Red Hat, Fedora,"
" and CentOS based Linux distributions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2695(title)
msgid "L"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2697(glossterm)
msgid "large object"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2699(para)
msgid "An object within Object Storage that is larger than 5 GBs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2704(glossterm)
msgid "Launchpad"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2706(para)
msgid "The collaboration site for OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2710(glossterm)
msgid "Layer-2 network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2712(para)
msgid "Term used for OSI network architecture for the data link layer."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2719(para)
msgid ""
"Virtualization API library used by OpenStack to interact with many of its "
"supported hypervisors."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2725(glossterm)
msgid "Linux bridge"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2727(para)
msgid ""
"Software that enables multiple VMs to share a single physical NIC within "
"Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2732(glossterm)
msgid "Linux Bridge neutron plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2734(para)
msgid ""
"Enables a Linux bridge to understand a Networking port, interface "
"attachment, and other abstractions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2740(glossterm)
msgid "Linux containers (LXC)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2746(glossterm)
msgid "live migration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2748(para)
msgid ""
"The ability within Compute to move running virtual machine instances from "
"one host to another with only a small service interruption during switch-"
"over."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2755(glossterm)
msgid "load balancer"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2757(para)
msgid ""
"A load balancer is a logical device that belongs to a cloud account. It is "
"used to distribute workloads between multiple back-end systems or services, "
"based on the criteria defined as part of its configuration."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2765(glossterm)
msgid "load balancing"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2767(para)
msgid ""
"The process of spreading client requests between two or more nodes to "
"improve performance and availability."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2773(glossterm)
msgid "Load-Balancing-as-a-Service (LBaaS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2775(para)
msgid ""
"Enables Networking to distribute incoming requests evenly between designated"
" instances."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2782(title)
msgid "M"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2784(glossterm)
msgid "management API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2786(para)
msgid "Alternative term for an admin API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2790(glossterm)
msgid "management network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2792(para)
msgid ""
"A network segment used for administration, not accessible to the public "
"Internet."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2797(glossterm)
msgid "manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2799(para)
msgid ""
"Logical groupings of related code such as the Block Storage volume manager "
"or network manager."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2804(glossterm)
msgid "manifest"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2806(para)
msgid "Used to track segments of a large object within Object Storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2811(glossterm)
msgid "manifest object"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2813(para)
msgid ""
"A special Object Storage object that contains the manifest for a large "
"object."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2818(glossterm)
msgid "marconi"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2820(para)
msgid "OpenStack project that provides a queue service to applications."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2825(glossterm)
msgid "melange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2827(para)
msgid ""
"Project name for OpenStack Network Information Service. To be merged with "
"Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2832(glossterm)
msgid "membership"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2834(para)
msgid ""
"The association between an Image Service VM image and a tenant. Enables "
"images to be shared with specified tenants."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2840(glossterm)
msgid "membership list"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2847(glossterm)
msgid "memcached"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2849(para)
msgid ""
"A distributed memory object caching system that is used by Object Storage "
"for caching."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2854(glossterm)
msgid "memory overcommit"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2856(para)
msgid ""
"The ability to start new VM instances based on the actual memory usage of a "
"host, as opposed to basing the decision on the amount of RAM each running "
"instance thinks it has available. Also known as RAM overcommit."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2864(glossterm)
msgid "message broker"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2866(para)
msgid ""
"The software package used to provide AMQP messaging capabilities within "
"Compute. Default package is RabbitMQ."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2872(glossterm)
msgid "message bus"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2874(para)
msgid ""
"The main virtual communication line used by all AMQP messages for inter-"
"cloud communications within Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2880(glossterm)
msgid "message queue"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2882(para)
msgid ""
"Passes requests from clients to the appropriate workers and returns the "
"output to the client after the job completes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2888(glossterm)
msgid "Meta-Data Server (MDS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2890(para)
msgid "Stores CephFS metadata."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2894(glossterm)
msgid "migration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2896(para)
msgid "The process of moving a VM instance from one host to another."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2901(glossterm)
msgid "multinic"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2903(para)
msgid ""
"Facility in Compute that allows each virtual machine instance to have more "
"than one VIF connected to it."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2909(glossterm)
msgid "Modular Layer 2 (ML2) neutron plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2911(para)
msgid ""
"Can concurrently use multiple layer-2 networking technologies, such as "
"802.1Q and VXLAN, in Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2917(glossterm)
msgid "Monitor (LBaaS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2919(para)
msgid ""
"LBaaS feature that provides availability monitoring using the "
"<placeholder-1/> command, TCP, and HTTP/HTTPS GET."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2925(glossterm)
msgid "Monitor (Mon)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2927(para)
msgid ""
"A Ceph component that communicates with external clients, checks data state "
"and consistency, and performs quorum functions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2933(glossterm)
msgid "multi-factor authentication"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2935(para)
msgid ""
"Authentication method that uses two or more credentials, such as a password "
"and a private key. Currently not supported in Identity Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2941(glossterm)
msgid "MultiNic"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2943(para)
msgid ""
"Facility in Compute that enables a virtual machine instance to have more "
"than one VIF connected to it."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2951(title)
msgid "N"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2953(glossterm)
msgid "Nebula"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2955(para)
msgid "Released as open source by NASA in 2010 and is the basis for Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2960(glossterm)
msgid "netadmin"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2962(para)
msgid ""
"One of the default roles in the Compute RBAC system. Enables the user to "
"allocate publicly accessible IP addresses to instances and change firewall "
"rules."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2969(glossterm)
msgid "NetApp volume driver"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2971(para)
msgid ""
"Enables Compute to communicate with NetApp storage devices through the "
"NetApp OnCommand Provisioning Manager."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2977(glossterm)
msgid "network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2979(para)
msgid ""
"A virtual network that provides connectivity between entities. For example, "
"a collection of virtual ports that share network connectivity. In Networking"
" terminology, a network is always a Layer-2 network."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2987(glossterm)
msgid "Network Address Translation (NAT)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2989(para)
msgid ""
"The process of modifying IP address information while in-transit. Supported "
"by Compute and Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2995(glossterm)
msgid "network controller"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml2997(para)
msgid ""
"A Compute daemon that orchestrates the network configuration of nodes, "
"including IP addresses, VLANs, and bridging. Also manages routing for both "
"public and private networks."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3006(glossterm)
msgid "Network File System (NFS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3008(para)
msgid ""
"A method for making file systems available over the network. Supported by "
"OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3013(glossterm)
msgid "network ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3015(para)
msgid ""
"Unique ID assigned to each network segment within Networking. Same as "
"network UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3020(glossterm)
msgid "network manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3022(para)
msgid ""
"The Compute component that manages various network components, such as "
"firewall rules, IP address allocation, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3028(glossterm)
msgid "network node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3030(para)
msgid "Any compute node that runs the network worker daemon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3035(glossterm)
msgid "network segment"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3037(para)
msgid "Represents a virtual, isolated OSI layer-2 subnet in Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3042(glossterm)
msgid "Network Time Protocol (NTP)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3044(para)
msgid ""
"A method of keeping a clock for a host or node correct through "
"communications with a trusted, accurate time source."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3050(glossterm)
msgid "network UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3052(para)
msgid "Unique ID for a Networking network segment."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3056(glossterm)
msgid "network worker"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3058(para)
msgid ""
"The nova-network worker daemon, provides services such as giving an IP "
"address to a booting nova instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3066(para)
msgid ""
"A core OpenStack project that provides a network connectivity abstraction "
"layer to OpenStack Compute. The project name of Networking is neutron."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3073(glossterm)
msgid "Networking API"
msgstr "Hálózatkezelés API"

#: ./doc/openstack-ops/glossary-terms.xml3075(para)
msgid ""
"API used to access OpenStack Networking. Provides an extensible architecture"
" to enable custom plug-in creation."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3081(glossterm)
msgid "neutron"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3083(para)
msgid ""
"A core OpenStack project that provides a network connectivity abstraction "
"layer to OpenStack Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3089(glossterm)
msgid "neutron API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3091(para)
msgid "An alternative name for Networking API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3095(glossterm)
msgid "neutron manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3097(para)
msgid ""
"Enables Compute and Networking integration, which enables Networking to "
"perform network management for guest VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3103(glossterm)
msgid "neutron plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3105(para)
msgid ""
"Interface within Networking that enables organizations to create custom "
"plug-ins for advanced features such as QoS, ACLs, or IDS."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3112(glossterm)
msgid "Nexenta volume driver"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3114(para)
msgid "Provides support for NexentaStor devices in Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3119(glossterm)
msgid "No ACK"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3121(para)
msgid ""
"Disables server-side message acknowledgment in the Compute RabbitMQ. "
"Increases performance but decreases reliability."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3127(glossterm)
msgid "node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3129(para)
msgid "A VM instance that runs on a host."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3133(glossterm)
msgid "non-durable exchange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3135(para)
msgid ""
"Message exchange that is cleared when the service restarts. Its data is not "
"written to persistent storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3141(glossterm)
msgid "non-durable queue"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3143(para)
msgid ""
"Message queue that is cleared when the service restarts. Its data is not "
"written to persistent storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3149(glossterm)
msgid "non-persistent volume"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3151(para)
msgid "Alternative term for an ephemeral volume."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3155(glossterm)
msgid "nova"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3157(para)
msgid "OpenStack project that provides compute services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3162(glossterm)
msgid "Nova API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3164(para)
msgid "Alternative term for the Compute API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3171(para)
msgid ""
"A Compute component that manages IP address allocation, firewalls, and other"
" network-related tasks. This is the legacy networking option and an "
"alternative to Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3181(title)
msgid "O"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3183(glossterm)
msgid "object"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3185(para)
msgid "A BLOB of data held by Object Storage; can be in any format."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3190(glossterm)
msgid "object auditor"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3192(para)
msgid ""
"Opens all objects for an object server and verifies the MD5 hash, size, and "
"metadata for each object."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3198(glossterm)
msgid "object expiration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3200(para)
msgid ""
"A configurable option within Object Storage to automatically delete objects "
"after a specified amount of time has passed or a certain date is reached."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3207(glossterm)
msgid "object hash"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3209(para)
msgid "Uniquely ID for an Object Storage object."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3213(glossterm)
msgid "object path hash"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3215(para)
msgid ""
"Used by Object Storage to determine the location of an object in the ring. "
"Maps objects to partitions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3221(glossterm)
msgid "object replicator"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3223(para)
msgid ""
"An Object Storage component that copies and object to remote partitions for "
"fault tolerance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3228(glossterm)
msgid "object server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3230(para)
msgid "An Object Storage component that is responsible for managing objects."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3237(para)
msgid ""
"The OpenStack core project that provides eventually consistent and redundant"
" storage and retrieval of fixed digital content. The project name of "
"OpenStack Object Storage is swift."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3246(glossterm)
msgid "Object Storage API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3248(para)
msgid "API used to access OpenStack Object Storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3252(glossterm)
msgid "Object Storage Device (OSD)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3254(para)
msgid "The Ceph storage daemon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3258(glossterm)
msgid "object versioning"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3260(para)
msgid ""
"Allows a user to set a flag on an Object Storage container so that all "
"objects within the container are versioned."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3267(glossterm)
msgid "Oldie"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3269(para)
msgid ""
"Term for an Object Storage process that runs for a long time. Can indicate a"
" hung process."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3275(glossterm)
msgid "Open Cloud Computing Interface (OCCI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3278(para)
msgid ""
"A standardized interface for managing compute, data, and network resources, "
"currently unsupported in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3284(glossterm)
msgid "Open Virtualization Format (OVF)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3286(para)
msgid "Standard for packaging VM images. Supported in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3291(glossterm)
msgid "Open vSwitch neutron plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3293(para)
msgid "Provides support for Open vSwitch in Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3298(glossterm)
msgid "OpenLDAP"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3300(para)
msgid ""
"An open source LDAP server. Supported by both Compute and Identity Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3307(para)
msgid ""
"OpenStack is a cloud operating system that controls large pools of compute, "
"storage, and networking resources throughout a data center, all managed "
"through a dashboard that gives administrators control while empowering their"
" users to provision resources through a web interface. OpenStack is an open "
"source project licensed under the Apache License 2.0."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3319(glossterm)
msgid "openSUSE"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3326(glossterm)
msgid "operator"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3328(para)
msgid ""
"The person responsible for planning and maintaining an OpenStack "
"installation."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3333(glossterm)
msgid "Orchestration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3335(para)
msgid ""
"An integrated project that orchestrates multiple cloud applications for "
"OpenStack. The project name of Orchestration is heat."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3342(glossterm)
msgid "orphan"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3344(para)
msgid ""
"In the context of Object Storage, this is a process that is not terminated "
"after an upgrade, restart, or reload of the service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3354(title)
msgid "P"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3356(glossterm)
msgid "parent cell"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3358(para)
msgid ""
"If a requested resource, such as CPU time, disk storage, or memory, is not "
"available in the parent cell, the request is forwarded to associated child "
"cells."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3365(glossterm)
msgid "partition"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3367(para)
msgid ""
"A unit of storage within Object Storage used to store objects. It exists on "
"top of devices and is, replicated for fault tolerance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3375(glossterm)
msgid "partition index"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3377(para)
msgid ""
"Contains the locations of all Object Storage partitions within the ring."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3382(glossterm)
msgid "partition shift value"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3384(para)
msgid ""
"Used by Object Storage to determine which partition data should reside on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3389(glossterm)
msgid "pause"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3391(para)
msgid ""
"A VM state where no changes occur (no changes in memory, network "
"communications stop, etc); the VM is frozen but not shut down."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3397(glossterm)
msgid "PCI passthrough"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3399(para)
msgid ""
"Gives guest VMs exclusive access to a PCI device. Currently supported in "
"OpenStack Havana and later releases."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3405(glossterm)
msgid "persistent message"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3407(para)
msgid ""
"A message that is stored both in memory and on disk. The message is not lost"
" after a failure or restart."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3413(glossterm)
msgid "persistent volume"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3415(para)
msgid "Changes to these types of disk volumes are saved."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3420(glossterm)
msgid "personality file"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3422(para)
msgid ""
"A file used to customize a Compute instance. It can be used to inject SSH "
"keys or a specific network configuration."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3430(glossterm)
msgid "Platform-as-a-Service (PaaS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3432(para)
msgid ""
"Provides to the consumer the ability to deploy applications through a "
"programming language or tools supported by the cloud platform provider. An "
"example of Platform-as-a-Service is an Eclipse/Java programming platform "
"provided with no downloads required."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3443(glossterm)
msgid "plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3445(para)
msgid ""
"Software component providing the actual implementation for Networking APIs, "
"or for Compute APIs, depending on the context."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3451(glossterm)
msgid "policy service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3453(para)
msgid ""
"Component of Identity Service that provides a rule-management interface and "
"a rule-based authorization engine."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3461(glossterm)
msgid "port"
msgstr "port"

#: ./doc/openstack-ops/glossary-terms.xml3463(para)
msgid ""
"A virtual network port within Networking; VIFs / vNICs are connected to a "
"port."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3468(glossterm)
msgid "port UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3470(para)
msgid "Unique ID for a Networking port."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3474(glossterm)
msgid "preseed"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3476(para)
msgid ""
"A tool to automate system configuration and installation on Debian-based "
"Linux distributions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3482(glossterm)
msgid "private image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3484(para)
msgid "An Image Service VM image that is only available to specified tenants."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3489(glossterm)
msgid "private IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3491(para)
msgid ""
"An IP address used for management and administration, not available to the "
"public Internet."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3497(glossterm)
msgid "private network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3499(para)
msgid ""
"The Network Controller provides virtual networks to enable compute servers "
"to interact with each other and with the public network. All machines must "
"have a public and private network interface. A private network interface can"
" be a flat or VLAN network interface. A flat network interface is controlled"
" by the flat_interface with flat managers. A VLAN network interface is "
"controlled by the vlan_interface option with VLAN managers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3512(glossterm)
msgid "project"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3514(para)
msgid ""
"A logical grouping of users within Compute, used to define quotas and access"
" to VM images."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3519(glossterm)
msgid "project ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3521(para)
msgid "User-defined alpha-numeric string in Compute; the name of a project."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3526(glossterm)
msgid "project VPN"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3528(para)
msgid "Alternative term for a cloudpipe."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3532(glossterm)
msgid "provider"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3534(para)
msgid "An administrator who has access to all hosts and instances."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3539(glossterm)
msgid "proxy node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3541(para)
msgid "A node that provides the Object Storage proxy service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3546(glossterm)
msgid "proxy server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3548(para)
msgid ""
"Users of Object Storage interact with the service through the proxy server, "
"which in-turn looks up the location of the requested data within the ring "
"and returns the results to the user."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3555(glossterm)
msgid "public API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3557(para)
msgid ""
"An API endpoint used for both service-to-service communication and end-user "
"interactions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3562(glossterm)
msgid "public image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3564(para)
msgid "An Image Service VM image that is available to all tenants."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3569(glossterm)
msgid "public IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3571(para)
msgid "An IP address that is accessible to end-users."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3576(glossterm)
msgid "public network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3578(para)
msgid ""
"The Network Controller provides virtual networks to enable compute servers "
"to interact with each other and with the public network. All machines must "
"have a public and private network interface. The public network interface is"
" controlled by the public_interface option."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3587(glossterm)
msgid "Puppet"
msgstr "Puppet"

#: ./doc/openstack-ops/glossary-terms.xml3589(para)
msgid ""
"An operating system configuration-management tool supported by OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3596(para)
msgid "Programming language used extensively in OpenStack."
msgstr "OpenStack által használt programozási nyelv."

#: ./doc/openstack-ops/glossary-terms.xml3603(title)
msgid "Q"
msgstr "Q"

#: ./doc/openstack-ops/glossary-terms.xml3605(glossterm)
msgid "QEMU Copy On Write 2 (QCOW2)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3614(para)
msgid ""
"Message queue software supported by OpenStack; an alternative to RabbitMQ."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3619(glossterm)
msgid "quarantine"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3621(para)
msgid ""
"If Object Storage finds objects, containers, or accounts that are corrupt, "
"they are placed in this state, are not replicated, cannot be read by "
"clients, and a correct copy is re-replicated."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3628(glossterm)
msgid "Quick EMUlator (QEMU)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3630(para)
msgid "QEMU is a generic and open source machine emulator and virtualizer."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3632(para)
msgid ""
"One of the hypervisors supported by OpenStack, generally used for "
"development purposes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3637(glossterm)
msgid "quota"
msgstr "kvóta"

#: ./doc/openstack-ops/glossary-terms.xml3639(para)
msgid ""
"In Compute and Block Storage, the ability to set resource limits on a per-"
"project basis."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3647(title)
msgid "R"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3649(glossterm)
msgid "RabbitMQ"
msgstr "RabbitMQ"

#: ./doc/openstack-ops/glossary-terms.xml3651(para)
msgid "The default message queue software used by OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3656(glossterm)
msgid "Rackspace Cloud Files"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3658(para)
msgid ""
"Released as open source by Rackspace in 2010, the basis for Object Storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3663(glossterm)
msgid "RADOS Block Device (RBD)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3665(para)
msgid ""
"Ceph component that enables a Linux block device to be striped over multiple"
" distributed data stores."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3671(glossterm)
msgid "radvd"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3673(para)
msgid ""
"The router advertisement daemon, used by the Compute VLAN manager and "
"FlatDHCP manager to provide routing services for VM instances."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3679(glossterm)
msgid "RAM filter"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3681(para)
msgid "The Compute setting that enables or disables RAM overcommitment."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3686(glossterm)
msgid "RAM overcommit"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3688(para)
msgid ""
"The ability to start new VM instances based on the actual memory usage of a "
"host, as opposed to basing the decision on the amount of RAM each running "
"instance thinks it has available. Also known as memory overcommit."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3696(glossterm)
msgid "rate limit"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3698(para)
msgid ""
"Configurable option within Object Storage to limit database writes on a per-"
"account and/or per-container basis."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3704(glossterm)
msgid "raw"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3706(para)
msgid ""
"One of the VM image disk formats supported by Image Service; an unstructured"
" disk image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3711(glossterm)
msgid "rebalance"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3713(para)
msgid ""
"The process of distributing Object Storage partitions across all drives in "
"the ring; used during initial ring creation and after ring reconfiguration."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3720(glossterm)
msgid "reboot"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3722(para)
msgid ""
"Either a soft or hard reboot of a server. With a soft reboot, the operating "
"system is signaled to restart, which enables a graceful shutdown of all "
"processes. A hard reboot is the equivalent of power cycling the server. The "
"virtualization platform should ensure that the reboot action has completed "
"successfully even in cases in which the underlying domain/VM is paused or "
"halted/stopped."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3734(glossterm)
msgid "rebuild"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3736(para)
msgid ""
"Removes all data on the server and replaces it with the specified image. "
"Server ID and IP addresses remain the same."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3742(glossterm)
msgid "Recon"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3744(para)
msgid "An Object Storage component that collects metrics."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3748(glossterm)
msgid "record"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3750(para)
msgid ""
"Belongs to a particular domain and is used to specify information about the "
"domain. There are several types of DNS records. Each record type contains "
"particular information used to describe the purpose of that record. Examples"
" include mail exchange (MX) records, which specify the mail server for a "
"particular domain, and name server (NS) records, which specify the "
"authoritative name servers for a domain."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3762(glossterm)
msgid "record ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3764(para)
msgid ""
"A number within a database that is incremented each time a change is made. "
"Used by Object Storage when replicating."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3770(glossterm)
msgid "Red Hat Enterprise Linux (RHEL)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3777(glossterm)
msgid "reference architecture"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3779(para)
msgid "A recommended architecture for an OpenStack cloud."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3784(glossterm)
msgid "region"
msgstr "régió"

#: ./doc/openstack-ops/glossary-terms.xml3786(para)
msgid ""
"A discrete OpenStack environment with dedicated API endpoints that typically"
" shares only the Identity Service (keystone) with other regions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3792(glossterm)
msgid "registry"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3794(para)
msgid "Alternative term for the Image Service registry."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3799(glossterm)
msgid "registry server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3801(para)
msgid ""
"An Image Service that provides VM image metadata information to clients."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3806(glossterm)
msgid "Reliable, Autonomic Distributed Object Store (RADOS)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3809(para)
msgid ""
"A collection of components that provides object storage within Ceph. Similar"
" to OpenStack Object Storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3815(glossterm)
msgid "Remote Procedure Call (RPC)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3817(para)
msgid ""
"The method used by the Compute RabbitMQ for intra-service communications."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3822(glossterm)
msgid "replica"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3824(para)
msgid ""
"Provides data redundancy and fault tolerance by creating copies of Object "
"Storage objects, accounts, and containers so that they are not lost when the"
" underlying storage fails."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3831(glossterm)
msgid "replica count"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3833(para)
msgid "The number of replicas of the data in an Object Storage ring."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3838(glossterm)
msgid "replication"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3840(para)
msgid ""
"The process of copying data to a separate physical device for fault "
"tolerance and performance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3846(glossterm)
msgid "replicator"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3848(para)
msgid ""
"The Object Storage back-end process that creates and manages object "
"replicas."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3853(glossterm)
msgid "request ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3855(para)
msgid "Unique ID assigned to each request sent to Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3860(glossterm)
msgid "rescue image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3862(para)
msgid ""
"A special type of VM image that is booted when an instance is placed into "
"rescue mode. Allows an administrator to mount the file systems for an "
"instance to correct the problem."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3869(glossterm)
msgid "resize"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3871(para)
msgid ""
"Converts an existing server to a different flavor, which scales the server "
"up or down. The original server is saved to enable rollback if a problem "
"occurs. All resizes must be tested and explicitly confirmed, at which time "
"the original server is removed."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3880(glossterm)
msgid "RESTful"
msgstr "RESTful"

#: ./doc/openstack-ops/glossary-terms.xml3882(para)
msgid ""
"A kind of web service API that uses REST, or Representational State "
"Transfer. REST is the style of architecture for hypermedia systems that is "
"used for the World Wide Web."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3889(glossterm)
msgid "ring"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3891(para)
msgid ""
"An entity that maps Object Storage data to partitions. A separate ring "
"exists for each service, such as account, object, and container."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3897(glossterm)
msgid "ring builder"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3899(para)
msgid ""
"Builds and manages rings within Object Storage, assigns partitions to "
"devices, and pushes the configuration to other storage nodes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3905(glossterm)
msgid "Role Based Access Control (RBAC)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3907(para)
msgid ""
"Provides a predefined list of actions that the user can perform, such as "
"start or stop VMs, reset passwords, and so on. Supported in both Identity "
"Service and Compute and can be configured using the horizon dashboard."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3915(glossterm)
msgid "role"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3917(para)
msgid ""
"A personality that a user assumes that enables them to perform a specific "
"set of operations. A role includes a set of rights and privileges. A user "
"assuming that role inherits those rights and privileges."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3925(glossterm)
msgid "role ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3927(para)
msgid "Alpha-numeric ID assigned to each Identity Service role."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3932(glossterm)
msgid "rootwrap"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3934(para)
msgid ""
"A feature of Compute that allows the unprivileged \"nova\" user to run a "
"specified list of commands as the Linux root user."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3940(glossterm)
msgid "round-robin scheduler"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3942(para)
msgid ""
"Type of Compute scheduler that evenly distributes instances among available "
"hosts."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3947(glossterm)
msgid "routing key"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3949(para)
msgid ""
"The Compute direct exchanges, fanout exchanges, and topic exchanges use this"
" key to determine how to process a message; processing varies depending on "
"exchange type."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3956(glossterm)
msgid "RPC driver"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3958(para)
msgid ""
"Modular system that allows the underlying message queue software of Compute "
"to be changed. For example, from RabbitMQ to ZeroMQ or Qpid."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3965(glossterm)
msgid "rsync"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3967(para)
msgid "Used by Object Storage to push object replicas."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3971(glossterm)
msgid "RXTX cap"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3973(para)
msgid ""
"Absolute limit on the amount of network traffic a Compute VM instance can "
"send and receive."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3978(glossterm)
msgid "RXTX quota"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3980(para)
msgid ""
"Soft limit on the amount of network traffic a Compute VM instance can send "
"and receive."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3985(glossterm)
msgid "Ryu neutron plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3987(para)
msgid ""
"Enables the Ryu network operating system to function as a Networking "
"OpenFlow controller."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3994(title)
msgid "S"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3996(glossterm)
msgid "S3"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml3998(para)
msgid ""
"Object storage service by Amazon; similar in function to Object Storage, it "
"can act as a back-end store for Image Service VM images."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4006(glossterm)
msgid "sahara"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4008(para)
msgid ""
"OpenStack project that provides a scalable data-processing stack and "
"associated management interfaces."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4016(glossterm)
msgid "scheduler manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4018(para)
msgid ""
"A Compute component that determines where VM instances should start. Uses "
"modular design to support a variety of scheduler types."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4024(glossterm)
msgid "scoped token"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4026(para)
msgid ""
"An Identity Service API access token that is associated with a specific "
"tenant."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4031(glossterm)
msgid "scrubber"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4033(para)
msgid ""
"Checks for and deletes unused VMs; the component of Image Service that "
"implements delayed delete."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4038(glossterm)
msgid "secret key"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4040(para)
msgid ""
"String of text known only by the user; used along with an access key to make"
" requests to the Compute API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4046(glossterm)
msgid "secure shell (SSH)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4048(para)
msgid ""
"Open source tool used to access remote hosts through an encrypted "
"communications channel, SSH key injection is supported by Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4054(glossterm)
msgid "security group"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4056(para)
msgid ""
"A set of network traffic filtering rules that are applied to a Compute "
"instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4061(glossterm)
msgid "segmented object"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4063(para)
msgid ""
"An Object Storage large object that has been broken up into pieces. The re-"
"assembled object is called a concatenated object."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4069(glossterm)
msgid "server"
msgstr "szerver"

#: ./doc/openstack-ops/glossary-terms.xml4071(para)
msgid ""
"Computer that provides explicit services to the client software running on "
"that system, often managing a variety of computer operations."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4074(para)
msgid ""
"A server is a VM instance in the Compute system. Flavor and image are "
"requisite elements when creating a server."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4080(glossterm)
msgid "server image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4082(para)
msgid "Alternative term for a VM image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4086(glossterm)
msgid "server UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4093(glossterm)
msgid "service"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4095(para)
msgid ""
"An OpenStack service, such as Compute, Object Storage, or Image Service. "
"Provides one or more endpoints through which users can access resources and "
"perform operations."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4104(glossterm)
msgid "service catalog"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4106(para)
msgid "Alternative term for the Identity Service catalog."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4111(glossterm)
msgid "service ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4113(para)
msgid ""
"Unique ID assigned to each service that is available in the Identity Service"
" catalog."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4118(glossterm)
msgid "service registration"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4120(para)
msgid ""
"An Identity Service feature that enables services, such as Compute, to "
"automatically register with the catalog."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4127(glossterm)
msgid "service tenant"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4129(para)
msgid ""
"Special tenant that contains all services that are listed in the catalog."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4134(glossterm)
msgid "service token"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4136(para)
msgid ""
"An administrator defined token used by Compute to communicate securely with "
"the Identity Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4141(glossterm)
msgid "session back-end"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4143(para)
msgid ""
"The method of storage used by horizon to track client sessions such as local"
" memory, cookies, a database, or memcached."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4149(glossterm)
msgid "session persistence"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4151(para)
msgid ""
"A feature of the load-balancing service. It attempts to force subsequent "
"connections to a service to be redirected to the same node as long as it is "
"online."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4158(glossterm)
msgid "session storage"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4160(para)
msgid ""
"A horizon component that stores and tracks client session information. "
"Implemented through the Django sessions framework."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4166(glossterm)
msgid "shared IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4168(para)
msgid ""
"An IP address that can be assigned to a VM instance within the shared IP "
"group. Public IP addresses can be shared across multiple servers for use in "
"various high availability scenarios. When an IP address is shared to another"
" server, the cloud network restrictions are modified to enable each server "
"to listen to and respond on that IP address. You can optionally specify that"
" the target server network configuration be modified. Shared IP addresses "
"can be used with many standard heartbeat facilities, such as keepalive, that"
" monitor for failure and manage IP failover."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4184(glossterm)
msgid "shared IP group"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4186(para)
msgid ""
"A collection of servers that can share IPs with other members of the group. "
"Any server in a group can share one or more public IPs with any other server"
" in the group. With the exception of the first server in a shared IP group, "
"servers must be launched into shared IP groups. A server may be a member of "
"only one shared IP group."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4196(glossterm)
msgid "shared storage"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4198(para)
msgid ""
"Block storage that is simultaneously accessible by multiple clients, for "
"example, NFS."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4203(glossterm)
msgid "Sheepdog"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4205(para)
msgid "Distributed block storage system for QEMU, supported by OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4210(glossterm)
msgid "Simple Cloud Identity Management (SCIM)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4213(para)
msgid ""
"Specification for managing identity in the cloud, currently unsupported by "
"OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4218(glossterm)
msgid "Single-root I/O Virtualization (SR-IOV)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4221(para)
msgid ""
"A specification that when implemented by a physical PCIe device enables it "
"to appear as multiple separate PCIe devices. This enables multiple "
"virtualized guests to share direct access to the physical device, offering "
"improved performance over an equivalent virtual device. Currently supported "
"in OpenStack Havana and later releases."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4231(glossterm)
msgid "SmokeStack"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4233(para)
msgid "Runs automated tests against the core OpenStack API; written in Rails."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4240(para)
msgid ""
"A point-in-time copy of an OpenStack storage volume or image. Use storage "
"volume snapshots to back up volumes. Use image snapshots to back up data, or"
" as \"gold\" images for additional servers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4248(glossterm)
msgid "soft reboot"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4250(para)
msgid ""
"A controlled reboot where a VM instance is properly restarted through "
"operating system commands."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4256(glossterm)
msgid "SolidFire Volume Driver"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4258(para)
msgid "The Block Storage driver for the SolidFire iSCSI storage appliance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4263(glossterm)
msgid "SPICE"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4265(para)
msgid ""
"The Simple Protocol for Independent Computing Environments (SPICE) provides "
"remote desktop access to guest virtual machines. It is an alternative to "
"VNC. SPICE is supported by OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4274(glossterm)
msgid "spread-first scheduler"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4276(para)
msgid ""
"The Compute VM scheduling algorithm that attempts to start a new VM on the "
"host with the least amount of load."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4282(glossterm)
msgid "SQL-Alchemy"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4284(para)
msgid "An open source SQL toolkit for Python, used in OpenStack."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4289(glossterm)
msgid "SQLite"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4291(para)
msgid ""
"A lightweight SQL database, used as the default persistent storage method in"
" many OpenStack services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4299(para)
msgid ""
"Community project that captures Compute AMQP communications, useful for "
"debugging."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4304(glossterm)
msgid "static IP address"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4306(para)
msgid "Alternative term for a fixed IP address."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4310(glossterm)
msgid "StaticWeb"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4312(para)
msgid ""
"WSGI middleware component of Object Storage that serves container data as a "
"static web page."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4317(glossterm)
msgid "storage back end"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4319(para)
msgid ""
"The method that a service uses for persistent storage, such as iSCSI, NFS, "
"or local disk."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4324(glossterm)
msgid "storage node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4326(para)
msgid ""
"An Object Storage node that provides container services, account services, "
"and object services; controls the account databases, container databases, "
"and object storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4333(glossterm)
msgid "storage manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4335(para)
msgid ""
"A XenAPI component that provides a pluggable interface to support a wide "
"variety of persistent storage back ends."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4341(glossterm)
msgid "storage manager back end"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4343(para)
msgid "A persistent storage method supported by XenAPI, such as iSCSI or NFS."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4348(glossterm)
msgid "storage services"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4350(para)
msgid ""
"Collective name for the Object Storage object services, container services, "
"and account services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4355(glossterm)
msgid "strategy"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4357(para)
msgid ""
"Specifies the authentication source used by Image Service or Identity "
"Service."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4362(glossterm)
msgid "subdomain"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4364(para)
msgid ""
"A domain within a parent domain. Subdomains cannot be registered. Subdomains"
" enable you to delegate domains. Subdomains can themselves have subdomains, "
"so third-level, fourth-level, fifth-level, and deeper levels of nesting are "
"possible."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4373(glossterm)
msgid "SUSE Linux Enterprise Server (SLES)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4380(glossterm)
msgid "suspend"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4382(para)
msgid "Alternative term for a paused VM instance."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4387(glossterm)
msgid "swap"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4389(para)
msgid ""
"Disk-based virtual memory, used by operating systems to provide more memory "
"than is actually available on the system."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4395(glossterm)
msgid "swawth"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4397(para)
msgid ""
"An authentication and authorization service for Object Storage, implemented "
"through WSGI middleware; uses Object Storage itself as the persistent "
"backing store."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4404(glossterm)
msgid "swift"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4406(para)
msgid "An OpenStack core project that provides object storage services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4411(glossterm)
msgid "swift All in One (SAIO)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4413(para)
msgid ""
"Creates a full Object Storage development environment within a single VM."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4418(glossterm)
msgid "swift middleware"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4420(para)
msgid ""
"Collective term for Object Storage components that provide additional "
"functionality."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4425(glossterm)
msgid "swift proxy server"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4427(para)
msgid ""
"Acts as the gatekeeper to Object Storage and is responsible for "
"authenticating the user."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4432(glossterm)
msgid "swift storage node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4434(para)
msgid ""
"A node that runs Object Storage account, container, and object services."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4439(glossterm)
msgid "sync point"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4441(para)
msgid ""
"Point in time since the last container and accounts database sync among "
"nodes within Object Storage."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4447(glossterm)
msgid "sysadmin"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4449(para)
msgid ""
"One of the default roles in the Compute RBAC system. Enables a user to add "
"other users to a project, interact with VM images that are associated with "
"the project, and start and stop VM (VM) instances."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4457(glossterm)
msgid "system usage"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4459(para)
msgid ""
"A Compute component that, along with the notification system, collects "
"metrics and usage information. This information can be used for billing."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4468(title)
msgid "T"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4470(glossterm)
msgid "Telemetry"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4472(para)
msgid ""
"An integrated project that provides metering and measuring facilities for "
"OpenStack. The project name of Telemetry is ceilometer."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4478(glossterm)
msgid "TempAuth"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4480(para)
msgid ""
"An authentication facility within Object Storage that enables Object Storage"
" itself to perform authentication and authorization. Frequently used in "
"testing and development."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4487(glossterm)
msgid "Tempest"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4489(para)
msgid ""
"Automated software test suite designed to run against the trunk of the "
"OpenStack core project."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4495(glossterm)
msgid "TempURL"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4497(para)
msgid ""
"An Object Storage middleware component that enables creation of URLs for "
"temporary object access."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4501(glossterm)
msgid "tenant"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4503(para)
msgid ""
"A group of users, used to isolate access to Compute resources. An "
"alternative term for a project."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4509(glossterm)
msgid "Tenant API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4511(para)
msgid "An API that is accessible to tenants."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4515(glossterm)
msgid "tenant endpoint"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4517(para)
msgid ""
"An Identity Service API endpoint that is associated with one or more "
"tenants."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4522(glossterm)
msgid "tenant ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4524(para)
msgid ""
"Unique ID assigned to each tenant within the Identity Service. The project "
"IDs map to the tenant IDs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4530(glossterm)
msgid "token"
msgstr "token"

#: ./doc/openstack-ops/glossary-terms.xml4532(para)
msgid ""
"An alpha-numeric string of text used to access OpenStack APIs and resources."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4537(glossterm)
msgid "token services"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4539(para)
msgid ""
"An Identity Service component that manages and validates tokens after a user"
" or tenant has been authenticated."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4545(glossterm)
msgid "tombstone"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4547(para)
msgid ""
"Used to mark Object Storage objects that have been deleted; ensures that the"
" object is not updated on another node after it has been deleted."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4553(glossterm)
msgid "topic publisher"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4555(para)
msgid ""
"A process that is created when a RPC call is executed; used to push the "
"message to the topic exchange."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4561(glossterm)
msgid "Torpedo"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4563(para)
msgid ""
"Community project used to run automated tests against the OpenStack API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4568(glossterm)
msgid "transaction ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4570(para)
msgid ""
"Unique ID assigned to each Object Storage request; used for debugging and "
"tracing."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4575(glossterm)
msgid "transient"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4577(para)
msgid "Alternative term for non-durable."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4581(glossterm)
msgid "transient exchange"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4583(para)
msgid "Alternative term for a non-durable exchange."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4588(glossterm)
msgid "transient message"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4590(para)
msgid ""
"A message that is stored in memory and is lost after the server is "
"restarted."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4595(glossterm)
msgid "transient queue"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4597(para)
msgid "Alternative term for a non-durable queue."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4601(glossterm)
msgid "trove"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4603(para)
msgid "OpenStack project that provides database services to applications."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4610(title)
msgid "U"
msgstr "U"

#: ./doc/openstack-ops/glossary-terms.xml4612(glossterm)
msgid "Ubuntu"
msgstr "Ubuntu"

#: ./doc/openstack-ops/glossary-terms.xml4614(para)
msgid "A Debian-based Linux distribution."
msgstr "Debian-alapú Linux disztribúció."

#: ./doc/openstack-ops/glossary-terms.xml4618(glossterm)
msgid "unscoped token"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4620(para)
msgid "Alternative term for an Identity Service default token."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4625(glossterm)
msgid "updater"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4627(para)
msgid ""
"Collective term for a group of Object Storage components that processes "
"queued and failed updates for containers and objects."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4633(glossterm)
msgid "user"
msgstr "felhasználó"

#: ./doc/openstack-ops/glossary-terms.xml4635(para)
msgid ""
"In Identity Service, each user is associated with one or more tenants, and "
"in Compute can be associated with roles, projects, or both."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4641(glossterm)
msgid "user data"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4643(para)
msgid ""
"A blob of data that can be specified by the user when launching an instance."
" This data can be accessed by the instance through the metadata service or "
"config drive. Commonly used for passing a shell script that is executed by "
"the instance on boot."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4652(glossterm)
msgid "User Mode Linux (UML)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4660(title)
msgid "V"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4662(glossterm)
msgid "VIF UUID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4664(para)
msgid "Unique ID assigned to each Networking VIF."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4668(glossterm)
msgid "Virtual Central Processing Unit (vCPU)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4671(para)
msgid "Sub-divides physical CPUs. Instances can then use those divisions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4676(glossterm)
msgid "Virtual Disk Image (VDI)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4683(glossterm)
msgid "Virtual Hard Disk (VHD)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4690(glossterm)
msgid "virtual IP"
msgstr "virtuális IP"

#: ./doc/openstack-ops/glossary-terms.xml4692(para)
msgid ""
"An Internet Protocol (IP) address configured on the load balancer for use by"
" clients connecting to a service that is load balanced. Incoming connections"
" are distributed to back-end nodes based on the configuration of the load "
"balancer."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4701(glossterm)
msgid "virtual machine (VM)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4703(para)
msgid ""
"An operating system instance that runs on top of a hypervisor. Multiple VMs "
"can run at the same time on the same physical host."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4709(glossterm)
msgid "virtual network"
msgstr "virtuális hálózat"

#: ./doc/openstack-ops/glossary-terms.xml4711(para)
msgid "An L2 network segment within Networking."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4715(glossterm)
msgid "Virtual Network Computing (VNC)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4717(para)
msgid ""
"Open source GUI and CLI tools used for remote console access to VMs. "
"Supported by Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4722(glossterm)
msgid "Virtual Network InterFace (VIF)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4724(para)
msgid ""
"An interface that is plugged into a port in a Networking network. Typically "
"a virtual network interface belonging to a VM."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4730(glossterm)
msgid "virtual port"
msgstr "virtuális port"

#: ./doc/openstack-ops/glossary-terms.xml4732(para)
msgid ""
"Attachment point where a virtual interface connects to a virtual network."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4737(glossterm)
msgid "virtual private network (VPN)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4739(para)
msgid ""
"Provided by Compute in the form of cloudpipes, specialized instances that "
"are used to create VPNs on a per-project basis."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4745(glossterm)
msgid "virtual server"
msgstr "virtuális szerver"

#: ./doc/openstack-ops/glossary-terms.xml4747(para)
msgid "Alternative term for a VM or guest."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4751(glossterm)
msgid "virtual switch (vSwitch)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4753(para)
msgid ""
"Software that runs on a host or node and provides the features and functions"
" of a hardware-based network switch."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4761(glossterm)
msgid "virtual VLAN"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4763(para)
msgid "Alternative term for a virtual network."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4767(glossterm)
msgid "VirtualBox"
msgstr "VirtualBox"

#: ./doc/openstack-ops/glossary-terms.xml4773(glossterm)
msgid "VLAN manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4775(para)
msgid ""
"A Compute component that provides dnsmasq and radvd and sets up forwarding "
"to and from cloudpipe instances."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4781(glossterm)
msgid "VLAN network"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4783(para)
msgid ""
"The Network Controller provides virtual networks to enable compute servers "
"to interact with each other and with the public network. All machines must "
"have a public and private network interface. A VLAN network is a private "
"network interface, which is controlled by the vlan_interface option with "
"VLAN managers."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4793(glossterm)
msgid "VM disk (VMDK)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4800(glossterm)
msgid "VM image"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4802(para)
msgid "Alternative term for an image."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4806(glossterm)
msgid "VM Remote Control (VMRC)"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4808(para)
msgid ""
"Method to access VM instance consoles using a web browser. Supported by "
"Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4813(glossterm)
msgid "VMware API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4815(para)
msgid "Supports interaction with VMware products in Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4820(glossterm)
msgid "VMware NSX Neutron plugin"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4822(para)
msgid "Provides support for VMware NSX in Neutron."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4826(glossterm)
msgid "VNC proxy"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4828(para)
msgid ""
"A Compute component that provides users access to the consoles of their VM "
"instances through VNC or VMRC."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4834(glossterm)
msgid "volume"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4836(para)
msgid ""
"Disk-based data storage generally represented as an iSCSI target with a file"
" system that supports extended attributes; can be persistent or ephemeral."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4843(glossterm)
msgid "Volume API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4845(para)
msgid ""
"An API on a separate endpoint for attaching, detaching, and creating block "
"storage for compute VMs."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4851(glossterm)
msgid "volume controller"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4853(para)
msgid ""
"A Block Storage component that oversees and coordinates storage volume "
"actions."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4858(glossterm)
msgid "volume driver"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4860(para)
msgid "Alternative term for a volume plug-in."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4864(glossterm)
msgid "volume ID"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4866(para)
msgid ""
"Unique ID applied to each storage volume under the Block Storage control."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4871(glossterm)
msgid "volume manager"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4873(para)
msgid ""
"A Block Storage component that creates, attaches, and detaches persistent "
"storage volumes."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4878(glossterm)
msgid "volume node"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4880(para)
msgid ""
"A Block Storage node that runs the <systemitem class=\"service\">cinder-"
"volume</systemitem> daemon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4886(glossterm)
msgid "volume plug-in"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4888(para)
msgid ""
"Provides support for new and specialized types of back-end storage for the "
"Block Storage volume manager."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4895(glossterm)
msgid "Volume Service API"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4897(para)
msgid "Alternative term for the Compute volume API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4901(glossterm)
msgid "volume worker"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4903(para)
msgid ""
"A cinder component that interacts with back-end storage to manage the "
"creation and deletion of volumes and the creation of compute volumes, "
"provided by the <systemitem class=\"service\">cinder-volume</systemitem> "
"daemon."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4910(glossterm)
msgid "vSphere"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4918(title)
msgid "W"
msgstr "W"

#: ./doc/openstack-ops/glossary-terms.xml4920(glossterm)
msgid "weighing"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4922(para)
msgid ""
"A Compute process that determines the suitability of the VM instances for a "
"job for a particular host. For example, not enough RAM on the host, too many"
" CPUs on the host, and so on."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4929(glossterm)
msgid "weight"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4931(para)
msgid ""
"Used by Object Storage devices to determine which storage devices are "
"suitable for the job. Devices are weighted by size."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4937(glossterm)
msgid "weighted cost"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4939(para)
msgid ""
"The sum of each cost used when deciding where to start a new VM instance in "
"Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4944(glossterm)
msgid "worker"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4946(para)
msgid ""
"A daemon that listens to a queue and carries out tasks in response to "
"messages. For example, the <systemitem class=\"service\">cinder-"
"volume</systemitem> worker manages volume creation and deletion on storage "
"arrays."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4959(title)
msgid "X"
msgstr "X"

#: ./doc/openstack-ops/glossary-terms.xml4961(glossterm)
msgid "Xen API"
msgstr "Xen API"

#: ./doc/openstack-ops/glossary-terms.xml4963(para)
msgid "The Xen administrative API, which is supported by Compute."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4968(glossterm)
msgid "Xen Cloud Platform (XCP)"
msgstr "Xen Cloud Platform (XCP)"

#: ./doc/openstack-ops/glossary-terms.xml4974(glossterm)
msgid "Xen Storage Manager Volume Driver"
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4976(para)
msgid ""
"A Block Storage volume plug-in that enables communication with the Xen "
"Storage Manager API."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml4982(glossterm)
msgid "XenServer"
msgstr "XenServer"

#: ./doc/openstack-ops/glossary-terms.xml4990(title)
msgid "Y"
msgstr "Y"

#: ./doc/openstack-ops/glossary-terms.xml5000(title)
msgid "Z"
msgstr "Z"

#: ./doc/openstack-ops/glossary-terms.xml5002(glossterm)
msgid "ZeroMQ"
msgstr "ZeroMQ"

#: ./doc/openstack-ops/glossary-terms.xml5004(para)
msgid ""
"Message queue software supported by OpenStack. An alternative to RabbitMQ. "
"Also spelled 0MQ."
msgstr ""

#: ./doc/openstack-ops/glossary-terms.xml5010(glossterm)
msgid "Zuul"
msgstr "Zuul"

#: ./doc/openstack-ops/glossary-terms.xml5012(para)
msgid ""
"Tool used in OpenStack development to ensure correctly ordered testing of "
"changes in parallel."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/preface_ops.xml338(None)
msgid ""
"@@image: 'figures/1-IMG_4895.JPG'; md5=fa6e602f909a462f29afd9596a8aa998"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml14(title)
msgid "Preface"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml15(para)
msgid ""
"OpenStack is an open source platform that lets you build an Infrastructure "
"as a Service (IaaS) cloud that runs on commodity hardware."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml19(title)
msgid "Introduction to OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml20(para)
msgid ""
"OpenStack believes in open source, open design, open development, all in an "
"open community that encourages participation by anyone. The long-term vision"
" for OpenStack is to produce a ubiquitous open source cloud computing "
"platform that meets the needs of public and private cloud providers "
"regardless of size. OpenStack services control large pools of compute, "
"storage, and networking resources throughout a data center."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml25(para)
msgid ""
"The technology behind OpenStack consists of a series of interrelated "
"projects delivering various components for a cloud infrastructure solution. "
"Each service provides an open API so that all of these resources can be "
"managed through a dashboard that gives administrators control while "
"empowering users to provision resources through a web interface, a command-"
"line client, or software development kits that support the API. Many "
"OpenStack APIs are extensible, meaning you can keep compatibility with a "
"core set of calls while providing access to more resources and innovating "
"through API extensions. The OpenStack project is a global collaboration of "
"developers and cloud computing technologists. The project produces an open "
"standard cloud computing platform for both public and private clouds. By "
"focusing on ease of implementation, massive scalability, a variety of rich "
"features, and tremendous extensibility, the project aims to deliver a "
"practical and reliable cloud solution for all types of organizations."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml38(title)
msgid "Getting Started with OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml39(para)
msgid ""
"As an open source project, one of the unique aspects of OpenStack is that it"
" has many different levels at which you can begin to engage with it—you "
"don't have to do everything yourself."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml43(title)
msgid "Using OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml44(para)
msgid ""
"You could ask, \"Do I even need to build a cloud?\" If you want to start "
"using a compute or storage service by just swiping your credit card, you can"
" go to eNovance, HP, Rackspace, or other organizations to start using their "
"public OpenStack clouds. Using their OpenStack cloud resources is similar to"
" accessing the publically available Amazon Web Services Elastic Compute "
"Cloud (EC2) or Simple Storage Solution (S3)."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml52(title)
msgid "Plug and Play OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml53(para)
msgid ""
"However, the enticing part of OpenStack might be to build your own private "
"cloud, and there are several ways to accomplish this goal. Perhaps the "
"simplest of all is an appliance-style solution. You purchase an appliance, "
"unpack it, plug in the power and the network, and watch it transform into an"
" OpenStack cloud with minimal additional configuration. Few, if any, other "
"open source cloud products have such turnkey options. If a turnkey solution "
"is interesting to you, take a look at Nebula One."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml59(para)
msgid ""
"However, hardware choice is important for many applications, so if that "
"applies to you, consider that there are several software distributions "
"available that you can run on servers, storage, and network products of your"
" choosing. Canonical (where OpenStack replaced Eucalyptus as the default "
"cloud option in 2011), Red Hat, and SUSE offer enterprise OpenStack "
"solutions and support. You may also want to take a look at some of the "
"specialized distributions, such as those from Rackspace, Piston, SwiftStack,"
" or Cloudscaling. Also, a hat tip to Apache CloudStack, which Citrix donated"
" to the Apache Foundation after its US $200 million purchase of Cloud.com. "
"While not currently packaged in any distributions, like Eucalyptus it is an "
"example of an alternative private cloud software developed in an open "
"source–like manner."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml69(para)
msgid ""
"Alternatively, if you want someone to help guide you through the decisions "
"about the underlying hardware or your applications, perhaps adding in a few "
"features or integrating components along the way, consider contacting one of"
" the system integrators with OpenStack experience, such as Mirantis or "
"Metacloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml73(para)
msgid ""
"If your preference is to build your own OpenStack expertise internally, a "
"good way to kick-start that might be to attend or arrange a training "
"session. The OpenStack Foundation recently launched a <link "
"href=\"http://www.openstack.org/marketplace/training\">Training Marketplace "
"(http://www.openstack.org/marketplace/training)</link> where you can look "
"for nearby events. Also, the OpenStack community is <link "
"href=\"https://wiki.openstack.org/wiki/Training-manuals\">working to produce"
" (https://wiki.openstack.org/wiki/Training-manuals)</link> open source "
"training materials."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml84(title)
msgid "Roll Your Own OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml85(para)
msgid ""
"However, this guide has a different audience—those seeking to derive the "
"most flexibility from the OpenStack framework; conducting do-it-yourself "
"solutions, if you will."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml88(para)
msgid ""
"OpenStack is designed for scalability, so you can easily add new compute, "
"network, and storage resources to grow your cloud over time. In addition to "
"several massive OpenStack public clouds, a considerable number of "
"organizations (such as Paypal, Intel, and Comcast) have built large-scale "
"private clouds. OpenStack offers much more than a typical software package "
"because it lets you integrate a number of different technologies to "
"construct a cloud. This approach provides great flexibility, but the number "
"of options might be bewildering at first."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml98(title)
msgid "Who This Book Is For"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml99(para)
msgid ""
"This book is for those of you starting to run OpenStack clouds as well as "
"those of you who were handed an operational one and want to keep it running "
"well. Perhaps you're on a devops team, perhaps you are a system "
"administrator starting to dabble in the cloud, or maybe you want to get on "
"the OpenStack cloud team at your company. This book is for all of you."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml105(para)
msgid ""
"This guide assumes that you are familiar with a Linux distribution that "
"supports OpenStack, SQL databases, and virtualization. You must be "
"comfortable administering and configuring multiple Linux machines for "
"networking. You must install and maintain an SQL database and occasionally "
"run queries against it."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml110(para)
msgid ""
"One of the most complex aspects of an OpenStack cloud is the networking "
"configuration. You should be familiar with concepts such as DHCP, Linux "
"bridges, VLANs, and iptables. You must also have access to a network "
"hardware expert who can configure the switches and routers required in your "
"OpenStack cloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml115(para)
msgid ""
"Cloud computing is a quite advanced topic, and this book requires a lot of "
"background knowledge. However, if you are fairly new to cloud computing, we "
"recommend that you make use of the <xref linkend=\"openstack_glossary\"/> at"
" the back of the book, as well as the online documentation for OpenStack and"
" additional resources mentioned in this book in <xref linkend=\"recommended-"
"reading\"/>."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml122(title)
msgid "Further Reading"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml123(para)
msgid ""
"There are other books on the OpenStack documentation website, at <link "
"href=\"http://docs.openstack.org\">docs.openstack.org</link>, that can help "
"you get the job done."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml128(title)
msgid "OpenStack Guides"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml130(term)
msgid "OpenStack Installation Guides"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml132(para)
msgid ""
"Describes a manual installation process, as in, by hand, no automation, for "
"multiple distributions based on a packaging system:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml139(link)
msgid "Installation Guide for Debian 7.0"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml145(link)
msgid "Installation Guide for openSUSE and SUSE Linux Enterprise Server"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml152(link)
msgid "Installation Guide for Red Hat Enterprise Linux, CentOS, and Fedora"
msgstr "Telepítési útmutató Red Hat Enterprise Linux-hoz, CentOS-hoz és Fedora-hoz"

#: ./doc/openstack-ops/preface_ops.xml158(link)
msgid "Installation Guide for Ubuntu 12.04 (LTS) Server"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml167(link)
msgid "OpenStack Configuration Reference"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml170(para)
msgid ""
"Contains a reference listing of all configuration options for core and "
"integrated OpenStack services by release version."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml178(link)
msgid "OpenStack Cloud Administrator Guide"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml180(para)
msgid ""
"Contains how-to information for managing an OpenStack cloud as needed for "
"your use cases, such as storage, computing, or software-defined-networking."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml188(link)
msgid "OpenStack High Availability Guide"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml191(para)
msgid ""
"Describes potential strategies for making your OpenStack services and "
"related controllers and data stores highly available."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml198(link)
msgid "OpenStack Security Guide"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml200(para)
msgid ""
"Provides best practices and conceptual information about securing an "
"OpenStack cloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml205(link)
msgid "Virtual Machine Image Guide"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml207(para)
msgid ""
"Shows you how to obtain, create, and modify virtual machine images that are "
"compatible with OpenStack."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml213(link)
msgid "OpenStack End User Guide"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml215(para)
msgid ""
"Shows OpenStack end users how to create and manage resources in an OpenStack"
" cloud with the OpenStack dashboard and OpenStack client commands."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml221(link)
msgid "OpenStack Admin User Guide"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml223(para)
msgid ""
"Shows OpenStack administrators how to create and manage resources in an "
"OpenStack cloud with the OpenStack dashboard and OpenStack client commands."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml230(link)
msgid "OpenStack API Quick Start"
msgstr "OpenStack API Rövid útmutató"

#: ./doc/openstack-ops/preface_ops.xml232(para)
msgid ""
"A brief overview of how to send REST API requests to endpoints for OpenStack"
" services."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml240(title)
msgid "How This Book Is Organized"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml241(para)
msgid ""
"This book is organized in two parts: the architecture decisions for "
"designing OpenStack clouds and the repeated operations for running OpenStack"
" clouds."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml243(para)
msgid "Part I"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml244(para)
msgid ""
"<xref linkend=\"example_architecture\"/>: Because of all the decisions the "
"other chapters discuss, this chapter describes the decisions made for this "
"particular book and much of the justification for the example architecture."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml247(para)
msgid ""
"<xref linkend=\"section_arch_provision\"/>: While this book doesn't describe"
" installation, we do recommend automation for deployment and configuration, "
"discussed in this chapter."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml250(para)
msgid ""
"<xref linkend=\"cloud_controller_design\"/>: The cloud controller is an "
"invention for the sake of consolidating and describing which services run on"
" which nodes. This chapter discusses hardware and network considerations as "
"well as how to design the cloud controller for performance and separation of"
" services."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml254(para)
msgid ""
"<xref linkend=\"compute_nodes\"/>: This chapter describes the compute nodes,"
" which are dedicated to running virtual machines. Some hardware choices come"
" into play here, as well as logging and networking descriptions."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml257(para)
msgid ""
"<xref linkend=\"scaling\"/>: This chapter discusses the growth of your cloud"
" resources through scaling and segregation considerations."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml259(para)
msgid ""
"<xref linkend=\"storage_decision\"/>: As with other architecture decisions, "
"storage concepts within OpenStack take a lot of consideration, and this "
"chapter lays out the choices for you."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml262(para)
msgid ""
"<xref linkend=\"network_design\"/>: Your OpenStack cloud networking needs to"
" fit into your existing networks while also enabling the best design for "
"your users and administrators, and this chapter gives you in-depth "
"information about networking decisions."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml266(para)
msgid "Part II"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml267(para)
msgid ""
"<xref linkend=\"lay_of_the_land\"/>: This chapter is written to let you get "
"your hands wrapped around your OpenStack cloud through command-line tools "
"and understanding what is already set up in your cloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml270(para)
msgid ""
"<xref linkend=\"projects_users\"/>: This chapter walks through user-enabling"
" processes that all admins must face to manage users, give them quotas to "
"parcel out resources, and so on."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml273(para)
msgid ""
"<xref linkend=\"user_facing_operations\"/>: This chapter shows you how to "
"use OpenStack cloud resources and train your users as well."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml275(para)
msgid ""
"<xref linkend=\"maintenance\"/>: This chapter goes into the common failures "
"that the authors have seen while running clouds in production, including "
"troubleshooting."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml277(para)
msgid ""
"<xref linkend=\"network_troubleshooting\"/>: Because network troubleshooting"
" is especially difficult with virtual resources, this chapter is chock-full "
"of helpful tips and tricks for tracing network traffic, finding the root "
"cause of networking failures, and debugging related services such as DHCP "
"and DNS."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml281(para)
msgid ""
"<xref linkend=\"logging_monitoring\"/>: This chapter shows you where "
"OpenStack places logs and how to best read and manage logs for monitoring "
"purposes."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml283(para)
msgid ""
"<xref linkend=\"backup_and_recovery\"/>: This chapter describes what you "
"need to back up within OpenStack as well as best practices for recovering "
"backups."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml285(para)
msgid ""
"<xref linkend=\"customize\"/>: For readers who need to get a specialized "
"feature into OpenStack, this chapter describes how to use DevStack to write "
"custom middleware or a custom scheduler to rebalance your resources."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml288(para)
msgid ""
"<xref linkend=\"upstream_openstack\"/>: Because OpenStack is so, well, open,"
" this chapter is dedicated to helping you navigate the community and find "
"out where you can help and where you can get help."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml291(para)
msgid ""
"<xref linkend=\"advanced_configuration\"/>: Much of OpenStack is driver-"
"oriented, so you can plug in different solutions to the base set of "
"services. This chapter describes some advanced configuration topics."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml294(para)
msgid ""
"<xref linkend=\"ch_ops_upgrades\"/>: This chapter provides upgrade "
"information based on the architectures used in this book."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml296(para)
msgid ""
"<xref linkend=\"use-cases\"/>: You can read a small selection of use cases "
"from the OpenStack community with some technical details and further "
"resources."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml298(para)
msgid ""
"<xref linkend=\"app_crypt\"/>: These are shared legendary tales of image "
"disappearances, VM massacres, and crazy troubleshooting techniques to share "
"those hard-learned lessons and wisdom."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml301(para)
msgid ""
"<xref linkend=\"working-with-roadmaps\"/>: Read about how to track the "
"OpenStack roadmap through the open and transparent development processes."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml303(para)
msgid ""
"<xref linkend=\"recommended-reading\"/>: So many OpenStack resources are "
"available online because of the fast-moving nature of the project, but there"
" are also listed here resources the authors found helpful while learning "
"themselves."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml306(para)
msgid ""
"<xref linkend=\"openstack_glossary\"/>: A list of terms used in this book is"
" included, which is a subset of the larger OpenStack glossary available "
"online."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml310(title)
msgid "Why and How We Wrote This Book"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml311(para)
msgid ""
"We wrote this book because we have deployed and maintained OpenStack clouds "
"for at least a year, and wanted to be able to distribute this knowledge to "
"others. After months of being the point people for an OpenStack cloud, we "
"also wanted to have a document to hand to our system administrators so that "
"they'd know how to operate the cloud on a daily basis—both reactively and "
"proactively. We wanted to provide more detailed technical information about "
"the decisions that deployers make along the way."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml320(para)
msgid ""
"Design and create an architecture for your first nontrivial OpenStack cloud."
" After you read this guide, you'll know which questions to ask and how to "
"organize your compute, networking, and storage resources and the associated "
"software packages."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml326(para)
msgid "Perform the day-to-day tasks required to administer a cloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml318(para)
msgid "We wrote this book to help you:<placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml329(para)
msgid ""
"We wrote this book in a book sprint, which is a facilitated rapid "
"development production method for books. For more information see the <link "
"href=\"http://www.booksprints.net\">BookSprints site</link>. Your authors "
"cobbled this book together in five days during February 2013, fueled by "
"caffeine and the best take-out food that Austin, Texas, could offer."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml334(para)
msgid ""
"On the first day we filled white boards with colorful sticky notes to start "
"to shape this nebulous book about how to architect and operate "
"clouds.<placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml342(para)
msgid ""
"We wrote furiously from our own experiences and bounced ideas between each "
"other. At regular intervals we reviewed the shape and organization of the "
"book and further molded it, leading to what you see today."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml346(para)
msgid "The team includes:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml349(para)
msgid ""
"<emphasis role=\"bold\">Tom Fifield</emphasis>. After learning about "
"scalability in computing from particle physics experiments such as ATLAS at "
"the Large Hadron Collider (LHC) at CERN, Tom worked on OpenStack clouds in "
"production to support the Australian public research sector. Tom currently "
"serves as an OpenStack community manager and works on OpenStack "
"documentation in his spare time."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml356(para)
msgid ""
"<emphasis role=\"bold\">Diane Fleming</emphasis>. Diane works on the "
"OpenStack API documentation tirelessly. She helped out wherever she could on"
" this project."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml361(para)
msgid ""
"<emphasis role=\"bold\">Anne Gentle</emphasis>. Anne is the documentation "
"coordinator for OpenStack and also served as an individual contributor to "
"the Google Documentation Summit in 2011, working with the Open Street Maps "
"team. Anne has worked on book sprints in the past with FLOSS Manuals’ Adam "
"Hyde facilitating. Anne lives in Austin, Texas."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml368(para)
msgid ""
"<emphasis role=\"bold\">Lorin Hochstein</emphasis>. An academic turned "
"software-developer-slash-operator, Lorin worked as the lead architect for "
"Cloud Services at Nimbis Services, where he deploys OpenStack for technical "
"computing applications. He has been working with OpenStack since the Cactus "
"release. Previously, he worked on high-performance computing extensions for "
"OpenStack at University of Southern California's Information Sciences "
"Institute (USC-ISI)."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml377(para)
msgid ""
"<emphasis role=\"bold\">Adam Hyde</emphasis>. Adam facilitated this book "
"sprint. He also founded the books sprint methodology and is the most "
"experienced book-sprint facilitator around. See "
"<uri>http://www.booksprints.net/</uri> for more information. Adam founded "
"FLOSS Manuals—a community of some 3,000 individuals developing Free Manuals "
"about Free Software. He is also the founder and project manager for "
"Booktype, an open source project for writing, editing, and publishing books "
"online and in print."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml386(para)
msgid ""
"<emphasis role=\"bold\">Jonathan Proulx</emphasis>. Jon has been piloting an"
" OpenStack cloud as a senior technical architect at the MIT Computer Science"
" and Artificial Intelligence Lab for his researchers to have as much "
"computing power as they need. He started contributing to OpenStack "
"documentation and reviewing the documentation so that he could accelerate "
"his learning."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml393(para)
msgid ""
"<emphasis role=\"bold\">Everett Toews</emphasis>. Everett is a developer "
"advocate at Rackspace making OpenStack and the Rackspace Cloud easy to use. "
"Sometimes developer, sometimes advocate, and sometimes operator, he's built "
"web applications, taught workshops, given presentations around the world, "
"and deployed OpenStack for production use by academia and business."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml400(para)
msgid ""
"<emphasis role=\"bold\">Joe Topjian</emphasis>. Joe has designed and "
"deployed several clouds at Cybera, a non-profit where they are building "
"e-infrastructure to support entrepreneurs and local researchers in Alberta, "
"Canada. He also actively maintains and operates these clouds as a systems "
"architect, and his experiences have generated a wealth of troubleshooting "
"skills for cloud environments."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml408(para)
msgid ""
"<emphasis role=\"bold\">OpenStack community members</emphasis>. Many "
"individual efforts keep a community book alive. Our community members "
"updated content for this book year-round. Also, a year after the first "
"sprint, Jon Proulx hosted a second two-day mini-sprint at MIT with the goal "
"of updating the book for the latest release. Since the book's inception, "
"more than 30 contributors have supported this book. We have a tool chain for"
" reviews, continuous builds, and translations. Writers and developers "
"continuously review patches, enter doc bugs, edit content, and fix doc bugs."
" We want to recognize their efforts!"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml416(para)
msgid ""
"The following people have contributed to this book: Akihiro Motoki, "
"Alejandro Avella, Alexandra Settle, Andreas Jaeger, Andy McCallum, Benjamin "
"Stassart, Chandan Kumar, Chris Ricker, David Cramer, David Wittman, Denny "
"Zhang, Emilien Macchi, Gauvain Pocentek, Ignacio Barrio, James E. Blair, Jay"
" Clark, Jeff White, Jeremy Stanley, K Jonathan Harker, KATO Tomoyuki, Lana "
"Brindley, Laura Alves, Lee Li, Lukasz Jernas, Mario B. Codeniera, Matthew "
"Kassawara, Michael Still, Monty Taylor, Nermina Miller, Nigel Williams, Phil"
" Hopkins, Russell Bryant, Sahid Orentino Ferdjaoui, Sandy Walsh, Sascha "
"Peilicke, Sean M. Collins, Sergey Lukjanov, Shilla Saebi, Stephen Gordon, "
"Summer Long, Uwe Stuehler, Vaibhav Bhatkar, Veronica Musso, Ying Chun "
"\"Daisy\" Guo, Zhengguang Ou, and ZhiQiang Fan."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml429(title)
msgid "How to Contribute to This Book"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml430(para)
msgid ""
"The genesis of this book was an in-person event, but now that the book is in"
" your hands we want you to contribute to it. OpenStack documentation follows"
" the coding principles of iterative work, with bug logging, investigating, "
"and fixing. We also store the source content on Github and invite "
"collaborators through the OpenStack Gerrit installation, which offers "
"reviews. For the O'Reilly edition of this book, we are using the company's "
"Atlas system which also stores source content on Github and enables "
"collaboration among contributors."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml439(para)
msgid ""
"Learn more about how to contribute to the OpenStack docs at <link "
"href=\"http://wiki.openstack.org/Documentation/HowTo\">Documentation How "
"To</link> (http://wiki.openstack.org/Documentation/HowTo)."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml444(para)
msgid ""
"If you find a bug and can't fix it or aren't sure it's really a doc bug, log"
" a bug at <link href=\"http://bugs.launchpad.net/openstack-"
"manuals\">OpenStack Manuals</link> (http://bugs.launchpad.net/openstack-"
"manuals). Tag the bug under <guilabel>Extra</guilabel> options with the "
"<literal>ops-guide</literal> tag to indicate that the bug is in this guide. "
"You can assign the bug to yourself if you know how to fix it. Also, a member"
" of the OpenStack doc-core team can triage the doc bug."
msgstr ""

#: ./doc/openstack-ops/part_operations.xml15(title)
msgid "Operations"
msgstr ""

#: ./doc/openstack-ops/part_operations.xml17(para)
msgid ""
"Congratulations! By now, you should have a solid design for your cloud. We "
"now recommend that you turn to the <link title=\"OpenStack Install and "
"Deploy Manual for Ubuntu\" href=\"http://docs.openstack.org/havana/install-"
"guide/install/apt/\">OpenStack Install and Deploy Manual for Ubuntu</link> "
"(http://docs.openstack.org/havana/install-guide/install/apt/), which "
"contains a step-by-step guide on how to manually install the OpenStack "
"packages and dependencies on your cloud."
msgstr ""

#: ./doc/openstack-ops/part_operations.xml25(para)
msgid ""
"While it is important for an operator to be familiar with the steps involved"
" in deploying OpenStack, we also strongly encourage you to evaluate "
"configuration-management tools such as <glossterm>Puppet</glossterm> or "
"<glossterm>Chef</glossterm> that can help automate this deployment process."
msgstr ""

#: ./doc/openstack-ops/part_operations.xml31(para)
msgid ""
"In the remainder of this guide, we assume that you have successfully "
"deployed an OpenStack cloud and are able to perform basic operations such as"
" adding images, booting instances, and attaching volumes."
msgstr ""

#: ./doc/openstack-ops/part_operations.xml35(para)
msgid ""
"As your focus turns to stable operations, we recommend that you do skim the "
"remainder of this book to get a sense of the content. Some of this content "
"is useful to read in advance so that you can put best practices into effect "
"to simplify your life in the long run. Other content is more useful as a "
"reference that you might turn to when an unexpected event occurs, such as a "
"power failure, or to troubleshoot a particular problem."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml53(None)
msgid ""
"@@image: 'figures/network_packet_ping.png'; "
"md5=3b1f2132f9133d2ce1960743a2d6c6a4"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml135(None)
msgid ""
"@@image: 'figures/neutron_packet_ping.png'; "
"md5=c22e7f04efcc1d5cb7c839ddcadccfcc"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml14(title)
msgid "Network Troubleshooting"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml15(para)
msgid ""
"Network troubleshooting can unfortunately be a very difficult and confusing "
"procedure. A network issue can cause a problem at several points in the "
"cloud. Using a logical troubleshooting procedure can help mitigate the "
"confusion and more quickly isolate where exactly the network issue is. This "
"chapter aims to give you the information you need to identify any issues for"
" either nova-network or OpenStack Networking (neutron) with Linux Bridge or "
"Open vSwitch."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml23(title)
msgid "Using \"ip a\" to Check Interface States"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml24(para)
msgid ""
"On compute nodes and nodes running nova-network, use the following command "
"to see information about interfaces, including information about IPs, VLANs,"
" and whether your interfaces are up."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml29(para)
msgid ""
"If you're encountering any sort of networking difficulty, one good initial "
"sanity check is to make sure that your interfaces are up. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml39(para)
msgid ""
"You can safely ignore the state of virbr0, which is a default bridge created"
" by libvirt and not used by OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml44(title)
msgid "Nova-Network Traffic in the Cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml45(para)
msgid ""
"If you are logged in to an instance and ping an external host, for example "
"google.com, the ping packet takes the route:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml49(title)
msgid "Traffic Route for Ping Packet"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml59(para)
msgid ""
"The instance generates a packet and places it on the virtual Network "
"Interface Card (NIC) inside the instance, such as eth0."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml64(para)
msgid ""
"The packet transfers to the virtual NIC of the compute host, such as, vnet1."
" You can find out what vnet NIC is being used by looking at the "
"<filename>/etc/libvirt/qemu/instance-xxxxxxxx.xml</filename> file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml71(para)
msgid ""
"From the vnet NIC, the packet transfers to a bridge on the compute node, "
"such as <code>br100</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml74(para)
msgid ""
"If you run FlatDHCPManager, one bridge is on the compute node. If you run "
"VlanManager, one bridge exists for each VLAN."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml77(para)
msgid ""
"To see which bridge the packet will use, run the command: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml81(para)
msgid ""
"Look for the vnet NIC. You can also reference <filename>nova.conf</filename>"
" and look for the <code>flat_interface_bridge</code> option."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml87(para)
msgid ""
"The packet transfers to the main NIC of the compute node. You can also see "
"this NIC in the <placeholder-1/> output, or you can find it by referencing "
"the flat_interface option in <filename>nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml93(para)
msgid ""
"After the packet is on this NIC, it transfers to the compute node's default "
"gateway. The packet is now most likely out of your control at this point. "
"The diagram depicts an external gateway. However, in the default "
"configuration with multi-host, the compute host is the gateway."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml101(para)
msgid "Reverse the direction to see the path of a ping reply."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml103(para)
msgid ""
"From this path, you can see that a single packet travels across four "
"different NICs. If a problem occurs with any of these NICs, a network issue "
"occurs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml108(title)
msgid "OpenStack Networking Service Traffic in the Cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml109(para)
msgid ""
"The OpenStack Networking Service, neutron, has many more degrees of freedom "
"than nova-network does because of its pluggable back end. It can be "
"configured with open source or vendor proprietary plug-ins that control "
"software defined networking (SDN) hardware or plug-ins that use Linux native"
" facilities on your hosts such as Open vSwitch or Linux Bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml115(para)
msgid ""
"The networking chapter of the OpenStack <link title=\"Cloud Administrator "
"Guide\" href=\"http://docs.openstack.org/admin-guide-"
"cloud/content/ch_networking.html\">Cloud Administrator Guide</link> "
"(http://docs.openstack.org/admin-guide-cloud/content/ch_networking.html) "
"shows a variety of networking scenarios and their connection paths. The "
"purpose of this section is to give you the tools to troubleshoot the various"
" components involved however they are plumbed together in your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml124(para)
msgid ""
"For this example we will use the Open vSwitch (OVS) back end. Other back-end"
" plug-ins will have very different flow paths. OVS is the most popularly "
"deployed network driver according to the October 2013 OpenStack User Survey,"
" with 50 percent more sites using it than the second place Linux Bridge "
"driver."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml129(para)
msgid "We'll describe each step in turn with this diagram for reference:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml131(title)
msgid "Neutron Network Paths"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml141(para)
msgid ""
"The instance generates a packet and places it on the virtual NIC inside the "
"instance, such as eth0."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml145(para)
msgid ""
"The packet transfers to a Test Access Point (TAP) device on the compute "
"host, such as tap690466bc-92. You can find out what TAP is being used by "
"looking at the <filename>/etc/libvirt/qemu/instance-xxxxxxxx.xml</filename> "
"file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml149(para)
msgid ""
"The TAP device name is constructed using the first 11 characters of the port"
" ID (10 hex digits plus an included '-'), so another means of finding the "
"device name is to use the <placeholder-1/> command. This returns a pipe- "
"delimited list, the first item of which is the port ID. For example, to get "
"the port ID associated with IP address 10.0.0.10, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml159(para)
msgid ""
"Taking the first 11 characters, we can construct a device name of "
"tapff387e54-9e from this output."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml163(para)
msgid ""
"The TAP device is connected to the integration bridge, <code>br-int</code>. "
"This bridge connects all the instance TAP devices and any other bridges on "
"the system. In this example, we have <code>int-br-eth1</code> and <code"
">patch-tun</code>. <code>int-br-eth1</code> is one half of a veth pair "
"connecting to the bridge <code>br-eth1</code>, which handles VLAN networks "
"trunked over the physical Ethernet device <code>eth1</code>. <code>patch-"
"tun</code> is an Open vSwitch internal port that connects to the <code>br-"
"tun</code> bridge for GRE networks."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml176(para)
msgid ""
"The TAP devices and veth devices are normal Linux network devices and may be"
" inspected with the usual tools such as <placeholder-1/> and "
"<placeholder-2/>. Open vSwitch internal devices, such as <code>patch-"
"tun</code>, are only visible within the Open vSwitch environment. If you try"
" to run <placeholder-3/>, it will raise an error saying that the device does"
" not exist."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml185(para)
msgid ""
"It is possible to watch packets on internal interfaces, but it does take a "
"little bit of networking gymnastics. First you need to create a dummy "
"network device that normal Linux tools can see. Then you need to add it to "
"the bridge containing the internal interface you want to snoop on. Finally, "
"you need to tell Open vSwitch to mirror all traffic to or from the internal "
"port onto this dummy port. After all this, you can then run <placeholder-1/>"
" on the dummy interface and see the traffic on the internal port."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml198(title)
msgid ""
"To capture packets from the <code>patch-tun</code> internal interface on "
"integration bridge, <code>br-int</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml203(para)
msgid "Create and bring up a dummy interface, <code>snooper0</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml212(para)
msgid "Add device <code>snooper0</code> to bridge <code>br-int</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml218(para)
msgid ""
"Create mirror of <code>patch-tun</code> to <code>snooper0</code> (returns "
"UUID of mirror port)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml224(para)
msgid ""
"Profit. You can now see traffic on <code>patch-tun</code> by running "
"<placeholder-1/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml228(para)
msgid ""
"Clean up by clearing all mirrors on <code>br-int</code> and deleting the "
"dummy interface."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml237(para)
msgid ""
"On the integration bridge, networks are distinguished using internal VLANs "
"regardless of how the networking service defines them. This allows instances"
" on the same host to communicate directly without transiting the rest of the"
" virtual, or physical, network. These internal VLAN IDs are based on the "
"order they are created on the node and may vary between nodes. These IDs are"
" in no way related to the segmentation IDs used in the network definition "
"and on the physical wire."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml247(para)
msgid ""
"VLAN tags are translated between the external tag, defined in the network "
"settings, and internal tags in several places. On the <code>br-int</code>, "
"incoming packets from the <code>int-br-eth1</code> are translated from "
"external tags to internal tags. Other translations also happen on the other "
"bridges and will be discussed in those sections."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml253(title)
msgid ""
"To discover which internal VLAN tag is in use for a given external VLAN by "
"using the <placeholder-1/> command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml257(para)
msgid ""
"Find the external VLAN tag of the network you're interested in. This is the "
"<code>provider:segmentation_id</code> as returned by the networking service:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml271(para)
msgid ""
"Grep for the <code>provider:segmentation_id</code>, 2113 in this case, in "
"the output of <placeholder-1/>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml278(para)
msgid ""
"Here you can see packets received on port ID 1 with the VLAN tag 2113 are "
"modified to have the internal VLAN tag 7. Digging a little deeper, you can "
"confirm that port 1 is in fact <code>int-br-eth1</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml311(para)
msgid ""
"The next step depends on whether the virtual network is configured to use "
"802.1Q VLAN tags or GRE"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml316(para)
msgid ""
"VLAN-based networks exit the integration bridge via veth interface <code"
">int-br-eth1</code> and arrive on the bridge <code>br-eth1</code> on the "
"other member of the veth pair <code>phy-br-eth1</code>. Packets on this "
"interface arrive with internal VLAN tags and are translated to external tags"
" in the reverse of the process described above."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml327(para)
msgid ""
"Packets, now tagged with the external VLAN tag, then exit onto the physical "
"network via <code>eth1</code>. The Layer2 switch this interface is connected"
" to must be configured to accept traffic with the VLAN ID used. The next hop"
" for this packet must also be on the same layer-2 network."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml335(para)
msgid ""
"GRE-based networks are passed with <code>patch-tun</code> to the tunnel "
"bridge <code>br-tun</code> on interface <code>patch-int</code>. This bridge "
"also contains one port for each GRE tunnel peer, so one for each compute "
"node and network node in your network. The ports are named sequentially from"
" <code>gre-1</code> onward."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml343(para)
msgid ""
"Matching <code>gre-&lt;n&gt;</code> interfaces to tunnel endpoints is "
"possible by looking at the Open vSwitch state:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml352(para)
msgid ""
"In this case, <code>gre-1</code> is a tunnel from IP 10.10.128.21, which "
"should match a local interface on this node, to IP 10.10.128.16 on the "
"remote side."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml356(para)
msgid ""
"These tunnels use the regular routing tables on the host to route the "
"resulting GRE packet, so there is no requirement that GRE endpoints are all "
"on the same layer-2 network, unlike VLAN encapsulation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml361(para)
msgid ""
"All interfaces on the <code>br-tun</code> are internal to Open vSwitch. To "
"monitor traffic on them you need to set up a mirror port as described above "
"for <code>patch-tun</code> in the <code>br-int</code> bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml366(para)
msgid ""
"All translation of GRE tunnels to and from internal VLANs happens on this "
"bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml369(title)
msgid ""
"To discover which internal VLAN tag is in use for a GRE tunnel by using the "
"<placeholder-1/> command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml374(para)
msgid ""
"Find the <code>provider:segmentation_id</code> of the network you're "
"interested in. This is the same field used for the VLAN ID in VLAN-based "
"networks:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml387(para)
msgid ""
"Grep for 0x&lt;<code>provider:segmentation_id</code>&gt;, 0x3 in this case, "
"in the output of <placeholder-1/>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml397(para)
msgid ""
"Here, you see three flows related to this GRE tunnel. The first is the "
"translation from inbound packets with this tunnel ID to internal VLAN ID 1. "
"The second shows a unicast flow to output port 53 for packets destined for "
"MAC address fa:16:3e:a6:48:24. The third shows the translation from the "
"internal VLAN representation to the GRE tunnel ID flooded to all output "
"ports. For further details of the flow descriptions, see the man page for "
"<placeholder-1/>. As in the VLAN example above, numeric port IDs can be "
"matched with their named representations by examining the output of "
"<placeholder-2/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml419(para)
msgid ""
"The packet is then received on the network node. Note that any traffic to "
"the l3-agent or dhcp-agent will be visible only within their network "
"namespace. Watching any interfaces outside those namespaces, even those that"
" carry the network traffic, will only show broadcast packets like Address "
"Resolution Protocols (ARPs), but unicast traffic to the router or DHCP "
"address will not be seen. See the <xref linkend=\"dealing_with_netns\"/> "
"section below for detail on how to run commands within these namespaces."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml426(para)
msgid ""
"Alternatively, it is possible to configure VLAN-based networks to use "
"external routers rather than the l3-agent shown here, so long as the "
"external router is on the same VLAN."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml432(para)
msgid ""
"VLAN-based networks are received as tagged packets on a physical network "
"interface, <code>eth1</code> in this example. Just as on the compute node, "
"this interface is a member of the <code>br-eth1</code> bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml439(para)
msgid ""
"GRE-based networks will be passed to the tunnel bridge <code>br-tun</code>, "
"which behaves just like the GRE interfaces on the compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml446(para)
msgid ""
"Next, the packets from either input go through the integration bridge, again"
" just as on the compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml451(para)
msgid ""
"The packet then makes it to the l3-agent. This is actually another TAP "
"device within the router's network namespace. Router namespaces are named in"
" the form <code>qrouter-&lt;router-uuid&gt;</code>. Running <placeholder-1/>"
" within the namespace will show the TAP device name, qr-e6256f7d-31 in this "
"example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml465(para)
msgid ""
"The <code>qg-&lt;n&gt;</code> interface in the l3-agent router namespace "
"sends the packet on to its next hop through device <code>eth0</code> on the "
"external bridge <code>br-ex</code>. This bridge is constructed similarly to "
"<code>br-eth1</code> and may be inspected in the same way."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml473(para)
msgid ""
"This external bridge also includes a physical network interface, "
"<code>eth0</code> in this example, which finally lands the packet on the "
"external network destined for an external router or destination."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml480(para)
msgid ""
"DHCP agents running on OpenStack networks run in namespaces similar to the "
"l3-agents. DHCP namespaces are named <code>qdhcp-&lt;uuid&gt;</code> and "
"have a TAP device on the integration bridge. Debugging of DHCP issues "
"usually involves working inside this network namespace."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml490(title)
msgid "Finding a Failure in the Path"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml491(para)
msgid ""
"Use ping to quickly find where a failure exists in the network path. In an "
"instance, first see whether you can ping an external host, such as "
"google.com. If you can, then there shouldn't be a network problem at all."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml495(para)
msgid ""
"If you can't, try pinging the IP address of the compute node where the "
"instance is hosted. If you can ping this IP, then the problem is somewhere "
"between the compute node and that compute node's gateway."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml499(para)
msgid ""
"If you can't ping the IP address of the compute node, the problem is between"
" the instance and the compute node. This includes the bridge connecting the "
"compute node's main NIC with the vnet NIC of the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml503(para)
msgid ""
"One last test is to launch a second instance and see whether the two "
"instances can ping each other. If they can, the issue might be related to "
"the firewall on the compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml509(title)
msgid "tcpdump"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml510(para)
msgid ""
"One great, although very in-depth, way of troubleshooting network issues is "
"to use <placeholder-1/>. We recommended using <placeholder-2/> at several "
"points along the network path to correlate where a problem might be. If you "
"prefer working with a GUI, either live or by using a <placeholder-3/> "
"capture, do also check out <link title=\"Wireshark\" "
"href=\"http://www.wireshark.org/\">Wireshark</link> "
"(http://www.wireshark.org/)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml518(para)
msgid "For example, run the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml520(code)
msgid ""
"tcpdump -i any -n -v 'icmp[icmptype] = icmp-echoreply or icmp[icmptype] = "
"icmp-echo'"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml523(para)
msgid "Run this on the command line of the following areas:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml527(para)
msgid "An external server outside of the cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml530(para)
msgid "A compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml533(para)
msgid "An instance running on that compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml536(para)
msgid "In this example, these locations have the following IP addresses:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml546(para)
msgid ""
"Next, open a new shell to the instance and then ping the external host where"
" <placeholder-1/> is running. If the network path to the external server and"
" back is fully functional, you see something like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml550(para)
msgid "On the external server:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml556(para)
msgid "On the compute node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml569(para)
msgid "On the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml572(para)
msgid ""
"Here, the external server received the ping request and sent a ping reply. "
"On the compute node, you can see that both the ping and ping reply "
"successfully passed through. You might also see duplicate packets on the "
"compute node, as seen above, because <placeholder-1/> captured the packet on"
" both the bridge and outgoing interface."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml581(para)
msgid ""
"Through nova-network, OpenStack Compute automatically manages iptables, "
"including forwarding packets to and from instances on a compute node, "
"forwarding floating IP traffic, and managing security group rules."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml585(para)
msgid "Run the following command to view the current iptables configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml588(para)
msgid ""
"If you modify the configuration, it reverts the next time you restart nova-"
"network. You must use OpenStack to manage iptables."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml594(title)
msgid "Network Configuration in the Database for Nova-Network"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml595(para)
msgid ""
"With nova-network, the nova database table contains a few tables with "
"networking information:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml599(para)
msgid ""
"fixed_ips: contains each possible IP address for the subnet(s) added to "
"Compute. This table is related to the instances table by way of the "
"fixed_ips.instance_uuid column."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml605(para)
msgid ""
"floating_ips: contains each floating IP address that was added to Compute. "
"This table is related to the fixed_ips table by way of the "
"floating_ips.fixed_ip_id column."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml610(para)
msgid ""
"instances: not entirely network specific, but it contains information about "
"the instance that is utilizing the fixed_ip and optional floating_ip."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml616(para)
msgid ""
"From these tables, you can see that a floating IP is technically never "
"directly related to an instance, it must always go through a fixed IP."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml620(title)
msgid "Manually Deassociating a Floating IP"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml621(para)
msgid ""
"Sometimes an instance is terminated but the floating IP was not correctly "
"de-associated from that instance. Because the database is in an inconsistent"
" state, the usual tools to deassociate the IP no longer work. To fix this, "
"you must manually update the database."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml627(para)
msgid "First, find the UUID of the instance in question:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml631(para)
msgid "Next, find the fixed IP entry for that UUID:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml634(para)
msgid "You can now get the related floating IP entry:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml638(para)
msgid "And finally, you can deassociate the floating IP:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml642(para)
msgid "You can optionally also deallocate the IP from the user's pool:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml649(title)
msgid "Debugging DHCP Issues with Nova-Network"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml650(para)
msgid ""
"One common networking problem is that an instance boots successfully but is "
"not reachable because it failed to obtain an IP address from dnsmasq, which "
"is the DHCP server that is launched by the nova-network service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml655(para)
msgid ""
"The simplest way to identify that this is the problem with your instance is "
"to look at the console output of your instance. If DHCP failed, you can "
"retrieve the console log by doing:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml660(para)
msgid ""
"If your instance failed to obtain an IP through DHCP, some messages should "
"appear in the console. For example, for the Cirros image, you see output "
"that looks like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml673(para)
msgid ""
"After you establish that the instance booted properly, the task is to figure"
" out where the failure is."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml675(para)
msgid ""
"A DHCP problem might be caused by a misbehaving dnsmasq process. First, "
"debug by checking logs and then restart the dnsmasq processes only for that "
"project (tenant). In VLAN mode there is a dnsmasq process for each tenant. "
"Once you have restarted targeted dnsmasq processes, the simplest way to rule"
" out dnsmasq causes is to kill all of the dnsmasq processes on the machine, "
"and restart nova-network. As a last resort, do this as root:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml686(para)
msgid ""
"Use openstack-nova-network on RHEL/CentOS/Fedora but nova-network on "
"Ubuntu/Debian."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml687(para)
msgid ""
"Several minutes after nova-network is restarted, you should see new dnsmasq "
"processes running:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml699(para)
msgid ""
"If your instances are still not able to obtain IP addresses, the next thing "
"to check is whether dnsmasq is seeing the DHCP requests from the instance. "
"On the machine that is running the dnsmasq process, which is the compute "
"host if running in multi-host mode, look at /var/log/syslog to see the "
"dnsmasq output. If dnsmasq is seeing the request properly and handing out an"
" IP, the output looks like this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml712(para)
msgid ""
"If you do not see the DHCPDISCOVER, a problem exists with the packet getting"
" from the instance to the machine running dnsmasq. If you see all of the "
"preceding output and your instances are still not able to obtain IP "
"addresses, then the packet is able to get from the instance to the host "
"running dnsmasq, but it is not able to make the return trip."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml719(para)
msgid "You might also see a message such as this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml722(para)
msgid ""
"This may be a dnsmasq and/or nova-network related issue. (For the example "
"above, the problem happened to be that dnsmasq did not have any more IP "
"addresses to give away because there were no more fixed IPs available in the"
" OpenStack Compute database)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml727(para)
msgid ""
"If there's a suspicious-looking dnsmasq log message, take a look at the "
"command-line arguments to the dnsmasq processes to see if they look correct."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml731(para)
msgid "The output looks something like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml745(para)
msgid ""
"The output shows three different dnsmasq processes. The dnsmasq process that"
" has the DHCP subnet range of 192.168.122.0 belongs to libvirt and can be "
"ignored. The other two dnsmasq processes belong to nova-network. The two "
"processes are actually related—one is simply the parent process of the "
"other. The arguments of the dnsmasq processes should correspond to the "
"details you configured nova-network with."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml753(para)
msgid ""
"If the problem does not seem to be related to dnsmasq itself, at this point "
"use <code>tcpdump</code> on the interfaces to determine where the packets "
"are getting lost."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml756(para)
msgid ""
"DHCP traffic uses UDP. The client sends from port 68 to port 67 on the "
"server. Try to boot a new instance and then systematically listen on the "
"NICs until you identify the one that isn't seeing the traffic. To use "
"<code>tcpdump</code> to listen to ports 67 and 68 on br100, you would do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml762(para)
msgid ""
"You should be doing sanity checks on the interfaces using command such as "
"<code>ip a</code> and <code>brctl show</code> to ensure that the interfaces "
"are actually up and configured the way that you think that they are."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml769(title)
msgid "Debugging DNS Issues"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml770(para)
msgid ""
"If you are able to use SSH to log into an instance, but it takes a very long"
" time (on the order of a minute) to get a prompt, then you might have a DNS "
"issue. The reason a DNS issue can cause this problem is that the SSH server "
"does a reverse DNS lookup on the IP address that you are connecting from. If"
" DNS lookup isn't working on your instances, then you must wait for the DNS "
"reverse lookup timeout to occur for the SSH login process to complete."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml779(para)
msgid ""
"When debugging DNS issues, start by making sure that the host where the "
"dnsmasq process for that instance runs is able to correctly resolve. If the "
"host cannot resolve, then the instances won't be able to either."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml783(para)
msgid ""
"A quick way to check whether DNS is working is to resolve a hostname inside "
"your instance by using the <code>host</code> command. If DNS is working, you"
" should see:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml791(para)
msgid ""
"If you're running the Cirros image, it doesn't have the \"host\" program "
"installed, in which case you can use ping to try to access a machine by "
"hostname to see whether it resolves. If DNS is working, the first line of "
"ping would be:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml798(para)
msgid ""
"If the instance fails to resolve the hostname, you have a DNS problem. For "
"example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml802(para)
msgid ""
"In an OpenStack cloud, the dnsmasq process acts as the DNS server for the "
"instances in addition to acting as the DHCP server. A misbehaving dnsmasq "
"process may be the source of DNS-related issues inside the instance. As "
"mentioned in the previous section, the simplest way to rule out a "
"misbehaving dnsmasq process is to kill all the dnsmasq processes on the "
"machine and restart nova-network. However, be aware that this command "
"affects everyone running instances on this node, including tenants that have"
" not seen the issue. As a last resort, as root:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml815(para)
msgid "After the dnsmasq processes start again, check whether DNS is working."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml817(para)
msgid ""
"If restarting the dnsmasq process doesn't fix the issue, you might need to "
"use tcpdump to look at the packets to trace where the failure is. The DNS "
"server listens on UDP port 53. You should see the DNS request on the bridge "
"(such as, br100) of your compute node. Let's say you start listening with "
"tcpdump on the compute node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml826(para)
msgid ""
"Then, if you use SSH to log into your instance and try <code>ping "
"openstack.org</code>, you should see something like:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml836(title)
msgid "Troubleshooting Open vSwitch"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml837(para)
msgid ""
"Open vSwitch as used in the previous OpenStack Networking Service examples "
"is a full-featured multilayer virtual switch licensed under the open source "
"Apache 2.0 license. Full documentation can be found at the project's website"
" at <link href=\"http://openvswitch.org/\">http://openvswitch.org/</link>. "
"In practice, given the configuration above, the most common issues are being"
" sure that the required bridges (<code>br-int</code>, <code>br-tun</code>, "
"<code>br-ex</code>, etc...) exist and have the proper ports connected to "
"them."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml846(para)
msgid ""
"The Open vSwitch driver should and usually does manage this automatically, "
"but it is useful to know how to do this by hand with the <placeholder-1/> "
"command. This command has many more subcommands than we will use here; see "
"the man page or use <placeholder-2/> for the full listing."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml852(para)
msgid ""
"To list the bridges on a system use <placeholder-1/>. This example shows a "
"compute node that has an internal bridge and a tunnel bridge. VLAN networks "
"are trunked through the <code>eth1</code> network interface:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml863(para)
msgid ""
"Working from the physical interface inwards, we can see the chain of ports "
"and bridges. First, the bridge <code>eth1-br</code>, which contains the "
"physical network interface eth1 and the virtual interface <code>phy-"
"eth1-br</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml874(para)
msgid ""
"Next, the internal bridge, <code>br-int</code>, contains <code>int-"
"eth1-br</code>, which pairs with <code>phy-eth1-br</code> to connect to the "
"physical network shown in the previous bridge, <code>patch-tun</code>, which"
" is used to connect to the GRE tunnel bridge and the TAP devices that "
"connect to the instances currently running on the system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml889(para)
msgid ""
"The tunnel bridge, <code>br-tun</code>, contains the <code>patch-int</code> "
"interface and <code>gre-&lt;N&gt;</code> interfaces for each peer it "
"connects to via GRE, one for each compute and network node in your cluster."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml904(para)
msgid ""
"If any of these links are missing or incorrect, it suggests a configuration "
"error. Bridges can be added with <placeholder-1/> and ports can be added to "
"bridges with <placeholder-2/>. While running these by hand can be useful "
"debugging, it is imperative that manual changes that you intend to keep be "
"reflected back into your configuration files."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml913(title)
msgid "Dealing with Network Namespaces"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml914(para)
msgid ""
"Linux network namespaces are a kernel feature the networking service uses to"
" support multiple isolated layer-2 networks with overlapping IP address "
"ranges. The support may be disabled, but it is on by default. If it is "
"enabled in your environment, your network nodes will run their dhcp-agents "
"and l3-agents in isolated namespaces. Network interfaces and traffic on "
"those interfaces will not be visible in the default namespace."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml922(para)
msgid "To see whether you are using namespaces, run <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml931(para)
msgid ""
"L3-agent router namespaces are named qrouter-&lt;router_uuid&gt;, and dhcp-"
"agent name spaces are named qdhcp-&lt;net_uuid&gt;. This output shows a "
"network node with four networks running dhcp-agents, one of which is also "
"running an l3-agent router. It's important to know which network you need to"
" be working in. A list of existing networks and their UUIDs can be obtained "
"buy running <placeholder-1/> with administrative credentials."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml937(para)
msgid ""
"Once you've determined which namespace you need to work in, you can use any "
"of the debugging tools mention earlier by prefixing the command with "
"<placeholder-1/>. For example, to see what network interfaces exist in the "
"first qdhcp namespace returned above, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml955(para)
msgid ""
"From this you see that the DHCP server on that network is using the "
"tape6256f7d-31 device and has an IP address 10.0.1.100. Seeing the address "
"169.254.169.254, you can also see that the dhcp-agent is running a metadata-"
"proxy service. Any of the commands mentioned previously in this chapter can "
"be run in the same way. It is also possible to run a shell, such as "
"<placeholder-1/>, and have an interactive session within the namespace. In "
"the latter case, exiting the shell returns you to the top-level default "
"namespace."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml967(para)
msgid ""
"The authors have spent too long a time looking at packet dumps in order to "
"distill this information for you. We trust that, following the methods "
"outlined in this chapter, you will have an easier time! Aside from working "
"with the tools and steps above, don't forget that sometimes an extra pair of"
" eyes goes a long way to assist."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml15(title)
msgid "Designing for Cloud Controllers and Cloud Management"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml16(para)
msgid ""
"OpenStack is designed to be massively horizontally scalable, which allows "
"all services to be distributed widely. However, to simplify this guide we "
"have decided to discuss services of a more central nature, using the concept"
" of a <emphasis>cloud controller</emphasis>. A cloud controller is just a "
"conceptual simplification. In the real world you design an architecture for "
"your cloud controller that enables high availability so that if any node "
"fails, another can take over the required tasks. In reality, cloud "
"controller tasks are spread out across more than a single node."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml26(para)
msgid ""
"The cloud controller provides the central management system for OpenStack "
"deployments. Typically, the cloud controller manages authentication and "
"sends messaging to all the systems through a message queue."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml30(para)
msgid ""
"For many deployments, the cloud controller is a single node. However, to "
"have high availability, you have to take a few considerations into account, "
"which we'll cover in this chapter."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml34(para)
msgid "The cloud controller manages the following services for the cloud:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml38(para)
msgid ""
"Databases (tracks current information about users and instances, for "
"example, in a database, typically one database instance managed per service)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml43(para)
msgid ""
"Message queue services (all AMQP—Advanced Message Queue Protocol—messages "
"for services are received and sent according to the queue broker)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml48(para)
msgid "Conductor services (proxy requests to a database)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml52(para)
msgid ""
"Authentication and authorization for identity management (indicates which "
"users can do what actions on certain cloud resources; quota management is "
"spread out among services, however)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml58(para)
msgid ""
"Image-management services (stores and serves images with metadata on each, "
"for launching in the cloud)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml62(para)
msgid ""
"Scheduling services (indicates which resources to use first; for example, "
"spreading out where instances are launched based on an algorithm)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml67(para)
msgid ""
"User dashboard (provides a web-based front-end for users to consume "
"OpenStack cloud services)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml71(para)
msgid ""
"API endpoints (offers each service's REST API access, where the API endpoint"
" catalog is managed by the identity service)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml76(para)
msgid ""
"For our example, the cloud controller has a collection of "
"<code>nova-*</code> components that represent the global state of the cloud,"
" talks to services such as authentication, maintains information about the "
"cloud in a database, communicates to all compute nodes and storage "
"<glossterm>worker</glossterm>s through a queue, and provides API access. "
"Each service running on a designated cloud controller may be broken out into"
" separate nodes for scalability or availability."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml84(para)
msgid ""
"As another example, you could use pairs of servers for a collective cloud "
"controller—one active, one standby—for redundant nodes providing a given set"
" of related services, such as:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml89(para)
msgid ""
"Frontend web for API requests, the scheduler for choosing which compute node"
" to boot an instance on, identity services, and the dashboard"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml94(para)
msgid "Database and message queue server (such as MySQL, RabbitMQ)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml98(para)
msgid "Image Service for the image management"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml101(para)
msgid ""
"Now that you see the myriad designs for controlling your cloud, read more "
"about the further considerations to help with your design decisions."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml104(title)
msgid "Hardware Considerations"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml105(para)
msgid ""
"A cloud controller's hardware can be the same as a compute node, though you "
"may want to further specify based on the size and type of cloud that you "
"run."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml108(para)
msgid ""
"It's also possible to use virtual machines for all or some of the services "
"that the cloud controller manages, such as the message queuing. In this "
"guide, we assume that all services are running directly on the cloud "
"controller."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml113(para)
msgid ""
"<xref linkend=\"controller-hardware-sizing\"/> contains common "
"considerations to review when sizing hardware for the cloud controller "
"design:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml117(caption)
msgid "Cloud Controller Hardware Sizing Considerations"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml122(th)
msgid "Consideration"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml123(th)
msgid "Ramification"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml129(para)
msgid "How many instances will run at once?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml132(para)
msgid ""
"Size your database server accordingly, and scale out beyond one cloud "
"controller if many instances will report status at the same time and "
"scheduling where a new instance starts up needs computing power."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml141(para)
msgid "How many compute nodes will run at once?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml144(para)
msgid ""
"Ensure that your messaging queue handles requests successfully and size "
"accordingly."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml150(para)
msgid "How many users will access the API?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml153(para)
msgid ""
"If many users will make multiple requests, make sure that the CPU load for "
"the cloud controller can handle it."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml159(para)
msgid ""
"How many users will access the <glossterm>dashboard</glossterm> versus the "
"REST API directly?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml163(para)
msgid ""
"The dashboard makes many requests, even more than the API access, so add "
"even more CPU if your dashboard is the main interface for your users."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml170(para)
msgid ""
"How many <code>nova-api</code> services do you run at once for your cloud?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml174(para)
msgid "You need to size the controller with a core per service."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml179(para)
msgid "How long does a single instance run?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml182(para)
msgid ""
"Starting instances and deleting instances is demanding on the compute node "
"but also demanding on the controller node because of all the API queries and"
" scheduling needs."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml190(para)
msgid "Does your authentication system also verify externally?"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml193(para)
msgid ""
"External systems such as, LDAP or <glossterm>Active Directory</glossterm> "
"require network connectivity between the cloud controller and an external "
"authentication system. Also ensure that the cloud controller has the CPU "
"power to keep up with requests."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml206(title)
msgid "Separation of Services"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml207(para)
msgid ""
"While our example contains all central services in a single location, it is "
"possible and indeed often a good idea to separate services onto different "
"physical servers. The following is a list of deployment scenarios we've "
"seen, and their justifications."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml218(para)
msgid ""
"Run <code>glance-*</code> servers on the <code>swift-proxy</code> server"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml222(para)
msgid ""
"This deployment felt that the spare I/O on the Object Storage proxy server "
"was sufficient, and that the Image Delivery portion of glance benefited from"
" being on physical hardware and having good connectivity to the Object "
"Storage backend it was using."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml234(para)
msgid "Run a central dedicated database server"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml237(para)
msgid ""
"This deployment used a central dedicated server to provide the databases for"
" all services. This approach simplified operations by isolating database "
"server updates and allowed for the simple creation of slave database servers"
" for failover."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml247(para)
msgid "Run one VM per service"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml249(para)
msgid ""
"This deployment ran central services on a set of servers running KVM. A "
"dedicated VM was created for each service (nova-scheduler, rabbitmq, "
"database, etc). This assisted the deployment with scaling because "
"administrators could tune the resources given to each virtual machine based "
"on the load it received (something that was not well understood during "
"installation)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml262(para)
msgid "Use an external load balancer"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml265(para)
msgid ""
"This deployment had an expensive hardware load balancer in its organization."
" It ran multiple <code>nova-api</code> and <code>swift-proxy</code> servers "
"on different physical servers and used the load balancer to switch between "
"them."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml277(para)
msgid ""
"One choice that always comes up is whether to virtualize. Some services, "
"such as <code>nova-compute</code>, <code>swift-proxy</code> and <code>swift-"
"object</code> servers, should not be virtualized. However, control servers "
"can often be happily virtualized—the performance penalty can usually be "
"offset by simply running more of the service."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml286(para)
msgid ""
"OpenStack Compute uses a SQL database to store and retrieve stateful "
"information. MySQL is the popular database choice in the OpenStack "
"community."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml289(para)
msgid ""
"Loss of the database leads to errors. As a result, we recommend that you "
"cluster your database to make it failure tolerant. Configuring and "
"maintaining a database cluster is done outside OpenStack and is determined "
"by the database software you choose to use in your cloud environment. "
"MySQL/Galera is a popular option for MySQL-based databases."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml298(title)
msgid "Message Queue"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml299(para)
msgid ""
"Most OpenStack services communicate with each other using the Message Queue."
" For example, Compute communicates to block storage services and networking "
"services through the message queue. Also, you can optionally enable "
"notifications for any service. RabbitMQ, Qpid, and 0mq are all popular "
"choices for a message-queue service. In general, if the message queue fails "
"or becomes inaccessible, the cluster grinds to a halt and ends up in a "
"\"read only\" state, with information stuck at the point where the last "
"message was sent. Accordingly, we recommend that you cluster the message "
"queue. Be aware that clustered message queues can be a pain point for many "
"OpenStack deployments. While RabbitMQ has native clustering support, there "
"have been reports of issues when running it at a large scale. While other "
"queuing solutions are available, such as 0mq and Qpid, 0mq does not offer "
"stateful queues. Qpid is the messaging system of choice for Red Hat and its "
"derivatives. Qpid does not have native clustering capabilities and requires "
"a supplemental service such as Pacemaker or Corsync. For your message queue,"
" you need to determine what level of data loss you are comfortable with and "
"whether to use an OpenStack project's ability to retry multiple MQ hosts in "
"the event of a failure, such as using Compute's ability to do so."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml322(title)
msgid "Conductor Services"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml323(para)
msgid ""
"In the previous version of OpenStack, all nova-compute services required "
"direct access to the database hosted on the cloud controller. This was "
"problematic for two reasons: security and performance. With regard to "
"security, if a compute node is compromised, the attacker inherently has "
"access to the database. With regard to performance, nova-compute calls to "
"the database are single-threaded and blocking. This creates a performance "
"bottleneck because database requests are fulfilled serially rather than in "
"parallel."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml333(para)
msgid ""
"The conductor service resolves both of these issues by acting as a proxy for"
" the nova-compute service. Now, instead of nova-compute directly accessing "
"the database, it contacts the nova-conductor service and nova-conductor "
"accesses the database on nova-compute's behalf. Since nova-compute no longer"
" has direct access to the database, the security issue is resolved. "
"Additionally, nova-conductor is a nonblocking service, so requests from all "
"compute nodes are fulfilled in parallel."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml344(para)
msgid ""
"If you are using nova-network and multi-host networking in your cloud "
"environment, nova-compute still requires direct access to the database."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml348(para)
msgid ""
"The nova-conductor service is horizontally scalable. To make nova-conductor "
"highly available and fault tolerant, just launch more instances of the <code"
">nova-conductor</code> process, either on the same server or across multiple"
" servers."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml356(para)
msgid ""
"All public access, whether direct, through a command-line client, or through"
" the web-based dashboard, uses the API service. Find the API reference at "
"<link href=\"http://api.openstack.org/\">http://api.openstack.org/</link>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml361(para)
msgid ""
"You must choose whether you want to support the Amazon EC2 compatibility "
"APIs, or just the OpenStack APIs. One issue you might encounter when running"
" both APIs is an inconsistent experience when referring to images and "
"instances."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml366(para)
msgid ""
"For example, the EC2 API refers to instances using IDs that contain "
"hexadecimal, whereas the OpenStack API uses names and digits. Similarly, the"
" EC2 API tends to rely on DNS aliases for contacting virtual machines, as "
"opposed to OpenStack, which typically lists IP addresses."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml371(para)
msgid ""
"If OpenStack is not set up in the right way, it is simple to have scenarios "
"in which users are unable to contact their instances due to having only an "
"incorrect DNS alias. Despite this, EC2 compatibility can assist users "
"migrating to your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml376(para)
msgid ""
"As with databases and message queues, having more than one <glossterm>API "
"server</glossterm> is a good thing. Traditional HTTP load-balancing "
"techniques can be used to achieve a highly available <code>nova-api</code> "
"service."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml383(title)
msgid "Extensions"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml384(para)
msgid ""
"The <link title=\"API Specifications\" href=\"http://docs.openstack.org/api"
"/api-specs.html\">API Specifications</link> (http://docs.openstack.org/api"
"/api-specs.html) define the core actions, capabilities, and mediatypes of "
"the OpenStack API. A client can always depend on the availability of this "
"core API and implementers are always required to support it in its entirety."
" Requiring strict adherence to the core API allows clients to rely upon a "
"minimal level of functionality when interacting with multiple "
"implementations of the same API."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml395(para)
msgid ""
"The OpenStack Compute API is extensible. An extension adds capabilities to "
"an API beyond those defined in the core. The introduction of new features, "
"MIME types, actions, states, headers, parameters, and resources can all be "
"accomplished by means of extensions to the core API. This allows the "
"introduction of new features in the API without requiring a version change "
"and allows the introduction of vendor-specific niche functionality."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml407(title)
msgid "Scheduling"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml408(para)
msgid ""
"The scheduling services are responsible for determining the compute or "
"storage node where a virtual machine or block storage volume should be "
"created. The scheduling services receive creation requests for these "
"resources from the message queue and then begin the process of determining "
"the appropriate node where the resource should reside. This process is done "
"by applying a series of user-configurable filters against the available "
"collection of nodes."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml417(para)
msgid ""
"There are currently two schedulers: nova-scheduler for virtual machines and "
"cinder-scheduler for block storage volumes. Both schedulers are able to "
"scale horizontally, so for high-availability purposes, or for very large or "
"high-schedule-frequency installations, you should consider running multiple "
"instances of each scheduler. The schedulers all listen to the shared message"
" queue, so no special load balancing is required."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml428(para)
msgid ""
"The OpenStack Image Service consists of two parts—<code>glance-api</code> "
"and <code>glance-registry</code>. The former is responsible for the delivery"
" of images; the compute node uses it to download images from the back-end. "
"The latter maintains the metadata information associated with virtual "
"machine images and requires a database."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml434(para)
msgid ""
"The <code>glance-api</code> part is an abstraction layer that allows a "
"choice of back-end. Currently, it supports:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml439(para)
msgid "OpenStack Object Storage: Allows you to store images as objects."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml443(para)
msgid ""
"File system: Uses any traditional file system to store the images as files."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml447(para)
msgid "S3: Allows you to fetch images from Amazon S3."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml450(para)
msgid ""
"HTTP: Allows you to fetch images from a web server. You cannot write images "
"by using this mode."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml455(para)
msgid ""
"If you have an OpenStack Object Storage service, we recommend using this as "
"a scalable place to store your images. You can also use a file system with "
"sufficient performance or Amazon S3—unless you do not need the ability to "
"upload new images through OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml461(title)
msgid "Dashboard"
msgstr "Vezérlőpult"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml462(para)
msgid ""
"The OpenStack dashboard (horizon) provides a web-based user interface to the"
" various OpenStack components. The dashboard includes an end-user area for "
"users to manage their virtual infrastructure and an admin area for cloud "
"operators to manage the OpenStack environment as a whole."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml468(para)
msgid ""
"The dashboard is implemented as a Python web application that normally runs "
"in <glossterm>Apache</glossterm><code>httpd</code>. Therefore, you may treat"
" it the same as any other web application, provided it can reach the API "
"servers (including their admin endpoints) over the network."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml476(title)
msgid "Authentication and Authorization"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml477(para)
msgid ""
"The concepts supporting OpenStack's authentication and authorization are "
"derived from well-understood and widely used systems of a similar nature. "
"Users have credentials they can use to authenticate, and they can be a "
"member of one or more groups (known as projects or tenants interchangeably)."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml483(para)
msgid ""
"For example, a cloud administrator might be able to list all instances in "
"the cloud, whereas a user can see only those in his current group. Resources"
" quotas, such as the number of cores that can be used, disk space, and so "
"on, are associated with a project."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml488(para)
msgid ""
"The OpenStack Identity Service (keystone) is the point that provides the "
"authentication decisions and user attribute information, which is then used "
"by the other OpenStack services to perform authorization. Policy is set in "
"the <filename>policy.json</filename> file. For information on how to "
"configure these, see <xref linkend=\"projects_users\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml495(para)
msgid ""
"The Identity Service supports different plug-ins for authentication "
"decisions and identity storage. Examples of these plug-ins include:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml500(para)
msgid "In-memory key-value Store (a simplified internal storage structure)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml504(para)
msgid "SQL database (such as MySQL or PostgreSQL)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml508(para)
msgid "PAM (Pluggable Authentication Module)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml511(para)
msgid "LDAP (such as OpenLDAP or Microsoft's Active Directory)"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml515(para)
msgid ""
"Many deployments use the SQL database, however LDAP is also a popular choice"
" for those with existing authentication infrastructure that needs to be "
"integrated."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml522(title)
msgid "Network Considerations"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml523(para)
msgid ""
"Because the cloud controller handles so many different services, it must be "
"able to handle the amount of traffic that hits it. For example, if you "
"choose to host the OpenStack Imaging Service on the cloud controller, the "
"cloud controller should be able to support the transferring of the images at"
" an acceptable speed."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml529(para)
msgid ""
"As another example, if you choose to use single-host networking where the "
"cloud controller is the network gateway for all instances, then the cloud "
"controller must support the total amount of traffic that travels between "
"your cloud and the public Internet."
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml534(para)
msgid ""
"We recommend that you use a fast NIC, such as 10 GB. You can also choose to "
"use two 10 GB NICs and bond them together. While you might not be able to "
"get a full bonded 20 GB speed, different transmission streams use different "
"NICs. For example, if the cloud controller transfers two images, each image "
"uses a different NIC and gets a full 10 GB of bandwidth."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_projects_users.xml70(None)
msgid ""
"@@image: 'figures/horizon-add-project.png'; "
"md5=59da13e5f88d090b204a8de5963616e7"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_projects_users.xml669(None)
msgid ""
"@@image: 'figures/horizon-user-project.png'; "
"md5=73cb16964f410444bb8e27b694d2afd1"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml14(title)
msgid "Managing Projects and Users"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml15(para)
msgid ""
"An OpenStack cloud does not have much value without users. This chapter "
"covers topics that relate to managing users, projects, and quotas. This "
"chapter describes users and projects as described by version 2 of the "
"OpenStack Identity API."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml20(para)
msgid ""
"While version 3 of the Identity API is available, the client tools do not "
"yet implement those calls and most OpenStack clouds are still implementing "
"Identity API v2.0."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml24(title)
msgid "Projects or Tenants?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml25(para)
msgid ""
"In OpenStack user interfaces and documentation, a group of users is referred"
" to as a <glossterm>project</glossterm> or <glossterm>tenant</glossterm>. "
"These terms are interchangeable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml28(para)
msgid ""
"The initial implementation of the OpenStack Compute Service (nova) had its "
"own authentication system and used the term <literal>project</literal>. When"
" authentication moved into the OpenStack Identity Service (keystone) "
"project, it used the term <literal>tenant</literal> to refer to a group of "
"users. Because of this legacy, some of the OpenStack tools refer to projects"
" and some refer to tenants."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml35(para)
msgid ""
"This guide uses the term <literal>project</literal>, unless an example shows"
" interaction with a tool that uses the term <literal>tenant</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml40(title)
msgid "Managing Projects"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml41(para)
msgid ""
"Users must be associated with at least one project, though they may belong "
"to many. Therefore, you should add at least one project before adding users."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml45(title)
msgid "Adding Projects"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml46(para)
msgid "To create a project through the OpenStack dashboard:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml49(para)
msgid "Log in as an administrative user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml52(para)
msgid "Select the <guilabel>Admin</guilabel> tab in the left navigation bar."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml55(para)
msgid "Under Identity Panel, click <guilabel>Projects</guilabel>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml58(para)
msgid "Click the <guibutton>Create Project</guibutton> button."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml61(para)
msgid ""
"You are prompted for a project name and an optional, but recommended, "
"description. Select the check box at the bottom of the form to enable this "
"project. By default, it is enabled, which is shown in <xref linkend"
"=\"horizon-add-project\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml65(title)
msgid "Dashboard's Create Project form"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml74(para)
msgid ""
"It is also possible to add project members and adjust the project quotas. "
"We'll discuss those actions later, but in practice it can be quite "
"convenient to deal with all these operations at one time."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml77(para)
msgid ""
"To add a project through the command line, you must use the keystone "
"utility, which uses \"tenant\" in place of \"project\":"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml80(para)
msgid ""
"This command creates a project named \"demo.\" Optionally, you can add a "
"description string by appending <code>--description <replaceable>tenant-"
"description</replaceable></code>, which can be very useful. You can also "
"create a group in a disabled state by appending <code>--enabled false</code>"
" to the command. By default, projects are created in an enabled state."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml89(title)
msgid "Quotas"
msgstr "Kvóták"

#: ./doc/openstack-ops/ch_ops_projects_users.xml90(para)
msgid ""
"To prevent system capacities from being exhausted without notification, you "
"can set up <glossterm baseform=\"quota\">quotas</glossterm>. Quotas are "
"operational limits. For example, the number of gigabytes allowed per tenant "
"can be controlled to ensure that a single tenant cannot consume all of the "
"disk space. Quotas are currently enforced at the tenant (or project) level, "
"rather than by user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml97(para)
msgid ""
"Because without sensible quotas a single tenant could use up all the "
"available resources, default quotas are shipped with OpenStack. You should "
"pay attention to what quota settings make sense for your hardware "
"capabilities."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml101(para)
msgid ""
"Using the command-line interface, you can manage quotas for the OpenStack "
"Compute Service and the Block Storage Service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml103(para)
msgid ""
"Typically, default values are changed because a tenant requires more than "
"the OpenStack default of 10 volumes per tenant, or more than the OpenStack "
"default of 1 TB of disk space on a compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml107(para)
msgid "To view all tenants, run: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml122(title)
msgid "Set Image Quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml123(para)
msgid ""
"OpenStack Havana introduced a basic quota feature for the Image service, so "
"you can now restrict a project's image storage by total number of bytes. "
"Currently, this quota is applied cloud-wide, so if you were to set an Image "
"quota limit of 5 GB, then all projects in your cloud will be able to store "
"only 5 GB of images and snapshots."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml127(para)
msgid ""
"To enable this feature, edit the <filename>/etc/glance/glance-"
"api.conf</filename> file, and under the [DEFAULT] section, add:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml131(para)
msgid "For example, to restrict a project's image storage to 5 GB, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml134(para)
msgid ""
"In the Icehouse release, there is a configuration option in <filename"
">glance-api.conf</filename> that limits the number of members allowed per "
"image, called <code>image_member_quota</code>, set to 128 by default. That "
"setting is a different quota from the storage quota."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml141(title)
msgid "Set Compute Service Quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml142(para)
msgid ""
"As an administrative user, you can update the Compute Service quotas for an "
"existing tenant, as well as update the quota defaults for a new tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml146(caption)
msgid "Compute Quota Descriptions"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml152(th)
msgid "Quota"
msgstr "Kvóta"

#: ./doc/openstack-ops/ch_ops_projects_users.xml154(th)
#: ./doc/openstack-ops/ch_ops_projects_users.xml494(td)
msgid "Property Name"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml160(para)
msgid "Fixed IPs"
msgstr "Fix IP-k"

#: ./doc/openstack-ops/ch_ops_projects_users.xml163(para)
msgid ""
"Number of fixed IP addresses allowed per tenant. This number must be equal "
"to or greater than the number of allowed instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml169(systemitem)
msgid "fixed-ips"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml178(para)
msgid "Number of floating IP addresses allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml182(systemitem)
msgid "floating-ips"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml188(para)
msgid "Injected File Content Bytes"
msgstr "Beszúrt fájl tartalom bájtok"

#: ./doc/openstack-ops/ch_ops_projects_users.xml191(para)
msgid "Number of content bytes allowed per injected file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml195(systemitem)
msgid "injected-file-content-bytes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml201(para)
msgid "Injected File Path Bytes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml204(para)
msgid "Number of bytes allowed per injected file path."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml208(systemitem)
msgid "injected-file-path-bytes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml214(para)
msgid "Injected Files"
msgstr "Beszúrt fájlok"

#: ./doc/openstack-ops/ch_ops_projects_users.xml217(para)
msgid "Number of injected files allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml221(systemitem)
msgid "injected-files"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml230(para)
msgid "Number of instances allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml234(systemitem)
msgid "instances"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml240(para)
msgid "Key Pairs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml243(para)
msgid "Number of key pairs allowed per user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml247(systemitem)
msgid "key-pairs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml253(para)
msgid "Metadata Items"
msgstr "Metaadat elemek"

#: ./doc/openstack-ops/ch_ops_projects_users.xml256(para)
msgid "Number of metadata items allowed per instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml260(systemitem)
msgid "metadata-items"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml266(para)
msgid "RAM"
msgstr "RAM"

#: ./doc/openstack-ops/ch_ops_projects_users.xml269(para)
msgid "Megabytes of instance RAM allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml273(systemitem)
msgid "ram"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml279(para)
msgid "Security Group Rules"
msgstr "Biztonsági csoport szabályok"

#: ./doc/openstack-ops/ch_ops_projects_users.xml282(para)
msgid "Number of rules per security group."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml286(systemitem)
msgid "security-group-rules"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml295(para)
msgid "Number of security groups per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml299(systemitem)
msgid "security-groups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml308(para)
msgid "Number of instance cores allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml312(systemitem)
msgid "cores"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml319(title)
msgid "View and Update Compute Quotas for a Tenant (Project)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml320(para)
msgid ""
"As an administrative user, you can use the <placeholder-1/> commands, which "
"are provided by the <literal>python-novaclient</literal> package, to view "
"and update tenant quotas."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml325(title)
msgid "To view and update default quota values"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml327(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml537(para)
msgid "List all default quotas for all tenants, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml349(para)
msgid "Update a default value for a new tenant, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml350(replaceable)
msgid "key"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml356(title)
msgid "To view quota values for a tenant (project)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml358(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml574(para)
msgid "Place the tenant ID in a useable variable, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml359(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml389(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml559(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml575(replaceable)
msgid "tenantName"
msgstr "tenantNames"

#: ./doc/openstack-ops/ch_ops_projects_users.xml362(para)
msgid "List the currently set quota values for a tenant, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml386(title)
msgid "To update quota values for a tenant (project)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml388(para)
msgid "Obtain the tenant ID, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml392(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml578(para)
msgid "Update a particular quota value, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml393(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml579(replaceable)
msgid "quotaName"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml393(replaceable)
msgid "quotaValue"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml393(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml579(replaceable)
msgid "tenantID"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml414(para)
msgid "To view a list of options for the <placeholder-1/> command, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml423(title)
msgid "Set Object Storage Quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml424(para)
msgid ""
"Object Storage quotas were introduced in Swift 1.8 (OpenStack Grizzly). "
"There are currently two categories of quotas for Object Storage:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml429(para)
msgid ""
"Container quotas: Limits the total size (in bytes) or number of objects that"
" can be stored in a single container."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml433(para)
msgid ""
"Account quotas: Limits the total size (in bytes) that a user has available "
"in the Object Storage service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml437(para)
msgid ""
"To take advantage of either container quotas or account quotas, your Object "
"Storage proxy server must have <code>container_quotas</code> or "
"<code>account_quotas</code> (or both) added to the [pipeline:main] pipeline."
" Each quota type also requires its own section in the <filename>proxy-"
"server.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml450(para)
msgid ""
"To view and update Object Storage quotas, use the <code>swift</code> command"
" provided by the <code>python-swiftclient</code> package. Any user included "
"in the project can view the quotas placed on their project. To update Object"
" Storage quotas on a project, you must have the role of ResellerAdmin in the"
" project that the quota is being applied to."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml454(para)
msgid "To view account quotas placed on a project:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml464(para)
msgid "To apply or update account quotas on a project:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml467(para)
msgid "For example, to place a 5 GB quota on an account:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml470(para)
msgid "To verify the quota, run the <placeholder-1/> command again:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml483(title)
msgid "Set Block Storage Quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml484(para)
msgid ""
"As an administrative user, you can update the Block Storage Service quotas "
"for a tenant, as well as update the quota defaults for a new tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml489(caption)
msgid "Block Storage Quota Descriptions"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml501(para)
msgid "gigabytes"
msgstr "gigabájt"

#: ./doc/openstack-ops/ch_ops_projects_users.xml504(para)
msgid "Number of volume gigabytes allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml509(para)
msgid "snapshots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml512(para)
msgid "Number of Block Storage snapshots allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml518(para)
msgid "volumes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml521(para)
msgid "Number of Block Storage volumes allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml529(title)
msgid "View and Update Block Storage Quotas for a Tenant (Project)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml530(para)
msgid ""
"As an administrative user, you can use the <placeholder-1/> commands, which "
"are provided by the <literal>python-cinderclient</literal> package, to view "
"and update tenant quotas."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml535(title)
msgid "To view and update default Block Storage quota values"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml550(para)
msgid ""
"To update a default value for a new tenant, update the property in the "
"<filename>/etc/cinder/cinder.conf</filename> file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml556(title)
msgid "To view Block Storage quotas for a tenant"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml558(para)
msgid "View quotas for the tenant, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml572(title)
msgid "To update Compute service quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml579(replaceable)
msgid "NewValue"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml596(title)
msgid "User Management"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml597(para)
msgid ""
"The command-line tools for managing users are inconvenient to use directly. "
"They require issuing multiple commands to complete a single task, and they "
"use UUIDs rather than symbolic names for many items. In practice, humans "
"typically do not use these tools directly. Fortunately, the OpenStack "
"dashboard provides a reasonable interface to this. In addition, many sites "
"write custom tools for local needs to enforce local policies and provide "
"levels of self-service to users that aren't currently available with "
"packaged tools."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml605(title)
msgid "Creating New Users"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml606(para)
msgid "To create a user, you need the following information:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml610(para)
msgid "Username"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml613(para)
msgid "Email address"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml616(para)
msgid "Password"
msgstr "Jelszó"

#: ./doc/openstack-ops/ch_ops_projects_users.xml619(para)
msgid "Primary project"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml622(para)
msgid "Role"
msgstr "Szerep"

#: ./doc/openstack-ops/ch_ops_projects_users.xml625(para)
msgid ""
"Username and email address are self-explanatory, though your site may have "
"local conventions you should observe. Setting and changing passwords in the "
"Identity service requires administrative privileges. As of the Folsom "
"release, users cannot change their own passwords. This is a large driver for"
" creating local custom tools, and must be kept in mind when assigning and "
"distributing passwords. The primary project is simply the first project the "
"user is associated with and must exist prior to creating the user. Role is "
"almost always going to be \"member.\" Out of the box, OpenStack comes with "
"two roles defined:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml634(para)
msgid "member: a typical user."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml637(para)
msgid ""
"admin: an administrative super user, which has full permissions across all "
"projects and should be used with great care."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml641(para)
msgid "It is possible to define other roles, but doing so is uncommon."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml643(para)
msgid ""
"Once you've gathered this information, creating the user in the dashboard is"
" just another web form similar to what we've seen before and can be found by"
" clicking the Users link in the Admin navigation bar and then clicking the "
"Create User button at the top right."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml646(para)
msgid ""
"Modifying users is also done from this Users page. If you have a large "
"number of users, this page can get quite crowded. The Filter search box at "
"the top of the page can be used to limit the users listing. A form very "
"similar to the user creation dialog can be pulled up by selecting Edit from "
"the actions dropdown menu at the end of the line for the user you are "
"modifying."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml653(title)
msgid "Associating Users with Projects"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml654(para)
msgid ""
"Many sites run with users being associated with only one project. This is a "
"more conservative and simpler choice both for administration and for users. "
"Administratively, if a user reports a problem with an instance or quota, it "
"is obvious which project this relates to as well. Users needn't worry about "
"what project they are acting in if they are only in one project. However, "
"note that, by default, any user can affect the resources of any other user "
"within their project. It is also possible to associate users with multiple "
"projects if that makes sense for your organization."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml661(para)
msgid ""
"Associating existing users with an additional project or removing them from "
"an older project is done from the Projects page of the dashboard by "
"selecting Modify Users from the Actions column, as shown in <xref linkend"
"=\"horizon-edit-project\"/>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml665(title)
msgid "<guilabel>Edit Project Members</guilabel> tab"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml673(para)
msgid ""
"From this view you can do a number of useful and a few dangerous things."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml675(para)
msgid ""
"The first column of this form, named All Users, includes a list of all the "
"users in your cloud who are not already associated with this project. The "
"second column shows all the users who are. These lists can be quite long, "
"but they can be limited by typing a substring of the user name you are "
"looking for in the filter field at the top of the column."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml679(para)
msgid ""
"From here, click the <guiicon>+</guiicon> icon to add users to the project. "
"Click the <guiicon>-</guiicon> to remove them."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml682(para)
msgid ""
"The dangerous possibility comes with the ability to change member roles. "
"This is the dropdown list below the user name in the <guilabel>Project "
"Members</guilabel> list. In virtually all cases this value should be set to "
"Member. This example purposefully shows an administrative user where this "
"value is admin."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml687(para)
msgid ""
"The admin is global not per project, so granting a user the admin role in "
"any project gives the user administrative rights across the whole cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml690(para)
msgid ""
"Typical use is to only create administrative users in a single project, by "
"convention the admin project, which is created by default during cloud "
"setup. If your administrative users also use the cloud to launch and manage "
"instances, it is strongly recommended that you use separate user accounts "
"for administrative access and normal operations and that they be in distinct"
" projects."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml696(title)
msgid "Customizing Authorization"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml697(para)
msgid ""
"The default <glossterm>authorization</glossterm> settings allow "
"administrative users only to create resources on behalf of a different "
"project. OpenStack handles two kind of authorization policies:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml702(para)
msgid ""
"<emphasis role=\"bold\">Operation-based</emphasis>: Policies specify access "
"criteria for specific operations, possibly with fine-grained control over "
"specific attributes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml707(para)
msgid ""
"<emphasis role=\"bold\">Resource-based</emphasis>: Whether access to a "
"specific resource might be granted or not according to the permissions "
"configured for the resource (currently available only for the network "
"resource). The actual authorization policies enforced in an OpenStack "
"service vary from deployment to deployment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml714(para)
msgid ""
"The policy engine reads entries from the <code>policy.json</code> file. The "
"actual location of this file might vary from distribution to distribution: "
"for nova, it is typically in <code>/etc/nova/policy.json</code>. You can "
"update entries while the system is running, and you do not have to restart "
"services. Currently, the only way to update such policies is to edit the "
"policy file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml719(para)
msgid ""
"The OpenStack service's policy engine matches a policy directly. A rule "
"indicates evaluation of the elements of such policies. For instance, in a "
"<code>compute:create: [[\"rule:admin_or_owner\"]]</code> statement, the "
"policy is <code>compute:create</code>, and the rule is "
"<code>admin_or_owner</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml726(para)
msgid ""
"Policies are triggered by an OpenStack policy engine whenever one of them "
"matches an OpenStack API operation or a specific attribute being used in a "
"given operation. For instance, the engine tests the "
"<code>create:compute</code> policy every time a user sends a <code>POST "
"/v2/{tenant_id}/servers</code> request to the OpenStack Compute API server. "
"Policies can be also related to specific <glossterm>API "
"extension</glossterm>s. For instance, if a user needs an extension like "
"<code>compute_extension:rescue</code> the attributes defined by the provider"
" extensions trigger the rule test for that operation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml739(para)
msgid ""
"An authorization policy can be composed by one or more rules. If more rules "
"are specified, evaluation policy is successful if any of the rules evaluates"
" successfully; if an API operation matches multiple policies, then all the "
"policies must evaluate successfully. Also, authorization rules are "
"recursive. Once a rule is matched, the rule(s) can be resolved to another "
"rule, until a terminal rule is reached. These are the rules defined:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml750(para)
msgid ""
"<emphasis role=\"bold\">Role-based rules</emphasis>: Evaluate successfully "
"if the user submitting the request has the specified role. For instance "
"<code>\"role:admin\"</code> is successful if the user submitting the request"
" is an administrator."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml756(para)
msgid ""
"<emphasis role=\"bold\">Field-based rules: </emphasis>Evaluate successfully "
"if a field of the resource specified in the current request matches a "
"specific value. For instance <code>\"field:networks:shared=True\"</code> is "
"successful if the attribute shared of the network resource is set to true."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml763(para)
msgid ""
"<emphasis role=\"bold\">Generic rules:</emphasis> Compare an attribute in "
"the resource with an attribute extracted from the user's security "
"credentials and evaluates successfully if the comparison is successful. For "
"instance <code>\"tenant_id:%(tenant_id)s\"</code> is successful if the "
"tenant identifier in the resource is equal to the tenant identifier of the "
"user submitting the request."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml771(para)
msgid ""
"Here are snippets of the default nova <filename>policy.json</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml775(emphasis)
msgid "[1]"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml776(emphasis)
msgid "[2]"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml792(emphasis)
msgid "[3]"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml795(para)
msgid ""
"[1] Shows a rule that evaluates successfully if the current user is an "
"administrator or the owner of the resource specified in the request (tenant "
"identifier is equal)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml797(para)
msgid ""
"[2] Shows the default policy, which is always evaluated if an API operation "
"does not match any of the policies in <code>policy.json</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml799(para)
msgid ""
"[3] Shows a policy restricting the ability to manipulate flavors to "
"administrators using the Admin API only."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml801(para)
msgid ""
"In some cases, some operations should be restricted to administrators only. "
"Therefore, as a further example, let us consider how this sample policy file"
" could be modified in a scenario where we enable users to create their own "
"flavors:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml808(title)
msgid "Users Who Disrupt Other Users"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml809(para)
msgid ""
"Users on your cloud can disrupt other users, sometimes intentionally and "
"maliciously and other times by accident. Understanding the situation allows "
"you to make a better decision on how to handle the disruption."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml813(para)
msgid ""
"For example, a group of users have instances that are utilizing a large "
"amount of compute resources for very compute-intensive tasks. This is "
"driving the load up on compute nodes and affecting other users. In this "
"situation, review your user use cases. You may find that high compute "
"scenarios are common, and should then plan for proper segregation in your "
"cloud, such as host aggregation or regions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml818(para)
msgid ""
"Another example is a user consuming a very large amount of bandwidth. Again,"
" the key is to understand what the user is doing. If they naturally need a "
"high amount of bandwidth, you might have to limit their transmission rate as"
" to not affect other users or move the user to an area with more bandwidth "
"available. On the other hand, maybe the user's instance has been hacked and "
"is part of a botnet launching DDOS attacks. Resolution of this issue is the "
"same as though any other server on your network has been hacked. Contact the"
" user and give them time to respond. If they don't respond, shut down the "
"instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml825(para)
msgid ""
"A final example is if a user is hammering cloud resources repeatedly. "
"Contact the user and learn what they are trying to do. Maybe they don't "
"understand that what they're doing is inappropriate or maybe there is an "
"issue with the resource they are trying to access that is causing their "
"requests to queue or lag."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml834(para)
msgid ""
"One key element of systems administration that is often overlooked is that "
"end users are the reason why systems administrators exist. Don't go the BOFH"
" route and terminate every user who causes an alert to go off. Work with "
"them to understand what they're trying to accomplish and see how your "
"environment can better assist them in achieving their goals. Meet your users"
" needs by organizing your users into projects, applying policies, managing "
"quotas, and working with them."
msgstr ""

#. Put one translator per line, in the form of NAME <EMAIL>, YEAR1, YEAR2
#: ./doc/openstack-ops/ch_ops_projects_users.xml0(None)
msgid "translator-credits"
msgstr ""
